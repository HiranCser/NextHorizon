jd_id,role_title,company,source_title,source_url,source_domain,jd_text,date_scraped,exp_min_years,exp_max_years,exp_evidence,seniority_level,seniority_evidence,matched_skills
57b33b88-b5bb-4cb6-bbf3-7438128d0d9f,Machine Learning Engineer,Togetherai,Job Application for Machine Learning Engineer - Inference at ...,https://boards.greenhouse.io/togetherai/jobs/4385540007,boards.greenhouse.io,"Job Application for Machine Learning Engineer - Inference at Together AI Back to jobs Machine Learning Engineer - Inference San Francisco Apply About the Role Together AI is seeking a Machine Learning Engineer to join our Inference Engine team, focusing on optimizing and enhancing the performance of our AI inference systems. This role involves working with state-of-the-art large language models models and ensuring they run efficiently and effectively at scale. If you are passionate about AI inference, PyTorch, and developing high-performance systems, we want to hear from you. This position offers the chance to collaborate closely with AI researchers and engineers to create cutting-edge AI solutions. Join us in shaping the future at Together AI! Responsibilities Design and build the production systems that power the Together AI inference engine, enabling reliability and performance at scale. Develop and optimize runtime inference services for large-scale AI applications. Collaborate with researchers, engineers, product managers, and designers to bring new features and research capabilities to the world. Conduct design and code reviews to ensure high standards of quality. Create services, tools, and developer documentation to support the inference engine. Implement robust and fault-tolerant systems for data ingestion and processing. Requirements 3+ years of experience writing high-performance, well-tested, production-quality code. Proficiency with Python and PyTorch. Demonstrated experience in building high performance libraries and tooling. Excellent understanding of low-level operating systems concepts including multi-threading, memory management, networking, storage, performance, and scale. Preferred: Knowledge of existing AI inference systems such as TGI, vLLM, TensorRT-LLM, Optimum Preferred: Knowledge of AI inference techniques such as speculative decoding. Preferred: Knowledge of CUDA/Triton programming. Nice to have: Knowledge of Rust, Cython and compilers. About Together AI Together AI is a research-driven artificial intelligence company. We believe open and transparent AI systems will drive innovation and create the best outcomes for society. Together, we are on a mission to significantly lower the cost of modern AI systems by co-designing software, hardware, algorithms, and models. We have contributed to leading open-source research, models, and datasets to advance the frontier of AI. Our team has been behind technological advancements such as FlashAttention, Hyena, FlexGen, and RedPajama. We invite you to join a passionate group of researchers and engineers in our journey to build the next-generation AI infrastructure. Compensation We offer competitive compensation, startup equity, health insurance, and other competitive benefits. The US base salary range for this full-time position is $160,000 - $230,000 + equity + benefits. Our salary ranges are determined by location, level, and role. Individual compensation will be determined by experience, skills, and job-related knowledge. Equal Opportunity Together AI is an Equal Opportunity Employer and is proud to offer equal employment opportunities to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. Please see our privacy policy at https://www.together.ai/privacy Create a Job Alert Interested in building your career at Together AI? Get future opportunities sent straight to your email. Create alert Apply for this job * indicates a required field Autofill with MyGreenhouse First Name * Last Name * Email * Phone Country Phone Resume/CV Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf Cover Letter Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf LinkedIn Profile Website U.S. Standard Demographic Questions We invite applicants to share their demographic background. If you choose to complete this survey, your responses may be used to identify areas of improvement in our hiring process. How would you describe your gender identity? (mark all that apply) Select... How would you describe your racial/ethnic background? (mark all that apply) Select... How would you describe your sexual orientation? (mark all that apply) Select... Do you identify as transgender? (select one) Select... Do you have a disability or chronic condition (physical, visual, auditory, cognitive, mental, emotional, or other) that substantially limits one or more of your major life activities, including mobility, communication (seeing, hearing, speaking), and learning? (select one) Select... Are you a veteran or active member of the United States Armed Forces? (select one) Select... Voluntary Self-Identification For government reporting purposes, we ask candidates to respond to the below self-identification survey. Completion of the form",2025-12-07,3.0,,3+ years,Unspecified,,Python; Machine Learning; Deep Learning; Generative AI
e14000e4-732d-4dbd-9105-da0d6c8f9879,Machine Learning Engineer,Woven By Toyota,"Senior Machine Learning Software Engineer, Frameworks Job Application for Machine Learning Engineer - Inference at ... ISEE - Machine Learning Engineer - Lever Zoox - Machine Learning Engineer - Mapping Machine Learning Engineer - AI Research (PhD) - Early Career Tagup - Machine Learning Engineer",https://jobs.lever.co/woven-by-toyota/ad02307a-daa5-418a-8b75-cb80e2561c86,jobs.lever.co,"Woven by Toyota - Senior Machine Learning Software Engineer, Frameworks Senior Machine Learning Software Engineer, Frameworks Palo Alto, CA / Ann Arbor, MI Product & Technology â€“ AD/ADAS / Employee / Hybrid Apply for this job Woven by Toyota is enabling Toyotaâ€™s once-in-a-century transformation into a mobility company. Inspired by a legacy of innovating for the benefit of others, our mission is to challenge the current state of mobility through human-centric innovation â€” expanding what â€œmobilityâ€ means and how it serves society. Our work centers on four pillars: AD/ADAS, our autonomous driving and advanced driver assist technologies; Arene, our software development platform for software-defined vehicles; Woven City, a test course for mobility; and Cloud & AI, the digital infrastructure powering our collaborative foundation. Business-critical functions empower these teams to execute, and together, weâ€™re working toward one bold goal: a world with zero accidents and enhanced well-being for all. TEAM At Woven by Toyota, we tackle Autonomy challenges at the intersection of AI, Robotics, and Advanced Driving. Our work involves a variety of challenges, such as analyzing petabytes of multimodal driving data, solving optimization problems, minimizing latency on hardware accelerators, deploying scalable and efficient machine learning (ML) training and evaluation pipelines, and designing novel neural network architectures to advance state-of-the-art ML for Perception, Prediction, and Motion Planning. We are looking for doers and creative problem solvers to join us in improving mobility for everyone with human-centered automated driving solutions for personal and commercial applications. WHO ARE WE LOOKING FOR? The team is looking for a skilled Machine Learning Engineer to work in close collaboration with our ML teams to build efficient cloud and data curation pipelines, automated training, evaluation and release pipelines, as well as providing introspection tools in our data. You will have the chance to design and implement innovative machine learning pipelines, and help accelerate the release of models for our next-generation autonomous vehicle platform, influencing millions of Toyota customer vehicles. We are looking for individuals who are passionate about self-driving car technology and its potential impact on humanity. RESPONSIBILITIES Develop foundational ML components to improve speed and ease of development of advanced machine learning models specifically tailored for autonomous vehicles utilizing deep learning and large-scale data. Deploy extensible, scalable and efficient ML data curation, training and evaluation cloud pipelines. Analyze model performance metrics, model failure modes, statistical relevance of datasets, etc. to guide the overall ML engineering effort. Integrate modern technologies with rigorous safety standards while maintaining cost efficiency. Significantly contribute to the development of needed components for end-to-end ML training and deployment, from data strategy to optimization and validation. Operate cross-functionally and serve a dual hat role in identifying opportunities to improve production models while also trailblazing and generalizing involved methods and toolings to empower others. Be a champion of the scientific method and critical thinking in inventing state-of-the-art deep learning solutions. Work in a high-velocity environment and employ agile development practices. Exhibit a ""Giver"" mindset, proactively asking, â€œWhat can I do for you?â€ to facilitate production development processes while maintaining a ""get things done"" mentality. Work in a hybrid workspace, with the requirement to be present in our Palo Alto (California) or Ann Arbor (Michigan) offices three days per week. MINIMUM QUALIFICATIONS BSc / BEng (MS / PhD nice-to-have) in Machine Learning, Computer Science, Robotics or related quantitative fields, or equivalent industry experience. 3+ years of experience with Python, PyTorch/Tensorflow, and software engineering best practices. 2+ years of experience covering machine learning workflows, data sampling and curation, pre-processing, model training, ablation studies, evaluation, deployment, and inference optimization. Deep understanding of runtime complexity, space complexity, distributed computing, and the application of these concepts in concrete, distributed ML training and evaluation. Experience working with temporal data and/or sequential modeling. Strong communication skills with the ability to communicate concepts clearly and precisely. NICE TO HAVES Experience with deep learning approaches such as supervised/unsupervised learning, transfer learning, multi-task learning, and/or deep reinforcement learning. 2+ years of experience with Apache Spark, Airflow, Flyte, Flink, Ray, or similar ML pipelines technologies. Experience deploying and tuning ML models onto custom edge hardware in robotics applications. Previously worked at, or in close collaboration with M",2025-12-07,3.0,,3+ years,Senior,senior,Python; Machine Learning; Deep Learning
6faba802-d533-4a26-86d0-c3f1d6503197,Machine Learning Engineer,Togetherai,Job Application for Machine Learning Engineer - Inference at ...,https://boards.greenhouse.io/togetherai/jobs/4385540007,boards.greenhouse.io,"Job Application for Machine Learning Engineer - Inference at Together AI Back to jobs Machine Learning Engineer - Inference San Francisco Apply About the Role Together AI is seeking a Machine Learning Engineer to join our Inference Engine team, focusing on optimizing and enhancing the performance of our AI inference systems. This role involves working with state-of-the-art large language models models and ensuring they run efficiently and effectively at scale. If you are passionate about AI inference, PyTorch, and developing high-performance systems, we want to hear from you. This position offers the chance to collaborate closely with AI researchers and engineers to create cutting-edge AI solutions. Join us in shaping the future at Together AI! Responsibilities Design and build the production systems that power the Together AI inference engine, enabling reliability and performance at scale. Develop and optimize runtime inference services for large-scale AI applications. Collaborate with researchers, engineers, product managers, and designers to bring new features and research capabilities to the world. Conduct design and code reviews to ensure high standards of quality. Create services, tools, and developer documentation to support the inference engine. Implement robust and fault-tolerant systems for data ingestion and processing. Requirements 3+ years of experience writing high-performance, well-tested, production-quality code. Proficiency with Python and PyTorch. Demonstrated experience in building high performance libraries and tooling. Excellent understanding of low-level operating systems concepts including multi-threading, memory management, networking, storage, performance, and scale. Preferred: Knowledge of existing AI inference systems such as TGI, vLLM, TensorRT-LLM, Optimum Preferred: Knowledge of AI inference techniques such as speculative decoding. Preferred: Knowledge of CUDA/Triton programming. Nice to have: Knowledge of Rust, Cython and compilers. About Together AI Together AI is a research-driven artificial intelligence company. We believe open and transparent AI systems will drive innovation and create the best outcomes for society. Together, we are on a mission to significantly lower the cost of modern AI systems by co-designing software, hardware, algorithms, and models. We have contributed to leading open-source research, models, and datasets to advance the frontier of AI. Our team has been behind technological advancements such as FlashAttention, Hyena, FlexGen, and RedPajama. We invite you to join a passionate group of researchers and engineers in our journey to build the next-generation AI infrastructure. Compensation We offer competitive compensation, startup equity, health insurance, and other competitive benefits. The US base salary range for this full-time position is $160,000 - $230,000 + equity + benefits. Our salary ranges are determined by location, level, and role. Individual compensation will be determined by experience, skills, and job-related knowledge. Equal Opportunity Together AI is an Equal Opportunity Employer and is proud to offer equal employment opportunities to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. Please see our privacy policy at https://www.together.ai/privacy Create a Job Alert Interested in building your career at Together AI? Get future opportunities sent straight to your email. Create alert Apply for this job * indicates a required field Autofill with MyGreenhouse First Name * Last Name * Email * Phone Country Phone Resume/CV Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf Cover Letter Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf LinkedIn Profile Website U.S. Standard Demographic Questions We invite applicants to share their demographic background. If you choose to complete this survey, your responses may be used to identify areas of improvement in our hiring process. How would you describe your gender identity? (mark all that apply) Select... How would you describe your racial/ethnic background? (mark all that apply) Select... How would you describe your sexual orientation? (mark all that apply) Select... Do you identify as transgender? (select one) Select... Do you have a disability or chronic condition (physical, visual, auditory, cognitive, mental, emotional, or other) that substantially limits one or more of your major life activities, including mobility, communication (seeing, hearing, speaking), and learning? (select one) Select... Are you a veteran or active member of the United States Armed Forces? (select one) Select... Voluntary Self-Identification For government reporting purposes, we ask candidates to respond to the below self-identification survey. Completion of the form",2025-12-07,3.0,,3+ years,Unspecified,,Python; Machine Learning; Deep Learning; Generative AI
d6c3a9b6-cb52-4c0f-bdab-56f07a41b7a8,Machine Learning Engineer,Woven By Toyota,"Senior Machine Learning Software Engineer, Frameworks Job Application for Machine Learning Engineer - Inference at ... ISEE - Machine Learning Engineer - Lever Zoox - Machine Learning Engineer - Mapping Machine Learning Engineer - AI Research (PhD) - Early Career Tagup - Machine Learning Engineer",https://jobs.lever.co/woven-by-toyota/ad02307a-daa5-418a-8b75-cb80e2561c86,jobs.lever.co,"Woven by Toyota - Senior Machine Learning Software Engineer, Frameworks Senior Machine Learning Software Engineer, Frameworks Palo Alto, CA / Ann Arbor, MI Product & Technology â€“ AD/ADAS / Employee / Hybrid Apply for this job Woven by Toyota is enabling Toyotaâ€™s once-in-a-century transformation into a mobility company. Inspired by a legacy of innovating for the benefit of others, our mission is to challenge the current state of mobility through human-centric innovation â€” expanding what â€œmobilityâ€ means and how it serves society. Our work centers on four pillars: AD/ADAS, our autonomous driving and advanced driver assist technologies; Arene, our software development platform for software-defined vehicles; Woven City, a test course for mobility; and Cloud & AI, the digital infrastructure powering our collaborative foundation. Business-critical functions empower these teams to execute, and together, weâ€™re working toward one bold goal: a world with zero accidents and enhanced well-being for all. TEAM At Woven by Toyota, we tackle Autonomy challenges at the intersection of AI, Robotics, and Advanced Driving. Our work involves a variety of challenges, such as analyzing petabytes of multimodal driving data, solving optimization problems, minimizing latency on hardware accelerators, deploying scalable and efficient machine learning (ML) training and evaluation pipelines, and designing novel neural network architectures to advance state-of-the-art ML for Perception, Prediction, and Motion Planning. We are looking for doers and creative problem solvers to join us in improving mobility for everyone with human-centered automated driving solutions for personal and commercial applications. WHO ARE WE LOOKING FOR? The team is looking for a skilled Machine Learning Engineer to work in close collaboration with our ML teams to build efficient cloud and data curation pipelines, automated training, evaluation and release pipelines, as well as providing introspection tools in our data. You will have the chance to design and implement innovative machine learning pipelines, and help accelerate the release of models for our next-generation autonomous vehicle platform, influencing millions of Toyota customer vehicles. We are looking for individuals who are passionate about self-driving car technology and its potential impact on humanity. RESPONSIBILITIES Develop foundational ML components to improve speed and ease of development of advanced machine learning models specifically tailored for autonomous vehicles utilizing deep learning and large-scale data. Deploy extensible, scalable and efficient ML data curation, training and evaluation cloud pipelines. Analyze model performance metrics, model failure modes, statistical relevance of datasets, etc. to guide the overall ML engineering effort. Integrate modern technologies with rigorous safety standards while maintaining cost efficiency. Significantly contribute to the development of needed components for end-to-end ML training and deployment, from data strategy to optimization and validation. Operate cross-functionally and serve a dual hat role in identifying opportunities to improve production models while also trailblazing and generalizing involved methods and toolings to empower others. Be a champion of the scientific method and critical thinking in inventing state-of-the-art deep learning solutions. Work in a high-velocity environment and employ agile development practices. Exhibit a ""Giver"" mindset, proactively asking, â€œWhat can I do for you?â€ to facilitate production development processes while maintaining a ""get things done"" mentality. Work in a hybrid workspace, with the requirement to be present in our Palo Alto (California) or Ann Arbor (Michigan) offices three days per week. MINIMUM QUALIFICATIONS BSc / BEng (MS / PhD nice-to-have) in Machine Learning, Computer Science, Robotics or related quantitative fields, or equivalent industry experience. 3+ years of experience with Python, PyTorch/Tensorflow, and software engineering best practices. 2+ years of experience covering machine learning workflows, data sampling and curation, pre-processing, model training, ablation studies, evaluation, deployment, and inference optimization. Deep understanding of runtime complexity, space complexity, distributed computing, and the application of these concepts in concrete, distributed ML training and evaluation. Experience working with temporal data and/or sequential modeling. Strong communication skills with the ability to communicate concepts clearly and precisely. NICE TO HAVES Experience with deep learning approaches such as supervised/unsupervised learning, transfer learning, multi-task learning, and/or deep reinforcement learning. 2+ years of experience with Apache Spark, Airflow, Flyte, Flink, Ray, or similar ML pipelines technologies. Experience deploying and tuning ML models onto custom edge hardware in robotics applications. Previously worked at, or in close collaboration with M",2025-12-07,3.0,,3+ years,Senior,senior,Python; Machine Learning; Deep Learning
f796f8c6-e071-4f66-8593-1f543f7a418d,Machine Learning Engineer,Togetherai,Job Application for Machine Learning Engineer - Inference at ...,https://boards.greenhouse.io/togetherai/jobs/4385540007,boards.greenhouse.io,"Job Application for Machine Learning Engineer - Inference at Together AI Back to jobs Machine Learning Engineer - Inference San Francisco Apply About the Role Together AI is seeking a Machine Learning Engineer to join our Inference Engine team, focusing on optimizing and enhancing the performance of our AI inference systems. This role involves working with state-of-the-art large language models models and ensuring they run efficiently and effectively at scale. If you are passionate about AI inference, PyTorch, and developing high-performance systems, we want to hear from you. This position offers the chance to collaborate closely with AI researchers and engineers to create cutting-edge AI solutions. Join us in shaping the future at Together AI! Responsibilities Design and build the production systems that power the Together AI inference engine, enabling reliability and performance at scale. Develop and optimize runtime inference services for large-scale AI applications. Collaborate with researchers, engineers, product managers, and designers to bring new features and research capabilities to the world. Conduct design and code reviews to ensure high standards of quality. Create services, tools, and developer documentation to support the inference engine. Implement robust and fault-tolerant systems for data ingestion and processing. Requirements 3+ years of experience writing high-performance, well-tested, production-quality code. Proficiency with Python and PyTorch. Demonstrated experience in building high performance libraries and tooling. Excellent understanding of low-level operating systems concepts including multi-threading, memory management, networking, storage, performance, and scale. Preferred: Knowledge of existing AI inference systems such as TGI, vLLM, TensorRT-LLM, Optimum Preferred: Knowledge of AI inference techniques such as speculative decoding. Preferred: Knowledge of CUDA/Triton programming. Nice to have: Knowledge of Rust, Cython and compilers. About Together AI Together AI is a research-driven artificial intelligence company. We believe open and transparent AI systems will drive innovation and create the best outcomes for society. Together, we are on a mission to significantly lower the cost of modern AI systems by co-designing software, hardware, algorithms, and models. We have contributed to leading open-source research, models, and datasets to advance the frontier of AI. Our team has been behind technological advancements such as FlashAttention, Hyena, FlexGen, and RedPajama. We invite you to join a passionate group of researchers and engineers in our journey to build the next-generation AI infrastructure. Compensation We offer competitive compensation, startup equity, health insurance, and other competitive benefits. The US base salary range for this full-time position is $160,000 - $230,000 + equity + benefits. Our salary ranges are determined by location, level, and role. Individual compensation will be determined by experience, skills, and job-related knowledge. Equal Opportunity Together AI is an Equal Opportunity Employer and is proud to offer equal employment opportunities to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. Please see our privacy policy at https://www.together.ai/privacy Create a Job Alert Interested in building your career at Together AI? Get future opportunities sent straight to your email. Create alert Apply for this job * indicates a required field Autofill with MyGreenhouse First Name * Last Name * Email * Phone Country Phone Resume/CV Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf Cover Letter Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf LinkedIn Profile Website U.S. Standard Demographic Questions We invite applicants to share their demographic background. If you choose to complete this survey, your responses may be used to identify areas of improvement in our hiring process. How would you describe your gender identity? (mark all that apply) Select... How would you describe your racial/ethnic background? (mark all that apply) Select... How would you describe your sexual orientation? (mark all that apply) Select... Do you identify as transgender? (select one) Select... Do you have a disability or chronic condition (physical, visual, auditory, cognitive, mental, emotional, or other) that substantially limits one or more of your major life activities, including mobility, communication (seeing, hearing, speaking), and learning? (select one) Select... Are you a veteran or active member of the United States Armed Forces? (select one) Select... Voluntary Self-Identification For government reporting purposes, we ask candidates to respond to the below self-identification survey. Completion of the form",2025-12-07,3.0,,3+ years,Unspecified,,Python; Machine Learning; Deep Learning; Generative AI
31738c83-92e0-4e10-a40c-bed0788cfcc6,Machine Learning Engineer,Woven By Toyota,"Senior Machine Learning Software Engineer, Frameworks Job Application for Machine Learning Engineer - Inference at ... ISEE - Machine Learning Engineer - Lever Zoox - Machine Learning Engineer - Mapping Machine Learning Engineer - AI Research (PhD) - Early Career Tagup - Machine Learning Engineer",https://jobs.lever.co/woven-by-toyota/ad02307a-daa5-418a-8b75-cb80e2561c86,jobs.lever.co,"Woven by Toyota - Senior Machine Learning Software Engineer, Frameworks Senior Machine Learning Software Engineer, Frameworks Palo Alto, CA / Ann Arbor, MI Product & Technology â€“ AD/ADAS / Employee / Hybrid Apply for this job Woven by Toyota is enabling Toyotaâ€™s once-in-a-century transformation into a mobility company. Inspired by a legacy of innovating for the benefit of others, our mission is to challenge the current state of mobility through human-centric innovation â€” expanding what â€œmobilityâ€ means and how it serves society. Our work centers on four pillars: AD/ADAS, our autonomous driving and advanced driver assist technologies; Arene, our software development platform for software-defined vehicles; Woven City, a test course for mobility; and Cloud & AI, the digital infrastructure powering our collaborative foundation. Business-critical functions empower these teams to execute, and together, weâ€™re working toward one bold goal: a world with zero accidents and enhanced well-being for all. TEAM At Woven by Toyota, we tackle Autonomy challenges at the intersection of AI, Robotics, and Advanced Driving. Our work involves a variety of challenges, such as analyzing petabytes of multimodal driving data, solving optimization problems, minimizing latency on hardware accelerators, deploying scalable and efficient machine learning (ML) training and evaluation pipelines, and designing novel neural network architectures to advance state-of-the-art ML for Perception, Prediction, and Motion Planning. We are looking for doers and creative problem solvers to join us in improving mobility for everyone with human-centered automated driving solutions for personal and commercial applications. WHO ARE WE LOOKING FOR? The team is looking for a skilled Machine Learning Engineer to work in close collaboration with our ML teams to build efficient cloud and data curation pipelines, automated training, evaluation and release pipelines, as well as providing introspection tools in our data. You will have the chance to design and implement innovative machine learning pipelines, and help accelerate the release of models for our next-generation autonomous vehicle platform, influencing millions of Toyota customer vehicles. We are looking for individuals who are passionate about self-driving car technology and its potential impact on humanity. RESPONSIBILITIES Develop foundational ML components to improve speed and ease of development of advanced machine learning models specifically tailored for autonomous vehicles utilizing deep learning and large-scale data. Deploy extensible, scalable and efficient ML data curation, training and evaluation cloud pipelines. Analyze model performance metrics, model failure modes, statistical relevance of datasets, etc. to guide the overall ML engineering effort. Integrate modern technologies with rigorous safety standards while maintaining cost efficiency. Significantly contribute to the development of needed components for end-to-end ML training and deployment, from data strategy to optimization and validation. Operate cross-functionally and serve a dual hat role in identifying opportunities to improve production models while also trailblazing and generalizing involved methods and toolings to empower others. Be a champion of the scientific method and critical thinking in inventing state-of-the-art deep learning solutions. Work in a high-velocity environment and employ agile development practices. Exhibit a ""Giver"" mindset, proactively asking, â€œWhat can I do for you?â€ to facilitate production development processes while maintaining a ""get things done"" mentality. Work in a hybrid workspace, with the requirement to be present in our Palo Alto (California) or Ann Arbor (Michigan) offices three days per week. MINIMUM QUALIFICATIONS BSc / BEng (MS / PhD nice-to-have) in Machine Learning, Computer Science, Robotics or related quantitative fields, or equivalent industry experience. 3+ years of experience with Python, PyTorch/Tensorflow, and software engineering best practices. 2+ years of experience covering machine learning workflows, data sampling and curation, pre-processing, model training, ablation studies, evaluation, deployment, and inference optimization. Deep understanding of runtime complexity, space complexity, distributed computing, and the application of these concepts in concrete, distributed ML training and evaluation. Experience working with temporal data and/or sequential modeling. Strong communication skills with the ability to communicate concepts clearly and precisely. NICE TO HAVES Experience with deep learning approaches such as supervised/unsupervised learning, transfer learning, multi-task learning, and/or deep reinforcement learning. 2+ years of experience with Apache Spark, Airflow, Flyte, Flink, Ray, or similar ML pipelines technologies. Experience deploying and tuning ML models onto custom edge hardware in robotics applications. Previously worked at, or in close collaboration with M",2025-12-07,3.0,,3+ years,Senior,senior,Python; Machine Learning; Deep Learning
2a3da512-7f3c-4c1a-9b1b-455475f8172f,Data Scientist,Pigment,"Pigment - Data Scientist - Lever Data Scientist WeRide.ai - Data Scientist, Metrics Team Data Scientist Gauntlet - Data Scientist - Lever",https://jobs.lever.co/pigment/01e58869-2094-4757-9315-b0972eb1d5c1,jobs.lever.co,"Pigment - Data Scientist Data Scientist France Tech â€“ Engineering / Full Time / Hybrid Apply for this job Join Pigment: The AI Platform Redefining Business Planning Pigment is the AI-powered business planning and performance management platform built for agility and scale. We connect people, data, and processes in one intuitive, feature-rich solution, empowering every teamâ€”from Finance to HRâ€”to build, adapt, and align strategic plans in real time. Founded in 2019, Pigment is one of the fastest-growing SaaS companies globally. Industry leaders like Unilever, Snowflake, Siemens, and DPD use Pigment daily to make more informed decisions and confidently navigate any scenario. With a team of 500+ across Paris, London, New York, San Francisco, and Toronto, we've raised nearly $400M from top-tier investors and were named a Visionary in the 2024 GartnerÂ® Magic Quadrantâ„¢ for Financial Planning Software. At Pigment, we take smart risks, celebrate bold ideas, and challenge the status quoâ€”all while working as one team. If you're driven by innovation and ready to make an impact at scale, weâ€™d love to hear from you. Pigment is seeking an experienced Data Scientist with a strong CS background and experience with Large Language Models (LLM) to join our innovative and fast-paced team. In this role, you will work on cutting-edge NLP projects and play a crucial part in developing and refining our product. If you are passionate about machine learning, have a strong background in natural language processing, and thrive in a collaborative and high-impact environment, we'd love to hear from you! What you will do : Research, fine-tune, and improve prompting of LLM models for Pigment's advanced use cases (Information Extraction, Information Retrieval, Text Generation tasks, etc.) Implement and deploy models in production environments Conduct experiments and benchmarking to assess the performance of various models and architectures Continuously research and stay up-to-date with recent advancements in NLP and large language models, applying novel techniques and methodologies to improve our models. ðŸŽ§ Listen to our podcast on Pigmentâ€™s GenAI team ðŸ“– Read more about our vision: Agentic AI for Data Analysis Requirements MS or Ph.D. in Computer Science, Mathematics, or a related field Minimum of 5 years of experience in NLP and machine learning Strong programming skills in SQL, Python, and relevant ML libraries and frameworks (e.g., TensorFlow, PyTorch, scikit-learn) Strong understanding of NLP techniques, including text representation, feature engineering, model selection, tokenization, and embeddings Hands-on experience working with large language models like GPT, LLAMA, BERT, or Transformer-based architectures Experience in the recent developments of Agentic Architecture is a plus Worked on LLM deployed projects (monitoring, LLM-as-a-judge, ...)' Solid understanding of GCP and related machine-learning offerings Excellent problem-solving skills and ability to work independently Strong written and verbal communication skills If you are passionate about NLP and Generative AI and want to work on a cutting-edge business planning platform, we encourage you to apply for this exciting opportunity at Pigment. What you will get Competitive package Stock options to ensure you have a stake in Pigment's growth The best health insurance with Alan Blue entirely free for you and your family Weekly Lunch and Lunch vouchers (Swile card) to cover your lunch breaks with total flexibility Subscription to Egym Wellpass (ex-Gymlib) for full access to gyms, studios, and wellness spaces across France Trust and flexible working hours Along with one company offsite every year, we have brand new offices at the heart of major cities including New York, San Francisco, Toronto, Paris, and London High-end equipment (based on stock/availability) to do your work in the best conditions Remote-friendly environment â‚¬70,000 - â‚¬100,000 a year We conduct background checks as part of our hiring process, in accordance with applicable laws and regulations in the countries where we operate. This may include verification of employment history, education, and, where legally permitted, criminal records. Any checks will be conducted lawfully prior to formal employment contracts being signed, with candidate consent, and information will be treated confidentially. Pigment is an equal opportunity employer. We believe diversity is a strength and fosters innovation. We are committed to enabling everyone to feel included and valued at the workplace. All qualified applicants will receive consideration for employment without regard to age, color, family, gender identity, marital status, national origin, physical or mental disability, sex (including pregnancy), sexual orientation, social origin, or any other characteristic protected by applicable laws. We may process your personal data in accordance with our HR Data Protection Notice . We may use artificial intelligence (AI) tools to support ",2025-12-07,5.0,,Minimum of 5 years,Unspecified,,Python; SQL; Machine Learning; Deep Learning; Generative AI
88668425-6768-486a-9708-100d63ce3684,Data Scientist,Voleon,"The Voleon Group - Data Scientist - Lever Senior Data Scientist Pigment - Data Scientist - Lever Data Scientist WeRide.ai - Data Scientist, Metrics Team Data Scientist Gauntlet - Data Scientist - Lever",https://jobs.lever.co/voleon/ebd0306d-4353-4b10-be9d-479af8127617,jobs.lever.co,"The Voleon Group - Data Scientist Data Scientist Berkeley, CA Research / Full-time / Hybrid Apply for this job Voleon is a technology company that applies state-of-the-art AI and machine learning techniques to real-world problems in finance. For nearly two decades, we have led our industry and worked at the frontier of applying AI/ML to investment management. We have become a multibillion-dollar asset manager, and we have ambitious goals for the future. Your colleagues will include internationally recognized experts in artificial intelligence and machine learning research as well as highly experienced finance and technology professionals. In addition to our enriching and collegial working environment, we offer highly competitive compensation and benefits packages, technology talks by our experts, a beautiful modern office, daily catered lunches, and more. The Voleon Group is forming a new team to help advance our data-driven investment initiatives. As a Data Scientist, you will be responsible for harvesting insights from a complex array of data. Your role will involve data curation, analysis, interpretation, visualization, and communication of your findings to members of the research staff and executive leadership. This role is a means to make a difference: as a machine learning company, data insights are essential to our business. Responsibilities Design and implement systems to ensure data correctness and monitor data health in data stores and live feeds Proactively identify abnormal production behavior and communicate them clearly to relevant stakeholders Perform extemporaneous analyses on research and production trading systems with leadership Harness financial expertise and statistical analysis to gain actionable insights into our production trading and research systems Design and implement analysis pipelines that automate those analyses found to be valuable for ongoing monitoring Requirements 1+ years of applied end-to-end industry experience, including internships working with complex datasets, including curation, querying, aggregation, exploratory data analysis, and visualization Experience using statistical methods to analyze data, identify patterns, conduct root cause analysis, discover insights, and recommend solutions Ability to frame and answer questions mathematically Ability to infer useful forward-looking directions from results of retrospective analysis Fluency in managing, processing, and visualizing tabular data using a combination of SQL, Pandas, and R Basic software development skills and experience with bash, linux/unix, and git Ability to refine requirements from ambiguous requests to produce reports demonstrating excellence in communication Bachelorâ€™s degree in a quantitative discipline (statistics, biostatistics, data science, computer science, or a related field) Preferred Masterâ€™s degree in a quantitative discipline Prior industry experience or displayed interest in finance, such as related academic projects, coursework in financial engineering, or industry internships Experience developing in a production-facing environment and familiarity with standard concepts and tooling, e.g., CI/CD, git, Airflow Compensation The base salary range for this position is $150,000 to $190,000 in the location(s) of this posting. Individual salaries are determined through a variety of factors, including, but not limited to, education, experience, knowledge, skills, and geography. Base salary does not include other forms of total compensation, such as bonus compensation and other benefits. Our benefits package includes medical, dental, and vision coverage, life and AD&D insurance, 20 days of paid time off, 9 sick days, and a 401(k) plan with a company match. â€œFriends of Voleonâ€ Candidate Referral Program If you have a great candidate in mind for this role and would like to have the potential to earn $7,500 if your referred candidate is successfully hired and employed by The Voleon Group, please use this form to submit your referral. For more details regarding eligibility, terms, and conditions, please make sure to review the Voleon Referral Bonus Program . Equal Opportunity Employer The Voleon Group is an Equal Opportunity employer. Applicants are considered without regard to race, color, religion, creed, national origin, age, sex, gender, marital status, sexual orientation and identity, genetic information, veteran status, citizenship, or any other factors prohibited by local, state, or federal law. #LI-MD1 We may use artificial intelligence (AI) tools to support parts of the hiring process. These tools assist our recruitment team but do not replace human judgement. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us. Apply for this job The Voleon Group Home Page Jobs powered by",2025-12-07,1.0,,1+ years,Staff,staff,SQL; Machine Learning
596047b5-703d-4ba4-bc61-89d56cefa784,Data Scientist,Gauntlet,Gauntlet - Data Scientist - Lever,https://jobs.lever.co/gauntlet/f778c21d-34ec-4555-a4ac-3f2206f8b90b,jobs.lever.co,"Gauntlet - Data Scientist Data Scientist New York City / San Francisco / Los Angeles / Remote Engineering / Full Time / Remote Apply for this job Gauntlet leads the field in quantitative research and optimization of DeFi economics. We manage market risk, optimize growth, and ensure economic safety for protocols facilitating most spot trading, borrowing, and lending activity across all of DeFi, protecting and optimizing the largest protocols and networks in the industry. We build institutional-grade vaults for decentralized finance, delivering risk-adjusted onchain yields for capital at scale. Designed by the most vigilant, quantitative minds in crypto and informed by years of research. As of November 2025, Gauntlet manages over $2B in vault TVL, and optimizes risk and incentives covering over $42 billion in customer TVL. We continually publish cutting-edge research that informs our risk models, alerts, and analysis, and is among the most cited institutions â€” including academic institutions â€” in terms of peer-reviewed papers addressing DeFi as a subject. Weâ€™re a Series B company with around 75 employees, operating remote-first with a home base in New York City. As a company, we build institutional-grade vaults that deliver risk-adjusted DeFi yields at scale, powered by automated risk models and off-chain intelligence. Gauntlet curates strategies across Morpho, Drift, Symbiotic, Aera and more, with >$2B in vault TVL and a growing suite of Prime, Core and Frontier vaults. Our mission is to drive adoption and understanding of the financial systems of the future. We operate with a traderâ€™s discipline and a risk managerâ€™s skepticism: size carefully, stress routinely, unwind decisively. The label equals the package equals the contents. No surprises, just predictable, reliable vaults. In order to grow our impact in the DeFi space we are looking to hire experienced Data Scientists to help new and established protocols better understand the systems theyâ€™ve built. This role will require establishing a strong ability to analyze and interpret data; as well as the ability to collaborate with and manage external clients. You will be working directly with the premier and innovative DeFi protocols and developing expert-level knowledge and experience of the mechanisms that underpin the DeFi industry. Responsibilities Perform in depth novel research into how to make premier DeFi protocols safer and more efficient through mechanism design, data analysis, and dynamic parameter optimization. Take ownership of client engagements, scoping out work, managing client relationships, and delivering value to clients through your research and work. Draft and write engaging research for public consumption both to grow Gauntletâ€™s Brand as well as to satisfy client requirements Build and deploy easy-to-understand and visually compelling dashboards for internal and external consumption Qualifications 4+ years of professional experience Extremely clear and effective communication and client management skills Proven track record of drawing deep insights from complex datasets Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) Ability to work independently working towards abstract goals Experience working with pricing models, financial products and/or different asset classes Bonus Points Experience working in the crypto industry is a big plus. Enthusiasm for the space, especially DeFi, is very much desired Experience with derivatives style products Experience managing external client relationships Published or presented research in the space Benefits and Perks Remote first - work from anywhere in the US & CAN! Competitive packages with the added opportunity for incentive-based compensation Regular in-person company retreats and cross-country ""office visit"" perk 100% paid medical, dental and vision premiums for employees Laptop provided $1,000 WFH stipend upon joining $100 per month reimbursement for fitness-related expenses Monthly reimbursement for home internet, phone, and cellular data Unlimited vacation policy 100% paid parental leave of 12 weeks Fertility benefits Please note at this time our hiring is reserved for potential employees who are able to work within the contiguous United States and Canada. Should you need alternative accommodations, please note that in your application. The national pay range for this role is $150,000 - $205,000 base plus additional On Target Earnings potential by level and equity in the company. Our salary ranges are based on paying competitively for a company of our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide. Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company. #LI-Remote We may use artificial intelligence (AI) tools to",2025-12-07,4.0,,4+ years,Unspecified,,Python; SQL
54e9800c-cc0c-422e-b1e5-e5606124cda6,Data Scientist,Gauntlet,Gauntlet - Data Scientist - Lever,https://jobs.lever.co/gauntlet/f778c21d-34ec-4555-a4ac-3f2206f8b90b,jobs.lever.co,"Gauntlet - Data Scientist Data Scientist New York City / San Francisco / Los Angeles / Remote Engineering / Full Time / Remote Apply for this job Gauntlet leads the field in quantitative research and optimization of DeFi economics. We manage market risk, optimize growth, and ensure economic safety for protocols facilitating most spot trading, borrowing, and lending activity across all of DeFi, protecting and optimizing the largest protocols and networks in the industry. We build institutional-grade vaults for decentralized finance, delivering risk-adjusted onchain yields for capital at scale. Designed by the most vigilant, quantitative minds in crypto and informed by years of research. As of November 2025, Gauntlet manages over $2B in vault TVL, and optimizes risk and incentives covering over $42 billion in customer TVL. We continually publish cutting-edge research that informs our risk models, alerts, and analysis, and is among the most cited institutions â€” including academic institutions â€” in terms of peer-reviewed papers addressing DeFi as a subject. Weâ€™re a Series B company with around 75 employees, operating remote-first with a home base in New York City. As a company, we build institutional-grade vaults that deliver risk-adjusted DeFi yields at scale, powered by automated risk models and off-chain intelligence. Gauntlet curates strategies across Morpho, Drift, Symbiotic, Aera and more, with >$2B in vault TVL and a growing suite of Prime, Core and Frontier vaults. Our mission is to drive adoption and understanding of the financial systems of the future. We operate with a traderâ€™s discipline and a risk managerâ€™s skepticism: size carefully, stress routinely, unwind decisively. The label equals the package equals the contents. No surprises, just predictable, reliable vaults. In order to grow our impact in the DeFi space we are looking to hire experienced Data Scientists to help new and established protocols better understand the systems theyâ€™ve built. This role will require establishing a strong ability to analyze and interpret data; as well as the ability to collaborate with and manage external clients. You will be working directly with the premier and innovative DeFi protocols and developing expert-level knowledge and experience of the mechanisms that underpin the DeFi industry. Responsibilities Perform in depth novel research into how to make premier DeFi protocols safer and more efficient through mechanism design, data analysis, and dynamic parameter optimization. Take ownership of client engagements, scoping out work, managing client relationships, and delivering value to clients through your research and work. Draft and write engaging research for public consumption both to grow Gauntletâ€™s Brand as well as to satisfy client requirements Build and deploy easy-to-understand and visually compelling dashboards for internal and external consumption Qualifications 4+ years of professional experience Extremely clear and effective communication and client management skills Proven track record of drawing deep insights from complex datasets Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) Ability to work independently working towards abstract goals Experience working with pricing models, financial products and/or different asset classes Bonus Points Experience working in the crypto industry is a big plus. Enthusiasm for the space, especially DeFi, is very much desired Experience with derivatives style products Experience managing external client relationships Published or presented research in the space Benefits and Perks Remote first - work from anywhere in the US & CAN! Competitive packages with the added opportunity for incentive-based compensation Regular in-person company retreats and cross-country ""office visit"" perk 100% paid medical, dental and vision premiums for employees Laptop provided $1,000 WFH stipend upon joining $100 per month reimbursement for fitness-related expenses Monthly reimbursement for home internet, phone, and cellular data Unlimited vacation policy 100% paid parental leave of 12 weeks Fertility benefits Please note at this time our hiring is reserved for potential employees who are able to work within the contiguous United States and Canada. Should you need alternative accommodations, please note that in your application. The national pay range for this role is $150,000 - $205,000 base plus additional On Target Earnings potential by level and equity in the company. Our salary ranges are based on paying competitively for a company of our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide. Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company. #LI-Remote We may use artificial intelligence (AI) tools to",2025-12-07,4.0,,4+ years,Unspecified,,Python; SQL
ec6ede39-4ab2-478b-a728-182d5f584273,Data Scientist,Pigment,"Pigment - Data Scientist - Lever Data Scientist WeRide.ai - Data Scientist, Metrics Team Data Scientist Gauntlet - Data Scientist - Lever",https://jobs.lever.co/pigment/01e58869-2094-4757-9315-b0972eb1d5c1,jobs.lever.co,"Pigment - Data Scientist Data Scientist France Tech â€“ Engineering / Full Time / Hybrid Apply for this job Join Pigment: The AI Platform Redefining Business Planning Pigment is the AI-powered business planning and performance management platform built for agility and scale. We connect people, data, and processes in one intuitive, feature-rich solution, empowering every teamâ€”from Finance to HRâ€”to build, adapt, and align strategic plans in real time. Founded in 2019, Pigment is one of the fastest-growing SaaS companies globally. Industry leaders like Unilever, Snowflake, Siemens, and DPD use Pigment daily to make more informed decisions and confidently navigate any scenario. With a team of 500+ across Paris, London, New York, San Francisco, and Toronto, we've raised nearly $400M from top-tier investors and were named a Visionary in the 2024 GartnerÂ® Magic Quadrantâ„¢ for Financial Planning Software. At Pigment, we take smart risks, celebrate bold ideas, and challenge the status quoâ€”all while working as one team. If you're driven by innovation and ready to make an impact at scale, weâ€™d love to hear from you. Pigment is seeking an experienced Data Scientist with a strong CS background and experience with Large Language Models (LLM) to join our innovative and fast-paced team. In this role, you will work on cutting-edge NLP projects and play a crucial part in developing and refining our product. If you are passionate about machine learning, have a strong background in natural language processing, and thrive in a collaborative and high-impact environment, we'd love to hear from you! What you will do : Research, fine-tune, and improve prompting of LLM models for Pigment's advanced use cases (Information Extraction, Information Retrieval, Text Generation tasks, etc.) Implement and deploy models in production environments Conduct experiments and benchmarking to assess the performance of various models and architectures Continuously research and stay up-to-date with recent advancements in NLP and large language models, applying novel techniques and methodologies to improve our models. ðŸŽ§ Listen to our podcast on Pigmentâ€™s GenAI team ðŸ“– Read more about our vision: Agentic AI for Data Analysis Requirements MS or Ph.D. in Computer Science, Mathematics, or a related field Minimum of 5 years of experience in NLP and machine learning Strong programming skills in SQL, Python, and relevant ML libraries and frameworks (e.g., TensorFlow, PyTorch, scikit-learn) Strong understanding of NLP techniques, including text representation, feature engineering, model selection, tokenization, and embeddings Hands-on experience working with large language models like GPT, LLAMA, BERT, or Transformer-based architectures Experience in the recent developments of Agentic Architecture is a plus Worked on LLM deployed projects (monitoring, LLM-as-a-judge, ...)' Solid understanding of GCP and related machine-learning offerings Excellent problem-solving skills and ability to work independently Strong written and verbal communication skills If you are passionate about NLP and Generative AI and want to work on a cutting-edge business planning platform, we encourage you to apply for this exciting opportunity at Pigment. What you will get Competitive package Stock options to ensure you have a stake in Pigment's growth The best health insurance with Alan Blue entirely free for you and your family Weekly Lunch and Lunch vouchers (Swile card) to cover your lunch breaks with total flexibility Subscription to Egym Wellpass (ex-Gymlib) for full access to gyms, studios, and wellness spaces across France Trust and flexible working hours Along with one company offsite every year, we have brand new offices at the heart of major cities including New York, San Francisco, Toronto, Paris, and London High-end equipment (based on stock/availability) to do your work in the best conditions Remote-friendly environment â‚¬70,000 - â‚¬100,000 a year We conduct background checks as part of our hiring process, in accordance with applicable laws and regulations in the countries where we operate. This may include verification of employment history, education, and, where legally permitted, criminal records. Any checks will be conducted lawfully prior to formal employment contracts being signed, with candidate consent, and information will be treated confidentially. Pigment is an equal opportunity employer. We believe diversity is a strength and fosters innovation. We are committed to enabling everyone to feel included and valued at the workplace. All qualified applicants will receive consideration for employment without regard to age, color, family, gender identity, marital status, national origin, physical or mental disability, sex (including pregnancy), sexual orientation, social origin, or any other characteristic protected by applicable laws. We may process your personal data in accordance with our HR Data Protection Notice . We may use artificial intelligence (AI) tools to support ",2025-12-07,5.0,,Minimum of 5 years,Unspecified,,Python; SQL; Machine Learning; Deep Learning; Generative AI
2a18ebe1-42a7-4728-8c18-31ee27ba7c88,Data Scientist,Voleon,"The Voleon Group - Data Scientist - Lever Senior Data Scientist Pigment - Data Scientist - Lever Data Scientist WeRide.ai - Data Scientist, Metrics Team Data Scientist Gauntlet - Data Scientist - Lever",https://jobs.lever.co/voleon/ebd0306d-4353-4b10-be9d-479af8127617,jobs.lever.co,"The Voleon Group - Data Scientist Data Scientist Berkeley, CA Research / Full-time / Hybrid Apply for this job Voleon is a technology company that applies state-of-the-art AI and machine learning techniques to real-world problems in finance. For nearly two decades, we have led our industry and worked at the frontier of applying AI/ML to investment management. We have become a multibillion-dollar asset manager, and we have ambitious goals for the future. Your colleagues will include internationally recognized experts in artificial intelligence and machine learning research as well as highly experienced finance and technology professionals. In addition to our enriching and collegial working environment, we offer highly competitive compensation and benefits packages, technology talks by our experts, a beautiful modern office, daily catered lunches, and more. The Voleon Group is forming a new team to help advance our data-driven investment initiatives. As a Data Scientist, you will be responsible for harvesting insights from a complex array of data. Your role will involve data curation, analysis, interpretation, visualization, and communication of your findings to members of the research staff and executive leadership. This role is a means to make a difference: as a machine learning company, data insights are essential to our business. Responsibilities Design and implement systems to ensure data correctness and monitor data health in data stores and live feeds Proactively identify abnormal production behavior and communicate them clearly to relevant stakeholders Perform extemporaneous analyses on research and production trading systems with leadership Harness financial expertise and statistical analysis to gain actionable insights into our production trading and research systems Design and implement analysis pipelines that automate those analyses found to be valuable for ongoing monitoring Requirements 1+ years of applied end-to-end industry experience, including internships working with complex datasets, including curation, querying, aggregation, exploratory data analysis, and visualization Experience using statistical methods to analyze data, identify patterns, conduct root cause analysis, discover insights, and recommend solutions Ability to frame and answer questions mathematically Ability to infer useful forward-looking directions from results of retrospective analysis Fluency in managing, processing, and visualizing tabular data using a combination of SQL, Pandas, and R Basic software development skills and experience with bash, linux/unix, and git Ability to refine requirements from ambiguous requests to produce reports demonstrating excellence in communication Bachelorâ€™s degree in a quantitative discipline (statistics, biostatistics, data science, computer science, or a related field) Preferred Masterâ€™s degree in a quantitative discipline Prior industry experience or displayed interest in finance, such as related academic projects, coursework in financial engineering, or industry internships Experience developing in a production-facing environment and familiarity with standard concepts and tooling, e.g., CI/CD, git, Airflow Compensation The base salary range for this position is $150,000 to $190,000 in the location(s) of this posting. Individual salaries are determined through a variety of factors, including, but not limited to, education, experience, knowledge, skills, and geography. Base salary does not include other forms of total compensation, such as bonus compensation and other benefits. Our benefits package includes medical, dental, and vision coverage, life and AD&D insurance, 20 days of paid time off, 9 sick days, and a 401(k) plan with a company match. â€œFriends of Voleonâ€ Candidate Referral Program If you have a great candidate in mind for this role and would like to have the potential to earn $7,500 if your referred candidate is successfully hired and employed by The Voleon Group, please use this form to submit your referral. For more details regarding eligibility, terms, and conditions, please make sure to review the Voleon Referral Bonus Program . Equal Opportunity Employer The Voleon Group is an Equal Opportunity employer. Applicants are considered without regard to race, color, religion, creed, national origin, age, sex, gender, marital status, sexual orientation and identity, genetic information, veteran status, citizenship, or any other factors prohibited by local, state, or federal law. #LI-MD1 We may use artificial intelligence (AI) tools to support parts of the hiring process. These tools assist our recruitment team but do not replace human judgement. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us. Apply for this job The Voleon Group Home Page Jobs powered by",2025-12-07,1.0,,1+ years,Staff,staff,SQL; Machine Learning
5fd823ff-9515-4ee2-8937-30e09d702a20,Data Scientist,Gauntlet,Gauntlet - Data Scientist - Lever,https://jobs.lever.co/gauntlet/f778c21d-34ec-4555-a4ac-3f2206f8b90b,jobs.lever.co,"Gauntlet - Data Scientist Data Scientist New York City / San Francisco / Los Angeles / Remote Engineering / Full Time / Remote Apply for this job Gauntlet leads the field in quantitative research and optimization of DeFi economics. We manage market risk, optimize growth, and ensure economic safety for protocols facilitating most spot trading, borrowing, and lending activity across all of DeFi, protecting and optimizing the largest protocols and networks in the industry. We build institutional-grade vaults for decentralized finance, delivering risk-adjusted onchain yields for capital at scale. Designed by the most vigilant, quantitative minds in crypto and informed by years of research. As of November 2025, Gauntlet manages over $2B in vault TVL, and optimizes risk and incentives covering over $42 billion in customer TVL. We continually publish cutting-edge research that informs our risk models, alerts, and analysis, and is among the most cited institutions â€” including academic institutions â€” in terms of peer-reviewed papers addressing DeFi as a subject. Weâ€™re a Series B company with around 75 employees, operating remote-first with a home base in New York City. As a company, we build institutional-grade vaults that deliver risk-adjusted DeFi yields at scale, powered by automated risk models and off-chain intelligence. Gauntlet curates strategies across Morpho, Drift, Symbiotic, Aera and more, with >$2B in vault TVL and a growing suite of Prime, Core and Frontier vaults. Our mission is to drive adoption and understanding of the financial systems of the future. We operate with a traderâ€™s discipline and a risk managerâ€™s skepticism: size carefully, stress routinely, unwind decisively. The label equals the package equals the contents. No surprises, just predictable, reliable vaults. In order to grow our impact in the DeFi space we are looking to hire experienced Data Scientists to help new and established protocols better understand the systems theyâ€™ve built. This role will require establishing a strong ability to analyze and interpret data; as well as the ability to collaborate with and manage external clients. You will be working directly with the premier and innovative DeFi protocols and developing expert-level knowledge and experience of the mechanisms that underpin the DeFi industry. Responsibilities Perform in depth novel research into how to make premier DeFi protocols safer and more efficient through mechanism design, data analysis, and dynamic parameter optimization. Take ownership of client engagements, scoping out work, managing client relationships, and delivering value to clients through your research and work. Draft and write engaging research for public consumption both to grow Gauntletâ€™s Brand as well as to satisfy client requirements Build and deploy easy-to-understand and visually compelling dashboards for internal and external consumption Qualifications 4+ years of professional experience Extremely clear and effective communication and client management skills Proven track record of drawing deep insights from complex datasets Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) Ability to work independently working towards abstract goals Experience working with pricing models, financial products and/or different asset classes Bonus Points Experience working in the crypto industry is a big plus. Enthusiasm for the space, especially DeFi, is very much desired Experience with derivatives style products Experience managing external client relationships Published or presented research in the space Benefits and Perks Remote first - work from anywhere in the US & CAN! Competitive packages with the added opportunity for incentive-based compensation Regular in-person company retreats and cross-country ""office visit"" perk 100% paid medical, dental and vision premiums for employees Laptop provided $1,000 WFH stipend upon joining $100 per month reimbursement for fitness-related expenses Monthly reimbursement for home internet, phone, and cellular data Unlimited vacation policy 100% paid parental leave of 12 weeks Fertility benefits Please note at this time our hiring is reserved for potential employees who are able to work within the contiguous United States and Canada. Should you need alternative accommodations, please note that in your application. The national pay range for this role is $150,000 - $205,000 base plus additional On Target Earnings potential by level and equity in the company. Our salary ranges are based on paying competitively for a company of our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide. Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company. #LI-Remote We may use artificial intelligence (AI) tools to",2025-12-07,4.0,,4+ years,Unspecified,,Python; SQL
e7565b0f-859d-4aa7-ada0-0ed350d25ce6,Data Scientist,Pigment,"Pigment - Data Scientist - Lever Data Scientist WeRide.ai - Data Scientist, Metrics Team Data Scientist Gauntlet - Data Scientist - Lever",https://jobs.lever.co/pigment/01e58869-2094-4757-9315-b0972eb1d5c1,jobs.lever.co,"Pigment - Data Scientist Data Scientist France Tech â€“ Engineering / Full Time / Hybrid Apply for this job Join Pigment: The AI Platform Redefining Business Planning Pigment is the AI-powered business planning and performance management platform built for agility and scale. We connect people, data, and processes in one intuitive, feature-rich solution, empowering every teamâ€”from Finance to HRâ€”to build, adapt, and align strategic plans in real time. Founded in 2019, Pigment is one of the fastest-growing SaaS companies globally. Industry leaders like Unilever, Snowflake, Siemens, and DPD use Pigment daily to make more informed decisions and confidently navigate any scenario. With a team of 500+ across Paris, London, New York, San Francisco, and Toronto, we've raised nearly $400M from top-tier investors and were named a Visionary in the 2024 GartnerÂ® Magic Quadrantâ„¢ for Financial Planning Software. At Pigment, we take smart risks, celebrate bold ideas, and challenge the status quoâ€”all while working as one team. If you're driven by innovation and ready to make an impact at scale, weâ€™d love to hear from you. Pigment is seeking an experienced Data Scientist with a strong CS background and experience with Large Language Models (LLM) to join our innovative and fast-paced team. In this role, you will work on cutting-edge NLP projects and play a crucial part in developing and refining our product. If you are passionate about machine learning, have a strong background in natural language processing, and thrive in a collaborative and high-impact environment, we'd love to hear from you! What you will do : Research, fine-tune, and improve prompting of LLM models for Pigment's advanced use cases (Information Extraction, Information Retrieval, Text Generation tasks, etc.) Implement and deploy models in production environments Conduct experiments and benchmarking to assess the performance of various models and architectures Continuously research and stay up-to-date with recent advancements in NLP and large language models, applying novel techniques and methodologies to improve our models. ðŸŽ§ Listen to our podcast on Pigmentâ€™s GenAI team ðŸ“– Read more about our vision: Agentic AI for Data Analysis Requirements MS or Ph.D. in Computer Science, Mathematics, or a related field Minimum of 5 years of experience in NLP and machine learning Strong programming skills in SQL, Python, and relevant ML libraries and frameworks (e.g., TensorFlow, PyTorch, scikit-learn) Strong understanding of NLP techniques, including text representation, feature engineering, model selection, tokenization, and embeddings Hands-on experience working with large language models like GPT, LLAMA, BERT, or Transformer-based architectures Experience in the recent developments of Agentic Architecture is a plus Worked on LLM deployed projects (monitoring, LLM-as-a-judge, ...)' Solid understanding of GCP and related machine-learning offerings Excellent problem-solving skills and ability to work independently Strong written and verbal communication skills If you are passionate about NLP and Generative AI and want to work on a cutting-edge business planning platform, we encourage you to apply for this exciting opportunity at Pigment. What you will get Competitive package Stock options to ensure you have a stake in Pigment's growth The best health insurance with Alan Blue entirely free for you and your family Weekly Lunch and Lunch vouchers (Swile card) to cover your lunch breaks with total flexibility Subscription to Egym Wellpass (ex-Gymlib) for full access to gyms, studios, and wellness spaces across France Trust and flexible working hours Along with one company offsite every year, we have brand new offices at the heart of major cities including New York, San Francisco, Toronto, Paris, and London High-end equipment (based on stock/availability) to do your work in the best conditions Remote-friendly environment â‚¬70,000 - â‚¬100,000 a year We conduct background checks as part of our hiring process, in accordance with applicable laws and regulations in the countries where we operate. This may include verification of employment history, education, and, where legally permitted, criminal records. Any checks will be conducted lawfully prior to formal employment contracts being signed, with candidate consent, and information will be treated confidentially. Pigment is an equal opportunity employer. We believe diversity is a strength and fosters innovation. We are committed to enabling everyone to feel included and valued at the workplace. All qualified applicants will receive consideration for employment without regard to age, color, family, gender identity, marital status, national origin, physical or mental disability, sex (including pregnancy), sexual orientation, social origin, or any other characteristic protected by applicable laws. We may process your personal data in accordance with our HR Data Protection Notice . We may use artificial intelligence (AI) tools to support ",2025-12-07,5.0,,Minimum of 5 years,Unspecified,,Python; SQL; Machine Learning; Deep Learning; Generative AI
ba0704bb-96c2-4247-92e1-e1b8f22de99d,Data Scientist,Voleon,"The Voleon Group - Data Scientist - Lever Senior Data Scientist Pigment - Data Scientist - Lever Data Scientist WeRide.ai - Data Scientist, Metrics Team Data Scientist Gauntlet - Data Scientist - Lever",https://jobs.lever.co/voleon/ebd0306d-4353-4b10-be9d-479af8127617,jobs.lever.co,"The Voleon Group - Data Scientist Data Scientist Berkeley, CA Research / Full-time / Hybrid Apply for this job Voleon is a technology company that applies state-of-the-art AI and machine learning techniques to real-world problems in finance. For nearly two decades, we have led our industry and worked at the frontier of applying AI/ML to investment management. We have become a multibillion-dollar asset manager, and we have ambitious goals for the future. Your colleagues will include internationally recognized experts in artificial intelligence and machine learning research as well as highly experienced finance and technology professionals. In addition to our enriching and collegial working environment, we offer highly competitive compensation and benefits packages, technology talks by our experts, a beautiful modern office, daily catered lunches, and more. The Voleon Group is forming a new team to help advance our data-driven investment initiatives. As a Data Scientist, you will be responsible for harvesting insights from a complex array of data. Your role will involve data curation, analysis, interpretation, visualization, and communication of your findings to members of the research staff and executive leadership. This role is a means to make a difference: as a machine learning company, data insights are essential to our business. Responsibilities Design and implement systems to ensure data correctness and monitor data health in data stores and live feeds Proactively identify abnormal production behavior and communicate them clearly to relevant stakeholders Perform extemporaneous analyses on research and production trading systems with leadership Harness financial expertise and statistical analysis to gain actionable insights into our production trading and research systems Design and implement analysis pipelines that automate those analyses found to be valuable for ongoing monitoring Requirements 1+ years of applied end-to-end industry experience, including internships working with complex datasets, including curation, querying, aggregation, exploratory data analysis, and visualization Experience using statistical methods to analyze data, identify patterns, conduct root cause analysis, discover insights, and recommend solutions Ability to frame and answer questions mathematically Ability to infer useful forward-looking directions from results of retrospective analysis Fluency in managing, processing, and visualizing tabular data using a combination of SQL, Pandas, and R Basic software development skills and experience with bash, linux/unix, and git Ability to refine requirements from ambiguous requests to produce reports demonstrating excellence in communication Bachelorâ€™s degree in a quantitative discipline (statistics, biostatistics, data science, computer science, or a related field) Preferred Masterâ€™s degree in a quantitative discipline Prior industry experience or displayed interest in finance, such as related academic projects, coursework in financial engineering, or industry internships Experience developing in a production-facing environment and familiarity with standard concepts and tooling, e.g., CI/CD, git, Airflow Compensation The base salary range for this position is $150,000 to $190,000 in the location(s) of this posting. Individual salaries are determined through a variety of factors, including, but not limited to, education, experience, knowledge, skills, and geography. Base salary does not include other forms of total compensation, such as bonus compensation and other benefits. Our benefits package includes medical, dental, and vision coverage, life and AD&D insurance, 20 days of paid time off, 9 sick days, and a 401(k) plan with a company match. â€œFriends of Voleonâ€ Candidate Referral Program If you have a great candidate in mind for this role and would like to have the potential to earn $7,500 if your referred candidate is successfully hired and employed by The Voleon Group, please use this form to submit your referral. For more details regarding eligibility, terms, and conditions, please make sure to review the Voleon Referral Bonus Program . Equal Opportunity Employer The Voleon Group is an Equal Opportunity employer. Applicants are considered without regard to race, color, religion, creed, national origin, age, sex, gender, marital status, sexual orientation and identity, genetic information, veteran status, citizenship, or any other factors prohibited by local, state, or federal law. #LI-MD1 We may use artificial intelligence (AI) tools to support parts of the hiring process. These tools assist our recruitment team but do not replace human judgement. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us. Apply for this job The Voleon Group Home Page Jobs powered by",2025-12-07,1.0,,1+ years,Staff,staff,SQL; Machine Learning
5d88424a-8904-47b7-98e8-092fdbe056d7,Data Engineer,Janestreet,Job Application for Data Engineer at Jane Street,https://boards.greenhouse.io/janestreet/jobs/6558007002,boards.greenhouse.io,"Job Application for Data Engineer at Jane Street Data Engineer New York, New York, United States Apply About the Position We are looking for a Data Engineer who can help us understand, clean, manage, and share the data that guides our trading. At Jane Street, having a thorough and accurate understanding of data is at the core of the work we do. Using our mix of in-house and open-source software, you will analyze datasets gathered from a variety of sources, checking for anomalies, matching formats and symbologies, automating ETL processes, and generally making it easier for our traders to generate valuable insights. You should be excited about digging deep into datasets and explaining your findings to different types of colleagues, working collaboratively with traders and software engineers. While prior experience with financial data would be nice, we donâ€™t expect you to have a finance background. Weâ€™re happy to hire talented engineers and teach them what they need to know. About You Top-notch programming skills in any language (Python a plus) Experience with using SQL and relational databases Experience with generating data visualizations Meticulous approach to data quality and validation Clear and concise communication skills; able to efficiently analyze and deconstruct technical problems If you're a recruiting agency and want to partner with us, please reach out to agency-partnerships@janestreet.com . Apply for this job * indicates a required field First Name * Last Name * Email * Phone Country Phone Resume/CV * Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf Cover Letter Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf Additional information (for source) Have you interviewed with Jane Street before? * Select... Pronouns Are you currently a student? * Select... Enter your college/university Candidate: college/university Major/Field of study Year you expect to complete your education Select... What is your off-cycle availability? Extra Why youâ€™re interested in Jane Street How you heard about us If you have a job now, why youâ€™re looking for a new one Year you expect to begin full time employment Current degree end date Current degree start date Who is your current employer/position? What is your current education level? Select... LinkedIn profile Website UID How did you hear about us? * Select... Area of Study Select... Languages Spoken Spanish Portuguese French Italian German Japanese Korean Bahasa Indonesian Mandarin Hindi Other Additional Information For Languages What year did you graduate high school? Submit application Powered by Greenhouse",2025-12-07,1.0,1.0,one Year,Unspecified,,Python; SQL
cacf5843-665e-416a-b08f-0479a5e9b042,Data Engineer,Beghouconsulting,Beghou Consulting - Data Engineer,https://jobs.lever.co/beghouconsulting/d2115694-9fd4-4cd7-87c0-c909e5855bc9,jobs.lever.co,"Beghou Consulting - Data Engineer Data Engineer Hyderabad, Telangana Consulting Support â€“ Software Development / Full-time / Hybrid Apply for this job Beghou brings over three decades of experience helping life sciences companies optimize their commercialization through strategic insight, advanced analytics, and technology. From developing go-to-market strategies and building foundational data analytics infrastructures to leveraging artificial intelligence to improve customer insights and engagement, Beghou helps life sciences companies maximize performance across their portfolios. Beghou also deploys proprietary and third-party technology solutions to help companies forecast performance, design territories, manage customer data, organize, and report on medical and commercial data, and more. Headquartered in Evanston, Illinois, we have 10 global offices. Our mission is to bring together analytical minds and innovative technology to help life sciences companies navigate the complexity of health care and improve patient outcomes. This position builds front-end and back-end infrastructure for the firmâ€™s in-house enterprise data platform as well as explores, enables, and documents new technologies. This position also works independently to support client teams with different data needs, including deployment for new clients, support for existing clients, development of backend datasets for dashboards, and support for the front-end. We'll trust you to: Ensures reliability and stability of the enterprise data platform and tools used by internal teams and clients. Demonstrates knowledge of the data platform components (warehouse, monitoring, language, etc.) and data engineering (ETL design, schema design, etc.) and performs unit testing. Builds and enhances data integration, management, and analytics tools and pipelines. Documents code, deployments, best practices, and improvements. Designs and builds ETL/ELT data systems, including cloud-based APIs, automated data transfer systems, and code management solutions. Acts as a regular point of contact for data engineering projects and collaborates with the internal consulting team and the data platform and technology teams to complete projects for clients. Participates in and contributes ideas to brainstorm, design, and implement more complex processes and analyses to solve challenging and abstract problems. Develops and implements best practice guidance and supporting materials for data management and advanced analytics pipelines. Creates high-quality presentations, deliverables, and code that meet objectives, with project manager guidance. Performs other job-related duties as assigned. You'll need to have: At least 5 yearsâ€™ experience in data engineering using Python, including the use of pandas or PySpark. Experience working with Databricks extensively (including installing packages, understanding and setting cluster configurations, managing jobs, user management, handling permissions, managing Unity Catalogues, Databricks APIs and AI tools, and handling configuration issues) and relational database technologies, such as PostgreSQL, Oracle, MySQL, Redshift, Snowflake. Software development fundamentals, including Agile development, version control systems such as Git or DevOps, code reviews, testing, and documentation. Experience configuring Azure AD/SAML/Okta/Oath and administering AWS or Azure security best practices, preferred. Experience with WYSIWYG ETL tools (Azure Data Factory, Informatica, Snap Logic, Boomi), preferred. Container orchestration systems experience using Docker, Kubernetes, AWS ECS, preferred. At least 6 months of experience in web application development using Flask, Django, JavaScript, Ajax, or CSS/HTML is preferred. Candidates holding a recognized data engineering certification are preferred (e.g., Databricks Data Engineer, Google Cloud Professional Data Engineer, Azure Data/Fabric Data Engineer, AWS Certified Data Engineer). Proficiency using Microsoft Office products, including Excel, PowerPoint, and Word. Life Sciences industry experience, preferred. Experience: 5 - 7 years At Beghou Consulting, you'll join a highly collaborative, values-driven team where technical excellence, analytical rigor, and personal growth converge. Whether you're passionate about AI innovation, building commercialization strategies, or shaping the next generation of data-first solutions in life sciences, this is a place to make an impact! We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us. Apply for this job Beghou Consulting Home Page Jobs powered by",2025-12-07,5.0,7.0,5 - 7 years,Unspecified,,Python; Cloud Platforms; Databases
a2a5d1f6-1c45-40d1-8833-9e56c529e64f,Data Engineer,Peerspace,Peerspace - Staff Data Engineer,https://jobs.lever.co/peerspace/1d2ff648-1497-453f-9337-885fc6306f02,jobs.lever.co,"Peerspace - Staff Data Engineer Staff Data Engineer United States Engineering / Full-time / Remote Apply for this job Staff Data Engineer About Peerspace Peerspace is the leading and category defining online marketplace for venue rentals for meetings, productions, and events. We open doors to the most inspiring spaces around the world, from lofts and mansions to storefronts and studios. Over $500M has been transacted through the platform, and our investors include GV (Google Ventures) and Foundation Capital. Role Overview As a Staff Data Engineer, you will serve as a technical leader and a key enabling function across the entire Engineering organization. You will be responsible for shaping the future of Peerspace's data platform, ensuring its scalability, reliability, and ability to meet the complex demands of a growing business. Beyond individual projects, you will focus on setting technical direction, establishing best practices, and mentoring engineers on both the data team and other product teams. Your role is to be a force multiplier, improving the data literacy and technical capabilities of the organization as a whole through architectural leadership and cross-functional influence. Qualifications: You are a great fit for this role if you have: â— Experience: 8-12+ years in data engineering or software engineering, with significant experience in technical leadership and architectural design for data-intensive systems. â— Technical Skills: â—‹ Authoritative expertise in designing and scaling large-scale data platforms on the cloud (GCP/BigQuery preferred). â—‹ Mastery of data modeling and transformation frameworks (e.g., DBT), with a focus on creating systems that are broadly usable and maintainable by many teams. â—‹ Deep architectural knowledge of data collection, event streaming (e.g., Segment), and ETL/ELT patterns at scale. â—‹ Experience evaluating, selecting, and integrating new data technologies to solve major business and technical challenges. â— Technical Leadership & Influence: Demonstrated ability to drive technical decisions across multiple teams, build consensus, and lead large-scale initiatives without direct authority. â— Collaboration: A natural ability to partner with senior leaders in Product, Engineering, and Analytics to translate business needs into a long-term technical strategy. â— Impact: A portfolio of work that demonstrates your ability to solve ambiguous, complex problems that enable entire teams or product areas. You have a reputation for improving engineering velocity and quality. â— Strategic Mindset: An ability to think beyond immediate requirements to build foundational systems that will support the company's long-term goals and future data products. Responsibilities: In this role, you will be responsible for: â— Platform Architecture: Architecting and evolving our core data infrastructure (BigQuery, DBT, Segment) to ensure it is robust, scalable, and serves as a reliable foundation for all data consumers. â— Setting Standards: Defining and evangelizing data engineering best practices, patterns, and tooling for use across the entire Peerspace engineering organization. â— Cross-Functional Leadership: Partnering with other engineering teams to design and implement services that produce clean, well-structured, and reliable data from the source. â— Solving Hard Problems: Tackling the most complex technical challenges within our data ecosystem, such as platform performance bottlenecks, data governance frameworks, or cost optimization strategies. â— Mentorship & Evangelism: Acting as a senior mentor and technical resource for engineers across the company, elevating the organization's collective data expertise through workshops, design documents, and 1:1 guidance. Why Peerspace? Peerspace is proudly certified as a Great Place to Workâ„¢ and we're a remote first company with team members located in cities around the globe. Beyond competitive salary and equity compensation, we provide: â— 100% employee coverage of medical, dental and vision insurance â— $500 annual professional development allowance â— Discount on all Peerspace bookings â— Laptop, high res display, and stipend to setup home office â— Monthly cell phone and internet credit â— Coworking membership if needed (in lieu of home office) â— Flexible take it as you need it time off policy â— Wellness Days observed company wide â— Annual in-person, all company offsites and team-building events The annual salary range for this role is $170,000 to $185,000. The actual salary will vary depending on experience, skills, and abilities as well as internal equity and market data. Diversity At Peerspace, we're dedicated to creating a team that's diverse, equitable and inclusive. We believe bringing people together from different backgrounds and identities makes us stronger and better serves the Peerspace community. We'd especially like to encourage applicants from different backgrounds, locations, and experiences. At Peerspace, we are committed to maintaining a",2025-12-07,8.0,12.0,8-12+ years,Staff,staff,Cloud Platforms; Distributed Systems
8bd97f23-a26e-45a1-94c3-e4045bfc3268,Data Engineer,Janestreet,Job Application for Data Engineer at Jane Street,https://boards.greenhouse.io/janestreet/jobs/6558007002,boards.greenhouse.io,"Job Application for Data Engineer at Jane Street Data Engineer New York, New York, United States Apply About the Position We are looking for a Data Engineer who can help us understand, clean, manage, and share the data that guides our trading. At Jane Street, having a thorough and accurate understanding of data is at the core of the work we do. Using our mix of in-house and open-source software, you will analyze datasets gathered from a variety of sources, checking for anomalies, matching formats and symbologies, automating ETL processes, and generally making it easier for our traders to generate valuable insights. You should be excited about digging deep into datasets and explaining your findings to different types of colleagues, working collaboratively with traders and software engineers. While prior experience with financial data would be nice, we donâ€™t expect you to have a finance background. Weâ€™re happy to hire talented engineers and teach them what they need to know. About You Top-notch programming skills in any language (Python a plus) Experience with using SQL and relational databases Experience with generating data visualizations Meticulous approach to data quality and validation Clear and concise communication skills; able to efficiently analyze and deconstruct technical problems If you're a recruiting agency and want to partner with us, please reach out to agency-partnerships@janestreet.com . Apply for this job * indicates a required field First Name * Last Name * Email * Phone Country Phone Resume/CV * Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf Cover Letter Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf Additional information (for source) Have you interviewed with Jane Street before? * Select... Pronouns Are you currently a student? * Select... Enter your college/university Candidate: college/university Major/Field of study Year you expect to complete your education Select... What is your off-cycle availability? Extra Why youâ€™re interested in Jane Street How you heard about us If you have a job now, why youâ€™re looking for a new one Year you expect to begin full time employment Current degree end date Current degree start date Who is your current employer/position? What is your current education level? Select... LinkedIn profile Website UID How did you hear about us? * Select... Area of Study Select... Languages Spoken Spanish Portuguese French Italian German Japanese Korean Bahasa Indonesian Mandarin Hindi Other Additional Information For Languages What year did you graduate high school? Submit application Powered by Greenhouse",2025-12-07,1.0,1.0,one Year,Unspecified,,Python; SQL
0b0b5ad3-3932-489d-b5b9-82d30af01c2c,Data Engineer,Beghouconsulting,Beghou Consulting - Data Engineer,https://jobs.lever.co/beghouconsulting/d2115694-9fd4-4cd7-87c0-c909e5855bc9,jobs.lever.co,"Beghou Consulting - Data Engineer Data Engineer Hyderabad, Telangana Consulting Support â€“ Software Development / Full-time / Hybrid Apply for this job Beghou brings over three decades of experience helping life sciences companies optimize their commercialization through strategic insight, advanced analytics, and technology. From developing go-to-market strategies and building foundational data analytics infrastructures to leveraging artificial intelligence to improve customer insights and engagement, Beghou helps life sciences companies maximize performance across their portfolios. Beghou also deploys proprietary and third-party technology solutions to help companies forecast performance, design territories, manage customer data, organize, and report on medical and commercial data, and more. Headquartered in Evanston, Illinois, we have 10 global offices. Our mission is to bring together analytical minds and innovative technology to help life sciences companies navigate the complexity of health care and improve patient outcomes. This position builds front-end and back-end infrastructure for the firmâ€™s in-house enterprise data platform as well as explores, enables, and documents new technologies. This position also works independently to support client teams with different data needs, including deployment for new clients, support for existing clients, development of backend datasets for dashboards, and support for the front-end. We'll trust you to: Ensures reliability and stability of the enterprise data platform and tools used by internal teams and clients. Demonstrates knowledge of the data platform components (warehouse, monitoring, language, etc.) and data engineering (ETL design, schema design, etc.) and performs unit testing. Builds and enhances data integration, management, and analytics tools and pipelines. Documents code, deployments, best practices, and improvements. Designs and builds ETL/ELT data systems, including cloud-based APIs, automated data transfer systems, and code management solutions. Acts as a regular point of contact for data engineering projects and collaborates with the internal consulting team and the data platform and technology teams to complete projects for clients. Participates in and contributes ideas to brainstorm, design, and implement more complex processes and analyses to solve challenging and abstract problems. Develops and implements best practice guidance and supporting materials for data management and advanced analytics pipelines. Creates high-quality presentations, deliverables, and code that meet objectives, with project manager guidance. Performs other job-related duties as assigned. You'll need to have: At least 5 yearsâ€™ experience in data engineering using Python, including the use of pandas or PySpark. Experience working with Databricks extensively (including installing packages, understanding and setting cluster configurations, managing jobs, user management, handling permissions, managing Unity Catalogues, Databricks APIs and AI tools, and handling configuration issues) and relational database technologies, such as PostgreSQL, Oracle, MySQL, Redshift, Snowflake. Software development fundamentals, including Agile development, version control systems such as Git or DevOps, code reviews, testing, and documentation. Experience configuring Azure AD/SAML/Okta/Oath and administering AWS or Azure security best practices, preferred. Experience with WYSIWYG ETL tools (Azure Data Factory, Informatica, Snap Logic, Boomi), preferred. Container orchestration systems experience using Docker, Kubernetes, AWS ECS, preferred. At least 6 months of experience in web application development using Flask, Django, JavaScript, Ajax, or CSS/HTML is preferred. Candidates holding a recognized data engineering certification are preferred (e.g., Databricks Data Engineer, Google Cloud Professional Data Engineer, Azure Data/Fabric Data Engineer, AWS Certified Data Engineer). Proficiency using Microsoft Office products, including Excel, PowerPoint, and Word. Life Sciences industry experience, preferred. Experience: 5 - 7 years At Beghou Consulting, you'll join a highly collaborative, values-driven team where technical excellence, analytical rigor, and personal growth converge. Whether you're passionate about AI innovation, building commercialization strategies, or shaping the next generation of data-first solutions in life sciences, this is a place to make an impact! We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us. Apply for this job Beghou Consulting Home Page Jobs powered by",2025-12-07,5.0,7.0,5 - 7 years,Unspecified,,Python; Cloud Platforms; Databases
6cc43a86-3308-4655-a819-b91fe8c35e19,Data Engineer,Peerspace,Peerspace - Staff Data Engineer,https://jobs.lever.co/peerspace/1d2ff648-1497-453f-9337-885fc6306f02,jobs.lever.co,"Peerspace - Staff Data Engineer Staff Data Engineer United States Engineering / Full-time / Remote Apply for this job Staff Data Engineer About Peerspace Peerspace is the leading and category defining online marketplace for venue rentals for meetings, productions, and events. We open doors to the most inspiring spaces around the world, from lofts and mansions to storefronts and studios. Over $500M has been transacted through the platform, and our investors include GV (Google Ventures) and Foundation Capital. Role Overview As a Staff Data Engineer, you will serve as a technical leader and a key enabling function across the entire Engineering organization. You will be responsible for shaping the future of Peerspace's data platform, ensuring its scalability, reliability, and ability to meet the complex demands of a growing business. Beyond individual projects, you will focus on setting technical direction, establishing best practices, and mentoring engineers on both the data team and other product teams. Your role is to be a force multiplier, improving the data literacy and technical capabilities of the organization as a whole through architectural leadership and cross-functional influence. Qualifications: You are a great fit for this role if you have: â— Experience: 8-12+ years in data engineering or software engineering, with significant experience in technical leadership and architectural design for data-intensive systems. â— Technical Skills: â—‹ Authoritative expertise in designing and scaling large-scale data platforms on the cloud (GCP/BigQuery preferred). â—‹ Mastery of data modeling and transformation frameworks (e.g., DBT), with a focus on creating systems that are broadly usable and maintainable by many teams. â—‹ Deep architectural knowledge of data collection, event streaming (e.g., Segment), and ETL/ELT patterns at scale. â—‹ Experience evaluating, selecting, and integrating new data technologies to solve major business and technical challenges. â— Technical Leadership & Influence: Demonstrated ability to drive technical decisions across multiple teams, build consensus, and lead large-scale initiatives without direct authority. â— Collaboration: A natural ability to partner with senior leaders in Product, Engineering, and Analytics to translate business needs into a long-term technical strategy. â— Impact: A portfolio of work that demonstrates your ability to solve ambiguous, complex problems that enable entire teams or product areas. You have a reputation for improving engineering velocity and quality. â— Strategic Mindset: An ability to think beyond immediate requirements to build foundational systems that will support the company's long-term goals and future data products. Responsibilities: In this role, you will be responsible for: â— Platform Architecture: Architecting and evolving our core data infrastructure (BigQuery, DBT, Segment) to ensure it is robust, scalable, and serves as a reliable foundation for all data consumers. â— Setting Standards: Defining and evangelizing data engineering best practices, patterns, and tooling for use across the entire Peerspace engineering organization. â— Cross-Functional Leadership: Partnering with other engineering teams to design and implement services that produce clean, well-structured, and reliable data from the source. â— Solving Hard Problems: Tackling the most complex technical challenges within our data ecosystem, such as platform performance bottlenecks, data governance frameworks, or cost optimization strategies. â— Mentorship & Evangelism: Acting as a senior mentor and technical resource for engineers across the company, elevating the organization's collective data expertise through workshops, design documents, and 1:1 guidance. Why Peerspace? Peerspace is proudly certified as a Great Place to Workâ„¢ and we're a remote first company with team members located in cities around the globe. Beyond competitive salary and equity compensation, we provide: â— 100% employee coverage of medical, dental and vision insurance â— $500 annual professional development allowance â— Discount on all Peerspace bookings â— Laptop, high res display, and stipend to setup home office â— Monthly cell phone and internet credit â— Coworking membership if needed (in lieu of home office) â— Flexible take it as you need it time off policy â— Wellness Days observed company wide â— Annual in-person, all company offsites and team-building events The annual salary range for this role is $170,000 to $185,000. The actual salary will vary depending on experience, skills, and abilities as well as internal equity and market data. Diversity At Peerspace, we're dedicated to creating a team that's diverse, equitable and inclusive. We believe bringing people together from different backgrounds and identities makes us stronger and better serves the Peerspace community. We'd especially like to encourage applicants from different backgrounds, locations, and experiences. At Peerspace, we are committed to maintaining a",2025-12-07,8.0,12.0,8-12+ years,Staff,staff,Cloud Platforms; Distributed Systems
1b367e88-00f6-483b-b9fb-021edbfd0551,Data Engineer,Janestreet,Job Application for Data Engineer at Jane Street,https://boards.greenhouse.io/janestreet/jobs/6558007002,boards.greenhouse.io,"Job Application for Data Engineer at Jane Street Data Engineer New York, New York, United States Apply About the Position We are looking for a Data Engineer who can help us understand, clean, manage, and share the data that guides our trading. At Jane Street, having a thorough and accurate understanding of data is at the core of the work we do. Using our mix of in-house and open-source software, you will analyze datasets gathered from a variety of sources, checking for anomalies, matching formats and symbologies, automating ETL processes, and generally making it easier for our traders to generate valuable insights. You should be excited about digging deep into datasets and explaining your findings to different types of colleagues, working collaboratively with traders and software engineers. While prior experience with financial data would be nice, we donâ€™t expect you to have a finance background. Weâ€™re happy to hire talented engineers and teach them what they need to know. About You Top-notch programming skills in any language (Python a plus) Experience with using SQL and relational databases Experience with generating data visualizations Meticulous approach to data quality and validation Clear and concise communication skills; able to efficiently analyze and deconstruct technical problems If you're a recruiting agency and want to partner with us, please reach out to agency-partnerships@janestreet.com . Apply for this job * indicates a required field First Name * Last Name * Email * Phone Country Phone Resume/CV * Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf Cover Letter Attach Attach Dropbox Google Drive Enter manually Enter manually Accepted file types: pdf, doc, docx, txt, rtf Additional information (for source) Have you interviewed with Jane Street before? * Select... Pronouns Are you currently a student? * Select... Enter your college/university Candidate: college/university Major/Field of study Year you expect to complete your education Select... What is your off-cycle availability? Extra Why youâ€™re interested in Jane Street How you heard about us If you have a job now, why youâ€™re looking for a new one Year you expect to begin full time employment Current degree end date Current degree start date Who is your current employer/position? What is your current education level? Select... LinkedIn profile Website UID How did you hear about us? * Select... Area of Study Select... Languages Spoken Spanish Portuguese French Italian German Japanese Korean Bahasa Indonesian Mandarin Hindi Other Additional Information For Languages What year did you graduate high school? Submit application Powered by Greenhouse",2025-12-07,1.0,1.0,one Year,Unspecified,,Python; SQL
3fb557af-baf2-4c9a-aba1-c4b2a706e0c7,Data Engineer,Peerspace,Peerspace - Staff Data Engineer,https://jobs.lever.co/peerspace/1d2ff648-1497-453f-9337-885fc6306f02,jobs.lever.co,"Peerspace - Staff Data Engineer Staff Data Engineer United States Engineering / Full-time / Remote Apply for this job Staff Data Engineer About Peerspace Peerspace is the leading and category defining online marketplace for venue rentals for meetings, productions, and events. We open doors to the most inspiring spaces around the world, from lofts and mansions to storefronts and studios. Over $500M has been transacted through the platform, and our investors include GV (Google Ventures) and Foundation Capital. Role Overview As a Staff Data Engineer, you will serve as a technical leader and a key enabling function across the entire Engineering organization. You will be responsible for shaping the future of Peerspace's data platform, ensuring its scalability, reliability, and ability to meet the complex demands of a growing business. Beyond individual projects, you will focus on setting technical direction, establishing best practices, and mentoring engineers on both the data team and other product teams. Your role is to be a force multiplier, improving the data literacy and technical capabilities of the organization as a whole through architectural leadership and cross-functional influence. Qualifications: You are a great fit for this role if you have: â— Experience: 8-12+ years in data engineering or software engineering, with significant experience in technical leadership and architectural design for data-intensive systems. â— Technical Skills: â—‹ Authoritative expertise in designing and scaling large-scale data platforms on the cloud (GCP/BigQuery preferred). â—‹ Mastery of data modeling and transformation frameworks (e.g., DBT), with a focus on creating systems that are broadly usable and maintainable by many teams. â—‹ Deep architectural knowledge of data collection, event streaming (e.g., Segment), and ETL/ELT patterns at scale. â—‹ Experience evaluating, selecting, and integrating new data technologies to solve major business and technical challenges. â— Technical Leadership & Influence: Demonstrated ability to drive technical decisions across multiple teams, build consensus, and lead large-scale initiatives without direct authority. â— Collaboration: A natural ability to partner with senior leaders in Product, Engineering, and Analytics to translate business needs into a long-term technical strategy. â— Impact: A portfolio of work that demonstrates your ability to solve ambiguous, complex problems that enable entire teams or product areas. You have a reputation for improving engineering velocity and quality. â— Strategic Mindset: An ability to think beyond immediate requirements to build foundational systems that will support the company's long-term goals and future data products. Responsibilities: In this role, you will be responsible for: â— Platform Architecture: Architecting and evolving our core data infrastructure (BigQuery, DBT, Segment) to ensure it is robust, scalable, and serves as a reliable foundation for all data consumers. â— Setting Standards: Defining and evangelizing data engineering best practices, patterns, and tooling for use across the entire Peerspace engineering organization. â— Cross-Functional Leadership: Partnering with other engineering teams to design and implement services that produce clean, well-structured, and reliable data from the source. â— Solving Hard Problems: Tackling the most complex technical challenges within our data ecosystem, such as platform performance bottlenecks, data governance frameworks, or cost optimization strategies. â— Mentorship & Evangelism: Acting as a senior mentor and technical resource for engineers across the company, elevating the organization's collective data expertise through workshops, design documents, and 1:1 guidance. Why Peerspace? Peerspace is proudly certified as a Great Place to Workâ„¢ and we're a remote first company with team members located in cities around the globe. Beyond competitive salary and equity compensation, we provide: â— 100% employee coverage of medical, dental and vision insurance â— $500 annual professional development allowance â— Discount on all Peerspace bookings â— Laptop, high res display, and stipend to setup home office â— Monthly cell phone and internet credit â— Coworking membership if needed (in lieu of home office) â— Flexible take it as you need it time off policy â— Wellness Days observed company wide â— Annual in-person, all company offsites and team-building events The annual salary range for this role is $170,000 to $185,000. The actual salary will vary depending on experience, skills, and abilities as well as internal equity and market data. Diversity At Peerspace, we're dedicated to creating a team that's diverse, equitable and inclusive. We believe bringing people together from different backgrounds and identities makes us stronger and better serves the Peerspace community. We'd especially like to encourage applicants from different backgrounds, locations, and experiences. At Peerspace, we are committed to maintaining a",2025-12-07,8.0,12.0,8-12+ years,Staff,staff,Cloud Platforms; Distributed Systems
ee374e15-5f2e-447d-822e-f18d59f22665,Data Engineer,Beghouconsulting,Beghou Consulting - Data Engineer,https://jobs.lever.co/beghouconsulting/d2115694-9fd4-4cd7-87c0-c909e5855bc9,jobs.lever.co,"Beghou Consulting - Data Engineer Data Engineer Hyderabad, Telangana Consulting Support â€“ Software Development / Full-time / Hybrid Apply for this job Beghou brings over three decades of experience helping life sciences companies optimize their commercialization through strategic insight, advanced analytics, and technology. From developing go-to-market strategies and building foundational data analytics infrastructures to leveraging artificial intelligence to improve customer insights and engagement, Beghou helps life sciences companies maximize performance across their portfolios. Beghou also deploys proprietary and third-party technology solutions to help companies forecast performance, design territories, manage customer data, organize, and report on medical and commercial data, and more. Headquartered in Evanston, Illinois, we have 10 global offices. Our mission is to bring together analytical minds and innovative technology to help life sciences companies navigate the complexity of health care and improve patient outcomes. This position builds front-end and back-end infrastructure for the firmâ€™s in-house enterprise data platform as well as explores, enables, and documents new technologies. This position also works independently to support client teams with different data needs, including deployment for new clients, support for existing clients, development of backend datasets for dashboards, and support for the front-end. We'll trust you to: Ensures reliability and stability of the enterprise data platform and tools used by internal teams and clients. Demonstrates knowledge of the data platform components (warehouse, monitoring, language, etc.) and data engineering (ETL design, schema design, etc.) and performs unit testing. Builds and enhances data integration, management, and analytics tools and pipelines. Documents code, deployments, best practices, and improvements. Designs and builds ETL/ELT data systems, including cloud-based APIs, automated data transfer systems, and code management solutions. Acts as a regular point of contact for data engineering projects and collaborates with the internal consulting team and the data platform and technology teams to complete projects for clients. Participates in and contributes ideas to brainstorm, design, and implement more complex processes and analyses to solve challenging and abstract problems. Develops and implements best practice guidance and supporting materials for data management and advanced analytics pipelines. Creates high-quality presentations, deliverables, and code that meet objectives, with project manager guidance. Performs other job-related duties as assigned. You'll need to have: At least 5 yearsâ€™ experience in data engineering using Python, including the use of pandas or PySpark. Experience working with Databricks extensively (including installing packages, understanding and setting cluster configurations, managing jobs, user management, handling permissions, managing Unity Catalogues, Databricks APIs and AI tools, and handling configuration issues) and relational database technologies, such as PostgreSQL, Oracle, MySQL, Redshift, Snowflake. Software development fundamentals, including Agile development, version control systems such as Git or DevOps, code reviews, testing, and documentation. Experience configuring Azure AD/SAML/Okta/Oath and administering AWS or Azure security best practices, preferred. Experience with WYSIWYG ETL tools (Azure Data Factory, Informatica, Snap Logic, Boomi), preferred. Container orchestration systems experience using Docker, Kubernetes, AWS ECS, preferred. At least 6 months of experience in web application development using Flask, Django, JavaScript, Ajax, or CSS/HTML is preferred. Candidates holding a recognized data engineering certification are preferred (e.g., Databricks Data Engineer, Google Cloud Professional Data Engineer, Azure Data/Fabric Data Engineer, AWS Certified Data Engineer). Proficiency using Microsoft Office products, including Excel, PowerPoint, and Word. Life Sciences industry experience, preferred. Experience: 5 - 7 years At Beghou Consulting, you'll join a highly collaborative, values-driven team where technical excellence, analytical rigor, and personal growth converge. Whether you're passionate about AI innovation, building commercialization strategies, or shaping the next generation of data-first solutions in life sciences, this is a place to make an impact! We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us. Apply for this job Beghou Consulting Home Page Jobs powered by",2025-12-07,5.0,7.0,5 - 7 years,Unspecified,,Python; Cloud Platforms; Databases
467893ff-5eb6-49f2-bb19-10b07b0c3f3b,Cloud Engineer,Talentwerx.Io,EXPANSIA - E01 Cloud Engineer III,https://jobs.lever.co/talentwerx.io/c0de2135-e41a-4661-8d09-c9efa4122270,jobs.lever.co,"EXPANSIA - E01 Cloud Engineer III E01 Cloud Engineer III Dayton, OH EXPANSIA â€“ EXPANSIA / Full Time / On-site Apply for this job Start Date: Immediate EXPANSIA is a service-disabled veteran-owned company that empowers organizations to be mission ready now with data, people, and ecosystems. As experts in continuous-delivery methods that drive digital adoption, we are dedicated to innovation, efficiency, and technology that benefit the warfighter. EXPANSIA specializes in integration, automation, and sustainment modernization through technology-enabled delivery models, digital engineering, and cloud-ready solutions. OVERVIEW Full-time/Permanent Employee Location: Dayton, OH We are seeking a skilled and experienced Cloud Engineer III to join our team and support the development, implementation, and maintenance of cloud-based solutions for government clients. As a Cloud Engineer III, you will assess cloud infrastructure and cloud service needs for an Integrated Digital Environment (IDE), assist in assessing the integration of existing custom IDEâ€™s implemented on Amazon Web Services and Azure throughout the U.S. militaryâ€™s mission systems environments, and assist with the implementation of the IDE, which will the deployment and configuration of COTS and GOTS applications, network connectivity and identity federation across military systems. You will automate build pipelines, migrations, security, and compliance while managing cloud networking, utilizing Ansible and similar tools for automation. Responsibilities include implementing and maintaining cloud infrastructure, performing administrative tasks, and providing deployment support. You will enhance security by applying patches, conducting security reviews, and managing access controls while implementing enterprise monitoring solutions using industry-standard tools. Additionally, you will document processes, identify automation opportunities, and develop scalable monitoring solutions, dashboards, and alerts to align with business and IT objectives. The proposed salary range for this position is $109,837-$138,000. There are a host of factors that can influence final salary including, but not limited to, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, geographic location, education, and certifications. Our employees value the flexibility EXPANSIA allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our unique mix of benefits options is designed to support and protect employees and their families. Employment benefits include health and wellness programs, income protection, paid leave and retirement and savings. RESPONSIBILITIES Design, implement, and manage cloud infrastructure in Amazon Web Services Automate cloud provisioning, configuration management, and deployments using tools like Terraform, Ansible, or CloudFormation. Work with application SMEâ€™s to optimize cloud-native services for scalability and performance. Collaborate with security teams to implement security best practices, including encryption, access controls, and compliance. Monitor cloud resources, ensuring optimal performance and cost efficiency. Troubleshoot and resolve cloud-related issues in production environments. Participate in designing and implementing disaster recovery and backup solutions. Stay up to date with the latest cloud technologies, trends, and best practices. KEY QUALIFICATIONS Clearance: Active TS/SCI Education and Years of Experience: Bachelorâ€™s degree with 5â€“7 years of experience, or a Masterâ€™s degree with 3â€“5 years of experience in cloud engineering, cloud infrastructure, or a similar role. Hands-on experience with Amazon Web Services and Microsoft Azure Proficiency in Infrastructure-as-Code (IaC) tools such as Terraform, Ansible, or AWS CloudFormation. Experience with containerization technologies like Docker and Kubernetes. Familiarity with CI/CD tools like Jenkins, GitLab, or AWS CodePipeline and AWS CodeDeploy Strong understanding of cloud networking, storage, and compute services. Experience with cloud security practices and tools, such as IAM, VPC, encryption, and firewalls. Proficient in scripting languages such as Python, Shell, or PowerShell. Familiarity with monitoring and logging tools like Prometheus, Grafana, or CloudWatch. Strong problem-solving and troubleshooting skills. Excellent communication and collaboration skills. Familiarity with Agile Scrum or Kanban development practices in Jira, Agility or similar tool. Security+ CE, CySA+, CCNA Security, CND, GICSP, GSEC or SSCP PREFERRED ADDITIONAL QUALIFICATIONS Experience with AWS GovCloud, Cloud One and similar government cloud solutions Familiarity with applying DISA, FISMA, NIST, CIS and ISO standards to cloud environments Cloud certifications (AWS Certified DevOps Engineer, AWS Certified Solutions Architect, etc.). Knowledge ",2025-12-07,5.0,7.0,5â€“7 years,Unspecified,,Cloud Platforms; Docker; Kubernetes; CI/CD; Distributed Systems
8c1547c0-9bc5-4901-b7aa-474e5324382b,Cloud Engineer,Talentwerx.Io,EXPANSIA - E01 Cloud Engineer III,https://jobs.lever.co/talentwerx.io/c0de2135-e41a-4661-8d09-c9efa4122270,jobs.lever.co,"EXPANSIA - E01 Cloud Engineer III E01 Cloud Engineer III Dayton, OH EXPANSIA â€“ EXPANSIA / Full Time / On-site Apply for this job Start Date: Immediate EXPANSIA is a service-disabled veteran-owned company that empowers organizations to be mission ready now with data, people, and ecosystems. As experts in continuous-delivery methods that drive digital adoption, we are dedicated to innovation, efficiency, and technology that benefit the warfighter. EXPANSIA specializes in integration, automation, and sustainment modernization through technology-enabled delivery models, digital engineering, and cloud-ready solutions. OVERVIEW Full-time/Permanent Employee Location: Dayton, OH We are seeking a skilled and experienced Cloud Engineer III to join our team and support the development, implementation, and maintenance of cloud-based solutions for government clients. As a Cloud Engineer III, you will assess cloud infrastructure and cloud service needs for an Integrated Digital Environment (IDE), assist in assessing the integration of existing custom IDEâ€™s implemented on Amazon Web Services and Azure throughout the U.S. militaryâ€™s mission systems environments, and assist with the implementation of the IDE, which will the deployment and configuration of COTS and GOTS applications, network connectivity and identity federation across military systems. You will automate build pipelines, migrations, security, and compliance while managing cloud networking, utilizing Ansible and similar tools for automation. Responsibilities include implementing and maintaining cloud infrastructure, performing administrative tasks, and providing deployment support. You will enhance security by applying patches, conducting security reviews, and managing access controls while implementing enterprise monitoring solutions using industry-standard tools. Additionally, you will document processes, identify automation opportunities, and develop scalable monitoring solutions, dashboards, and alerts to align with business and IT objectives. The proposed salary range for this position is $109,837-$138,000. There are a host of factors that can influence final salary including, but not limited to, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, geographic location, education, and certifications. Our employees value the flexibility EXPANSIA allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our unique mix of benefits options is designed to support and protect employees and their families. Employment benefits include health and wellness programs, income protection, paid leave and retirement and savings. RESPONSIBILITIES Design, implement, and manage cloud infrastructure in Amazon Web Services Automate cloud provisioning, configuration management, and deployments using tools like Terraform, Ansible, or CloudFormation. Work with application SMEâ€™s to optimize cloud-native services for scalability and performance. Collaborate with security teams to implement security best practices, including encryption, access controls, and compliance. Monitor cloud resources, ensuring optimal performance and cost efficiency. Troubleshoot and resolve cloud-related issues in production environments. Participate in designing and implementing disaster recovery and backup solutions. Stay up to date with the latest cloud technologies, trends, and best practices. KEY QUALIFICATIONS Clearance: Active TS/SCI Education and Years of Experience: Bachelorâ€™s degree with 5â€“7 years of experience, or a Masterâ€™s degree with 3â€“5 years of experience in cloud engineering, cloud infrastructure, or a similar role. Hands-on experience with Amazon Web Services and Microsoft Azure Proficiency in Infrastructure-as-Code (IaC) tools such as Terraform, Ansible, or AWS CloudFormation. Experience with containerization technologies like Docker and Kubernetes. Familiarity with CI/CD tools like Jenkins, GitLab, or AWS CodePipeline and AWS CodeDeploy Strong understanding of cloud networking, storage, and compute services. Experience with cloud security practices and tools, such as IAM, VPC, encryption, and firewalls. Proficient in scripting languages such as Python, Shell, or PowerShell. Familiarity with monitoring and logging tools like Prometheus, Grafana, or CloudWatch. Strong problem-solving and troubleshooting skills. Excellent communication and collaboration skills. Familiarity with Agile Scrum or Kanban development practices in Jira, Agility or similar tool. Security+ CE, CySA+, CCNA Security, CND, GICSP, GSEC or SSCP PREFERRED ADDITIONAL QUALIFICATIONS Experience with AWS GovCloud, Cloud One and similar government cloud solutions Familiarity with applying DISA, FISMA, NIST, CIS and ISO standards to cloud environments Cloud certifications (AWS Certified DevOps Engineer, AWS Certified Solutions Architect, etc.). Knowledge ",2025-12-07,5.0,7.0,5â€“7 years,Unspecified,,Cloud Platforms; Docker; Kubernetes; CI/CD; Distributed Systems
581afe5e-50ec-4b69-a2d6-656c58c24851,Cloud Engineer,Talentwerx.Io,EXPANSIA - E01 Cloud Engineer III,https://jobs.lever.co/talentwerx.io/c0de2135-e41a-4661-8d09-c9efa4122270,jobs.lever.co,"EXPANSIA - E01 Cloud Engineer III E01 Cloud Engineer III Dayton, OH EXPANSIA â€“ EXPANSIA / Full Time / On-site Apply for this job Start Date: Immediate EXPANSIA is a service-disabled veteran-owned company that empowers organizations to be mission ready now with data, people, and ecosystems. As experts in continuous-delivery methods that drive digital adoption, we are dedicated to innovation, efficiency, and technology that benefit the warfighter. EXPANSIA specializes in integration, automation, and sustainment modernization through technology-enabled delivery models, digital engineering, and cloud-ready solutions. OVERVIEW Full-time/Permanent Employee Location: Dayton, OH We are seeking a skilled and experienced Cloud Engineer III to join our team and support the development, implementation, and maintenance of cloud-based solutions for government clients. As a Cloud Engineer III, you will assess cloud infrastructure and cloud service needs for an Integrated Digital Environment (IDE), assist in assessing the integration of existing custom IDEâ€™s implemented on Amazon Web Services and Azure throughout the U.S. militaryâ€™s mission systems environments, and assist with the implementation of the IDE, which will the deployment and configuration of COTS and GOTS applications, network connectivity and identity federation across military systems. You will automate build pipelines, migrations, security, and compliance while managing cloud networking, utilizing Ansible and similar tools for automation. Responsibilities include implementing and maintaining cloud infrastructure, performing administrative tasks, and providing deployment support. You will enhance security by applying patches, conducting security reviews, and managing access controls while implementing enterprise monitoring solutions using industry-standard tools. Additionally, you will document processes, identify automation opportunities, and develop scalable monitoring solutions, dashboards, and alerts to align with business and IT objectives. The proposed salary range for this position is $109,837-$138,000. There are a host of factors that can influence final salary including, but not limited to, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, geographic location, education, and certifications. Our employees value the flexibility EXPANSIA allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our unique mix of benefits options is designed to support and protect employees and their families. Employment benefits include health and wellness programs, income protection, paid leave and retirement and savings. RESPONSIBILITIES Design, implement, and manage cloud infrastructure in Amazon Web Services Automate cloud provisioning, configuration management, and deployments using tools like Terraform, Ansible, or CloudFormation. Work with application SMEâ€™s to optimize cloud-native services for scalability and performance. Collaborate with security teams to implement security best practices, including encryption, access controls, and compliance. Monitor cloud resources, ensuring optimal performance and cost efficiency. Troubleshoot and resolve cloud-related issues in production environments. Participate in designing and implementing disaster recovery and backup solutions. Stay up to date with the latest cloud technologies, trends, and best practices. KEY QUALIFICATIONS Clearance: Active TS/SCI Education and Years of Experience: Bachelorâ€™s degree with 5â€“7 years of experience, or a Masterâ€™s degree with 3â€“5 years of experience in cloud engineering, cloud infrastructure, or a similar role. Hands-on experience with Amazon Web Services and Microsoft Azure Proficiency in Infrastructure-as-Code (IaC) tools such as Terraform, Ansible, or AWS CloudFormation. Experience with containerization technologies like Docker and Kubernetes. Familiarity with CI/CD tools like Jenkins, GitLab, or AWS CodePipeline and AWS CodeDeploy Strong understanding of cloud networking, storage, and compute services. Experience with cloud security practices and tools, such as IAM, VPC, encryption, and firewalls. Proficient in scripting languages such as Python, Shell, or PowerShell. Familiarity with monitoring and logging tools like Prometheus, Grafana, or CloudWatch. Strong problem-solving and troubleshooting skills. Excellent communication and collaboration skills. Familiarity with Agile Scrum or Kanban development practices in Jira, Agility or similar tool. Security+ CE, CySA+, CCNA Security, CND, GICSP, GSEC or SSCP PREFERRED ADDITIONAL QUALIFICATIONS Experience with AWS GovCloud, Cloud One and similar government cloud solutions Familiarity with applying DISA, FISMA, NIST, CIS and ISO standards to cloud environments Cloud certifications (AWS Certified DevOps Engineer, AWS Certified Solutions Architect, etc.). Knowledge ",2025-12-07,5.0,7.0,5â€“7 years,Unspecified,,Cloud Platforms; Docker; Kubernetes; CI/CD; Distributed Systems
746f10e6-7d08-433c-bc16-834464a8a615,DevOps Engineer,,"NBCUniversal DevOps Engineer, Playout | SmartRecruiters",https://jobs.smartrecruiters.com/NBCUniversal3/744000096908345-devops-engineer-playout,jobs.smartrecruiters.com,"NBCUniversal DevOps Engineer, Playout | SmartRecruiters Google Chrome Microsoft Edge Apple Safari Mozilla Firefox DevOps Engineer, Playout Full-time Business Segment: Operations & Technology Compensation: USD 90000 - USD 110000 - yearly Company Description NBCUniversal is one of the world's leading media and entertainment companies. We create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation. Our impact is rooted in improving the communities where our employees, customers, and audiences live and work. We have a rich tradition of giving back and ensuring our employees have the opportunity to serve their communities. We champion an inclusive culture and strive to attract and develop a talented workforce to create and deliver a wide range of content reflecting our world. Comcast NBCUniversal has announced its intent to create a new publicly traded company ('Versant') comprised of most of NBCUniversal's cable television networks, including USA Network, CNBC, MSNBC, Oxygen, E!, SYFY and Golf Channel along with complementary digital assets Fandango, Rotten Tomatoes, GolfNow, GolfPass, and SportsEngine. The well-capitalized company will have significant scale as a pure-play set of assets anchored by leading news, sports and entertainment content. The spin-off is expected to be completed during 2025. Job Description NBCU is looking for creative DevOps Engineers for NBCUâ€™s Distribution Engineering organization who has the appetite to learn, possesses a combination of technical skills along with communication and soft skills with a mindset of Agile, DevOps and Engineering. This role will be responsible for developing CICD pipelines which is scalable, reliable, efficient; deploy product upgrades from the vendor; identifying issues, providing appropriate solution for the issues encountered and maintenance of Distribution Engineeringâ€™s core Playout platform. RESPONSIBILITIES: Â· Develop robust Continuous Integration and Continuous Delivery (CICD) pipeline Â· Deployment, automation, and maintenance of cloud-based production system Â· Integrate security, code quality and automated testing as part of the pipeline Â· Participate in product release cycles, deploying code to integration, staging, and production environments Â· Analyze current technology utilized within the company and develop steps and processes to improve and expand upon them by evaluating new technology alternatives and vendor products Â· Implement Infrastructure as a Code to instantiate / provision cloud resources required Â· Work collaboratively with engineers and vendor to deploy requirements Â· System troubleshooting and problem resolution across the platform Â· Definition and deployment of systems to collect DevOps metrics, logging and monitoring for CICD pipeline Â· Providing recommendations, best practices, and process improvements Â· Provide Tier 2 support for Operations/On-Air Engineering teams Note: This is not a 24/7 on-call support role. There is a separate Tier 1 support team handling this Qualifications REQUIREMENTS: Â· Understanding of Broadcast and Media distribution workflows / technologies Â· Bachelorâ€™s / Masterâ€™s degree in Computer Science or related degree Â· 2+ yrs. experience in DevOps, modern infrastructure deployment and maintenance Â· 2+ yrs. experience in Infrastructure As a code (e.g., Terraform) Â· Experience delivering hosted cloud services in (e.g., AWS, GCP or Azure) Â· Experience with CI/CD orchestration tools (e.g., GitHub Actions, or Jenkins) Â· Experience with networking and cloud-based network environments Â· Experience with containerization & Kubernetes Â· Experience with CI/CD build and deployment practices Â· Experience in administrating Linux environments Â· Must have an automate-first and automate everything attitude Â· Experience with multiple scripting languages (e.g., YML, Bash, Python, Perl, Ruby, or JavaScript) Â· Ability to use Agile process for project management, development & tracking DESIRED CHARACTERISTICS: Â· Experience with a variety of software and hardware operating environments Â· Experience with IP video technologies a plus Â· Familiarity with CICD, monitoring/logging tools. Â· Good communicator and can clearly articulate complex issues and technologies Â· Great design and problem-solving skills. Â· Willing to take ownership of problems and see them through to resolution Â· Comfortable working in a fast-paced agile e",2025-12-07,2.0,,2+ yrs,Unspecified,,Kubernetes; Linux / Bash; Version Control; CI/CD
53f7c1d0-d64f-4670-973a-053066e92c2a,DevOps Engineer,Clearcapital,Clear Capital | CubiCasa - Senior DevOps Engineer,https://jobs.lever.co/clearcapital/82a20740-6bec-469e-b651-a1dea886ee1c,jobs.lever.co,"Clear Capital | CubiCasa - Senior DevOps Engineer Senior DevOps Engineer Remote - US Technology â€“ Information Technology / Remote Apply for this job The DevOps team at Clear Capital is responsible for building and maintaining our AWS cloud infrastructure, which powers our own SaaS applications, data and analytics products, machine learning models, and more. We foster a culture of learning and collaboration, operating under the philosophy that the best idea, not the loudest voice or biggest title, â€œwins.â€ We are seeking a DevOps Engineer with strong Site Reliability Engineering principles to take ownership of our application observability stack, centered around Sumo Logic in AWS. This role will ensure our platforms emit the right telemetryâ€”logs, metrics, traces, eventsâ€”and will design modern dashboards, alerts, and analytics that are intuitive and actionable for engineering and non-DevOps teams alike. You will focus on making our systems measurable, reliable, and transparent, enabling faster troubleshooting, data-driven decision-making, and proactive operations across our cloud services. What You Will Work On Own and lead the architecture, administration, and evolution of Sumo Logic in AWS across multiple application stacks. Collaborate with application teams to ensure complete, consistent, structured telemetry. Build alerts and dashboards for teams across all of Clear Capital Engineering. Push automation and Infrastructure-as-Code for observability resources. Who We Are Looking For 5+ years of cloud operations experience; with focus on monitoring and alerting. Expertise in AWS: Cloudwatch, CloudTrail, IAM, EKS, EC2, Lambda, RDS, Redshift, S3, Glue, Networking. Proficiency with Terraform, git Familiarity with SRE methodologies: monitoring philosophies, SLIs/SLOs, incident response, postmortems. Familiarity with Java and Python, and the supporting ecosystems. Experience migrating telemetry tools, or building observability from scratch. Experience guiding adoption of OpenTelemetry: Developers, Product Owners, C-suite. Strong communication skills: translating technical data into meaningful visibility for product, support, and engineering. What You Can Expect Compensation: The base salary for this position ranges from $115,000 to $157,500 annually, depending on your location, experience, and qualifications. Additional compensation offerings include company profit-sharing bonus program, communication stipends, and referral bonuses. Inclusive benefits package offering: Comprehensive medical, dental, and company paid vision insurance, 401(k) retirement plan with employer match, voluntary life and AD&D insurance options, voluntary supplemental insurances for accident, critical illness, and legal services, paid time off (PTO) and paid holidays, employee assistance and wellness programs, company paid short term disability coverage, company contributions to health saving funds (with participation in the high deductible health plan. We offer company paid access to Galileo for virtual primary care and Rula for virtual mental health resources. Through our Anniversary Program, we celebrate the meaningful milestones and long tenure that reflect how much we value your contributions and commitment to our team. Career and skill development resources to help advance your career and personal growth. A mission-driven environment where your work makes a measurable impact on the real estate industry. What We Value Wherever it Leads, Whatever it TakesÂ® - No matter how remote, complex, or unexpected. Our commitment never wavers. Hire NICE people - Skills can be taught but character shines through. We seek those who bring integrity, kindness, and grit. Lift others up - We lead with empathy and strive to improve the lives of those around us. Sweat the details - Excellence lives in the little things. Getting it just so is how we make a big impact. Raise the bar - We donâ€™t settle for industry standards, we redefine them. About Us Our story began in the mountain town of Truckee, California more than 20 years ago, when we pioneered simple, web-based valuation technology solutions for an industry that relied on paper. Today, weâ€™ve grown one of the highest-coverage networks of real estate professionals across the country. As we continue our journey to modernize valuation, weâ€™ll hold on to our promise from day one: to go wherever it leads and do whatever it takes to serve our customers with remarkable technology and uncompromising service. Clear Capital is an equal-opportunity employer. To all recruitment agencies: Clear Capital does not accept agency resumes. Please do not forward resumes to our jobs alias, Clear Capital employees, or any other company location. Clear Capital is not responsible for any fees related to unsolicited resumes. Apply for this job Jobs powered by",2025-12-07,5.0,,5+ years,Lead,lead,Version Control
f512df0a-e380-4ebb-9483-8e088d4b72e5,DevOps Engineer,Saronic,Saronic - DevOps Engineer,https://jobs.lever.co/saronic/915beb5b-dec4-4792-8b14-e32e66261d68,jobs.lever.co,"Saronic - DevOps Engineer DevOps Engineer Austin, Texas IT / Full Time / On-site Apply for this job Saronic Technologies is a leader in revolutionizing defense autonomy at sea, dedicated to developing state-of-the-art solutions that enhance maritime operations for the Department of Defense (DoD) through autonomous and intelligent platforms. Job Overview: We are seeking a DevOps Engineer responsible for managing development operations and IT infrastructure to support our rapid growth. Responsibilities: Continuous Integration and Deployment: Design, implement, and maintain robust CI/CD pipelines to enable the efficient and automated release of software and firmware updates for our autonomous surface vessels. Collaborate with development teams to ensure smooth integration of new features and enhancements Infrastructure Automation: Utilize infrastructure-as-code (IaC) techniques to automate the provisioning, configuration, and management of cloud-based and on-premises infrastructure. Develop and maintain deployment scripts and configuration management tools Monitoring and Alerting: Implement and manage monitoring systems to ensure high availability, performance, and security of our applications and infrastructure. Establish appropriate alerting mechanisms to promptly identify and respond to incidents or anomalies Cloud Management: Manage cloud-based infrastructure and services (e.g., AWS GovCloud, Azure) to ensure scalability, reliability, and cost optimization. Monitor resource usage, analyze trends, and propose optimizations to improve efficiency Security and Compliance: Implement security best practices and industry standards for our infrastructure and applications. Collaborate with the security team to conduct vulnerability assessments, penetration testing, and remediation activities. Ensure compliance with relevant regulations and standards Qualifications: Bachelor's degree in Computer Science, Information Technology, or a related field. Advanced degree preferred Minimum of 3 years of experience in a combined DevOps and IT role, preferably in a technology-focused company Strong knowledge of DevOps principles, CI/CD methodologies, and experience with relevant tools (e.g., Jenkins, Git, Docker, Kubernetes) Experience managing cloud infrastructure and services (e.g., AWS, Azure, Google Cloud Platform) Proficiency in scripting and automation languages (e.g., Bash, Python) to streamline infrastructure and deployment processes Solid understanding of networking protocols, security practices, and infrastructure components (routers, switches, firewalls) Experience with configuration management tools (e.g., Ansible, Puppet, Chef) and infrastructure-as-code frameworks (e.g., Terraform, CloudFormation) Strong troubleshooting and problem-solving skills with the ability to analyze complex technical issues and propose effective solutions Knowledge of IT support best practices, including hardware and software troubleshooting, user management, and system administration Excellent communication and collaboration skills, with the ability to work effectively in a multidisciplinary team environment Self-motivated with strong attention to detail and the ability to manage multiple tasks and priorities simultaneously Benefits: Medical Insurance: Comprehensive health insurance plans covering a range of services Saronic pays 100% of the premium for employees and 80% for dependents Dental and Vision Insurance: Coverage for routine dental check-ups, orthodontics, and vision care Saronic pays 99% of the premium for employees and 80% for dependents Time Off: Generous PTO and Holidays Parental Leave: Paid maternity and paternity leave to support new parents Competitive Salary: Industry-standard salaries with opportunities for performance-based bonuses Retirement Plan: 401(k) plan Stock Options: Equity options to give employees a stake in the companyâ€™s success Life and Disability Insurance: Basic life insurance and short- and long-term disability coverage Additional Perks: Free lunch benefit and unlimited free drinks and snacks in the office Physical Demands: Prolonged periods of sitting at a desk and working on a computer. Occasional standing and walking within the office. Manual dexterity to operate a computer keyboard, mouse, and other office equipment. Visual acuity to read screens, documents, and reports. Occasional reaching, bending, or stooping to access file drawers, cabinets, or office supplies. Lifting and carrying items up to 20 pounds occasionally (e.g., office supplies, packages). This role requires access to export-controlled information or items that require â€œU.S. Personâ€ status. As defined by U.S. law, individuals who are any one of the following are considered to be a â€œU.S. Personâ€: (1) U.S. citizens, (2) legal permanent residents (a.k.a. green card holders), and (3) certain protected classes of asylees and refugees, as defined in 8 U.S.C. 1324b(a)(3) . Saronic does not discriminate on the basis of race, sex, color, relig",2025-12-07,3.0,,Minimum of 3 years,Unspecified,,Docker; Kubernetes; Linux / Bash; Version Control; CI/CD; Distributed Systems
0aecd7e7-8f40-4c74-ac12-e0c4b35942d8,DevOps Engineer,,"NBCUniversal DevOps Engineer, Playout | SmartRecruiters",https://jobs.smartrecruiters.com/NBCUniversal3/744000096908345-devops-engineer-playout,jobs.smartrecruiters.com,"NBCUniversal DevOps Engineer, Playout | SmartRecruiters Google Chrome Microsoft Edge Apple Safari Mozilla Firefox DevOps Engineer, Playout Full-time Business Segment: Operations & Technology Compensation: USD 90000 - USD 110000 - yearly Company Description NBCUniversal is one of the world's leading media and entertainment companies. We create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation. Our impact is rooted in improving the communities where our employees, customers, and audiences live and work. We have a rich tradition of giving back and ensuring our employees have the opportunity to serve their communities. We champion an inclusive culture and strive to attract and develop a talented workforce to create and deliver a wide range of content reflecting our world. Comcast NBCUniversal has announced its intent to create a new publicly traded company ('Versant') comprised of most of NBCUniversal's cable television networks, including USA Network, CNBC, MSNBC, Oxygen, E!, SYFY and Golf Channel along with complementary digital assets Fandango, Rotten Tomatoes, GolfNow, GolfPass, and SportsEngine. The well-capitalized company will have significant scale as a pure-play set of assets anchored by leading news, sports and entertainment content. The spin-off is expected to be completed during 2025. Job Description NBCU is looking for creative DevOps Engineers for NBCUâ€™s Distribution Engineering organization who has the appetite to learn, possesses a combination of technical skills along with communication and soft skills with a mindset of Agile, DevOps and Engineering. This role will be responsible for developing CICD pipelines which is scalable, reliable, efficient; deploy product upgrades from the vendor; identifying issues, providing appropriate solution for the issues encountered and maintenance of Distribution Engineeringâ€™s core Playout platform. RESPONSIBILITIES: Â· Develop robust Continuous Integration and Continuous Delivery (CICD) pipeline Â· Deployment, automation, and maintenance of cloud-based production system Â· Integrate security, code quality and automated testing as part of the pipeline Â· Participate in product release cycles, deploying code to integration, staging, and production environments Â· Analyze current technology utilized within the company and develop steps and processes to improve and expand upon them by evaluating new technology alternatives and vendor products Â· Implement Infrastructure as a Code to instantiate / provision cloud resources required Â· Work collaboratively with engineers and vendor to deploy requirements Â· System troubleshooting and problem resolution across the platform Â· Definition and deployment of systems to collect DevOps metrics, logging and monitoring for CICD pipeline Â· Providing recommendations, best practices, and process improvements Â· Provide Tier 2 support for Operations/On-Air Engineering teams Note: This is not a 24/7 on-call support role. There is a separate Tier 1 support team handling this Qualifications REQUIREMENTS: Â· Understanding of Broadcast and Media distribution workflows / technologies Â· Bachelorâ€™s / Masterâ€™s degree in Computer Science or related degree Â· 2+ yrs. experience in DevOps, modern infrastructure deployment and maintenance Â· 2+ yrs. experience in Infrastructure As a code (e.g., Terraform) Â· Experience delivering hosted cloud services in (e.g., AWS, GCP or Azure) Â· Experience with CI/CD orchestration tools (e.g., GitHub Actions, or Jenkins) Â· Experience with networking and cloud-based network environments Â· Experience with containerization & Kubernetes Â· Experience with CI/CD build and deployment practices Â· Experience in administrating Linux environments Â· Must have an automate-first and automate everything attitude Â· Experience with multiple scripting languages (e.g., YML, Bash, Python, Perl, Ruby, or JavaScript) Â· Ability to use Agile process for project management, development & tracking DESIRED CHARACTERISTICS: Â· Experience with a variety of software and hardware operating environments Â· Experience with IP video technologies a plus Â· Familiarity with CICD, monitoring/logging tools. Â· Good communicator and can clearly articulate complex issues and technologies Â· Great design and problem-solving skills. Â· Willing to take ownership of problems and see them through to resolution Â· Comfortable working in a fast-paced agile e",2025-12-07,2.0,,2+ yrs,Unspecified,,Kubernetes; Linux / Bash; Version Control; CI/CD
a3612f65-8c21-4f6c-a399-d784ffa8e7ba,DevOps Engineer,Saronic,Saronic - DevOps Engineer,https://jobs.lever.co/saronic/915beb5b-dec4-4792-8b14-e32e66261d68,jobs.lever.co,"Saronic - DevOps Engineer DevOps Engineer Austin, Texas IT / Full Time / On-site Apply for this job Saronic Technologies is a leader in revolutionizing defense autonomy at sea, dedicated to developing state-of-the-art solutions that enhance maritime operations for the Department of Defense (DoD) through autonomous and intelligent platforms. Job Overview: We are seeking a DevOps Engineer responsible for managing development operations and IT infrastructure to support our rapid growth. Responsibilities: Continuous Integration and Deployment: Design, implement, and maintain robust CI/CD pipelines to enable the efficient and automated release of software and firmware updates for our autonomous surface vessels. Collaborate with development teams to ensure smooth integration of new features and enhancements Infrastructure Automation: Utilize infrastructure-as-code (IaC) techniques to automate the provisioning, configuration, and management of cloud-based and on-premises infrastructure. Develop and maintain deployment scripts and configuration management tools Monitoring and Alerting: Implement and manage monitoring systems to ensure high availability, performance, and security of our applications and infrastructure. Establish appropriate alerting mechanisms to promptly identify and respond to incidents or anomalies Cloud Management: Manage cloud-based infrastructure and services (e.g., AWS GovCloud, Azure) to ensure scalability, reliability, and cost optimization. Monitor resource usage, analyze trends, and propose optimizations to improve efficiency Security and Compliance: Implement security best practices and industry standards for our infrastructure and applications. Collaborate with the security team to conduct vulnerability assessments, penetration testing, and remediation activities. Ensure compliance with relevant regulations and standards Qualifications: Bachelor's degree in Computer Science, Information Technology, or a related field. Advanced degree preferred Minimum of 3 years of experience in a combined DevOps and IT role, preferably in a technology-focused company Strong knowledge of DevOps principles, CI/CD methodologies, and experience with relevant tools (e.g., Jenkins, Git, Docker, Kubernetes) Experience managing cloud infrastructure and services (e.g., AWS, Azure, Google Cloud Platform) Proficiency in scripting and automation languages (e.g., Bash, Python) to streamline infrastructure and deployment processes Solid understanding of networking protocols, security practices, and infrastructure components (routers, switches, firewalls) Experience with configuration management tools (e.g., Ansible, Puppet, Chef) and infrastructure-as-code frameworks (e.g., Terraform, CloudFormation) Strong troubleshooting and problem-solving skills with the ability to analyze complex technical issues and propose effective solutions Knowledge of IT support best practices, including hardware and software troubleshooting, user management, and system administration Excellent communication and collaboration skills, with the ability to work effectively in a multidisciplinary team environment Self-motivated with strong attention to detail and the ability to manage multiple tasks and priorities simultaneously Benefits: Medical Insurance: Comprehensive health insurance plans covering a range of services Saronic pays 100% of the premium for employees and 80% for dependents Dental and Vision Insurance: Coverage for routine dental check-ups, orthodontics, and vision care Saronic pays 99% of the premium for employees and 80% for dependents Time Off: Generous PTO and Holidays Parental Leave: Paid maternity and paternity leave to support new parents Competitive Salary: Industry-standard salaries with opportunities for performance-based bonuses Retirement Plan: 401(k) plan Stock Options: Equity options to give employees a stake in the companyâ€™s success Life and Disability Insurance: Basic life insurance and short- and long-term disability coverage Additional Perks: Free lunch benefit and unlimited free drinks and snacks in the office Physical Demands: Prolonged periods of sitting at a desk and working on a computer. Occasional standing and walking within the office. Manual dexterity to operate a computer keyboard, mouse, and other office equipment. Visual acuity to read screens, documents, and reports. Occasional reaching, bending, or stooping to access file drawers, cabinets, or office supplies. Lifting and carrying items up to 20 pounds occasionally (e.g., office supplies, packages). This role requires access to export-controlled information or items that require â€œU.S. Personâ€ status. As defined by U.S. law, individuals who are any one of the following are considered to be a â€œU.S. Personâ€: (1) U.S. citizens, (2) legal permanent residents (a.k.a. green card holders), and (3) certain protected classes of asylees and refugees, as defined in 8 U.S.C. 1324b(a)(3) . Saronic does not discriminate on the basis of race, sex, color, relig",2025-12-07,3.0,,Minimum of 3 years,Unspecified,,Docker; Kubernetes; Linux / Bash; Version Control; CI/CD; Distributed Systems
50146d1e-8c95-4d75-8b1f-d8b6d1737e46,DevOps Engineer,Clearcapital,Clear Capital | CubiCasa - Senior DevOps Engineer,https://jobs.lever.co/clearcapital/82a20740-6bec-469e-b651-a1dea886ee1c,jobs.lever.co,"Clear Capital | CubiCasa - Senior DevOps Engineer Senior DevOps Engineer Remote - US Technology â€“ Information Technology / Remote Apply for this job The DevOps team at Clear Capital is responsible for building and maintaining our AWS cloud infrastructure, which powers our own SaaS applications, data and analytics products, machine learning models, and more. We foster a culture of learning and collaboration, operating under the philosophy that the best idea, not the loudest voice or biggest title, â€œwins.â€ We are seeking a DevOps Engineer with strong Site Reliability Engineering principles to take ownership of our application observability stack, centered around Sumo Logic in AWS. This role will ensure our platforms emit the right telemetryâ€”logs, metrics, traces, eventsâ€”and will design modern dashboards, alerts, and analytics that are intuitive and actionable for engineering and non-DevOps teams alike. You will focus on making our systems measurable, reliable, and transparent, enabling faster troubleshooting, data-driven decision-making, and proactive operations across our cloud services. What You Will Work On Own and lead the architecture, administration, and evolution of Sumo Logic in AWS across multiple application stacks. Collaborate with application teams to ensure complete, consistent, structured telemetry. Build alerts and dashboards for teams across all of Clear Capital Engineering. Push automation and Infrastructure-as-Code for observability resources. Who We Are Looking For 5+ years of cloud operations experience; with focus on monitoring and alerting. Expertise in AWS: Cloudwatch, CloudTrail, IAM, EKS, EC2, Lambda, RDS, Redshift, S3, Glue, Networking. Proficiency with Terraform, git Familiarity with SRE methodologies: monitoring philosophies, SLIs/SLOs, incident response, postmortems. Familiarity with Java and Python, and the supporting ecosystems. Experience migrating telemetry tools, or building observability from scratch. Experience guiding adoption of OpenTelemetry: Developers, Product Owners, C-suite. Strong communication skills: translating technical data into meaningful visibility for product, support, and engineering. What You Can Expect Compensation: The base salary for this position ranges from $115,000 to $157,500 annually, depending on your location, experience, and qualifications. Additional compensation offerings include company profit-sharing bonus program, communication stipends, and referral bonuses. Inclusive benefits package offering: Comprehensive medical, dental, and company paid vision insurance, 401(k) retirement plan with employer match, voluntary life and AD&D insurance options, voluntary supplemental insurances for accident, critical illness, and legal services, paid time off (PTO) and paid holidays, employee assistance and wellness programs, company paid short term disability coverage, company contributions to health saving funds (with participation in the high deductible health plan. We offer company paid access to Galileo for virtual primary care and Rula for virtual mental health resources. Through our Anniversary Program, we celebrate the meaningful milestones and long tenure that reflect how much we value your contributions and commitment to our team. Career and skill development resources to help advance your career and personal growth. A mission-driven environment where your work makes a measurable impact on the real estate industry. What We Value Wherever it Leads, Whatever it TakesÂ® - No matter how remote, complex, or unexpected. Our commitment never wavers. Hire NICE people - Skills can be taught but character shines through. We seek those who bring integrity, kindness, and grit. Lift others up - We lead with empathy and strive to improve the lives of those around us. Sweat the details - Excellence lives in the little things. Getting it just so is how we make a big impact. Raise the bar - We donâ€™t settle for industry standards, we redefine them. About Us Our story began in the mountain town of Truckee, California more than 20 years ago, when we pioneered simple, web-based valuation technology solutions for an industry that relied on paper. Today, weâ€™ve grown one of the highest-coverage networks of real estate professionals across the country. As we continue our journey to modernize valuation, weâ€™ll hold on to our promise from day one: to go wherever it leads and do whatever it takes to serve our customers with remarkable technology and uncompromising service. Clear Capital is an equal-opportunity employer. To all recruitment agencies: Clear Capital does not accept agency resumes. Please do not forward resumes to our jobs alias, Clear Capital employees, or any other company location. Clear Capital is not responsible for any fees related to unsolicited resumes. Apply for this job Jobs powered by",2025-12-07,5.0,,5+ years,Lead,lead,Version Control
83a56786-6a21-4bda-8c2d-bc0b5dc1e185,DevOps Engineer,,"NBCUniversal DevOps Engineer, Playout | SmartRecruiters",https://jobs.smartrecruiters.com/NBCUniversal3/744000096908345-devops-engineer-playout,jobs.smartrecruiters.com,"NBCUniversal DevOps Engineer, Playout | SmartRecruiters Google Chrome Microsoft Edge Apple Safari Mozilla Firefox DevOps Engineer, Playout Full-time Business Segment: Operations & Technology Compensation: USD 90000 - USD 110000 - yearly Company Description NBCUniversal is one of the world's leading media and entertainment companies. We create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation. Our impact is rooted in improving the communities where our employees, customers, and audiences live and work. We have a rich tradition of giving back and ensuring our employees have the opportunity to serve their communities. We champion an inclusive culture and strive to attract and develop a talented workforce to create and deliver a wide range of content reflecting our world. Comcast NBCUniversal has announced its intent to create a new publicly traded company ('Versant') comprised of most of NBCUniversal's cable television networks, including USA Network, CNBC, MSNBC, Oxygen, E!, SYFY and Golf Channel along with complementary digital assets Fandango, Rotten Tomatoes, GolfNow, GolfPass, and SportsEngine. The well-capitalized company will have significant scale as a pure-play set of assets anchored by leading news, sports and entertainment content. The spin-off is expected to be completed during 2025. Job Description NBCU is looking for creative DevOps Engineers for NBCUâ€™s Distribution Engineering organization who has the appetite to learn, possesses a combination of technical skills along with communication and soft skills with a mindset of Agile, DevOps and Engineering. This role will be responsible for developing CICD pipelines which is scalable, reliable, efficient; deploy product upgrades from the vendor; identifying issues, providing appropriate solution for the issues encountered and maintenance of Distribution Engineeringâ€™s core Playout platform. RESPONSIBILITIES: Â· Develop robust Continuous Integration and Continuous Delivery (CICD) pipeline Â· Deployment, automation, and maintenance of cloud-based production system Â· Integrate security, code quality and automated testing as part of the pipeline Â· Participate in product release cycles, deploying code to integration, staging, and production environments Â· Analyze current technology utilized within the company and develop steps and processes to improve and expand upon them by evaluating new technology alternatives and vendor products Â· Implement Infrastructure as a Code to instantiate / provision cloud resources required Â· Work collaboratively with engineers and vendor to deploy requirements Â· System troubleshooting and problem resolution across the platform Â· Definition and deployment of systems to collect DevOps metrics, logging and monitoring for CICD pipeline Â· Providing recommendations, best practices, and process improvements Â· Provide Tier 2 support for Operations/On-Air Engineering teams Note: This is not a 24/7 on-call support role. There is a separate Tier 1 support team handling this Qualifications REQUIREMENTS: Â· Understanding of Broadcast and Media distribution workflows / technologies Â· Bachelorâ€™s / Masterâ€™s degree in Computer Science or related degree Â· 2+ yrs. experience in DevOps, modern infrastructure deployment and maintenance Â· 2+ yrs. experience in Infrastructure As a code (e.g., Terraform) Â· Experience delivering hosted cloud services in (e.g., AWS, GCP or Azure) Â· Experience with CI/CD orchestration tools (e.g., GitHub Actions, or Jenkins) Â· Experience with networking and cloud-based network environments Â· Experience with containerization & Kubernetes Â· Experience with CI/CD build and deployment practices Â· Experience in administrating Linux environments Â· Must have an automate-first and automate everything attitude Â· Experience with multiple scripting languages (e.g., YML, Bash, Python, Perl, Ruby, or JavaScript) Â· Ability to use Agile process for project management, development & tracking DESIRED CHARACTERISTICS: Â· Experience with a variety of software and hardware operating environments Â· Experience with IP video technologies a plus Â· Familiarity with CICD, monitoring/logging tools. Â· Good communicator and can clearly articulate complex issues and technologies Â· Great design and problem-solving skills. Â· Willing to take ownership of problems and see them through to resolution Â· Comfortable working in a fast-paced agile e",2025-12-07,2.0,,2+ yrs,Unspecified,,Kubernetes; Linux / Bash; Version Control; CI/CD
a8fb06ac-afdb-43e7-aa69-2f81e1476189,DevOps Engineer,Clearcapital,Clear Capital | CubiCasa - Senior DevOps Engineer,https://jobs.lever.co/clearcapital/82a20740-6bec-469e-b651-a1dea886ee1c,jobs.lever.co,"Clear Capital | CubiCasa - Senior DevOps Engineer Senior DevOps Engineer Remote - US Technology â€“ Information Technology / Remote Apply for this job The DevOps team at Clear Capital is responsible for building and maintaining our AWS cloud infrastructure, which powers our own SaaS applications, data and analytics products, machine learning models, and more. We foster a culture of learning and collaboration, operating under the philosophy that the best idea, not the loudest voice or biggest title, â€œwins.â€ We are seeking a DevOps Engineer with strong Site Reliability Engineering principles to take ownership of our application observability stack, centered around Sumo Logic in AWS. This role will ensure our platforms emit the right telemetryâ€”logs, metrics, traces, eventsâ€”and will design modern dashboards, alerts, and analytics that are intuitive and actionable for engineering and non-DevOps teams alike. You will focus on making our systems measurable, reliable, and transparent, enabling faster troubleshooting, data-driven decision-making, and proactive operations across our cloud services. What You Will Work On Own and lead the architecture, administration, and evolution of Sumo Logic in AWS across multiple application stacks. Collaborate with application teams to ensure complete, consistent, structured telemetry. Build alerts and dashboards for teams across all of Clear Capital Engineering. Push automation and Infrastructure-as-Code for observability resources. Who We Are Looking For 5+ years of cloud operations experience; with focus on monitoring and alerting. Expertise in AWS: Cloudwatch, CloudTrail, IAM, EKS, EC2, Lambda, RDS, Redshift, S3, Glue, Networking. Proficiency with Terraform, git Familiarity with SRE methodologies: monitoring philosophies, SLIs/SLOs, incident response, postmortems. Familiarity with Java and Python, and the supporting ecosystems. Experience migrating telemetry tools, or building observability from scratch. Experience guiding adoption of OpenTelemetry: Developers, Product Owners, C-suite. Strong communication skills: translating technical data into meaningful visibility for product, support, and engineering. What You Can Expect Compensation: The base salary for this position ranges from $115,000 to $157,500 annually, depending on your location, experience, and qualifications. Additional compensation offerings include company profit-sharing bonus program, communication stipends, and referral bonuses. Inclusive benefits package offering: Comprehensive medical, dental, and company paid vision insurance, 401(k) retirement plan with employer match, voluntary life and AD&D insurance options, voluntary supplemental insurances for accident, critical illness, and legal services, paid time off (PTO) and paid holidays, employee assistance and wellness programs, company paid short term disability coverage, company contributions to health saving funds (with participation in the high deductible health plan. We offer company paid access to Galileo for virtual primary care and Rula for virtual mental health resources. Through our Anniversary Program, we celebrate the meaningful milestones and long tenure that reflect how much we value your contributions and commitment to our team. Career and skill development resources to help advance your career and personal growth. A mission-driven environment where your work makes a measurable impact on the real estate industry. What We Value Wherever it Leads, Whatever it TakesÂ® - No matter how remote, complex, or unexpected. Our commitment never wavers. Hire NICE people - Skills can be taught but character shines through. We seek those who bring integrity, kindness, and grit. Lift others up - We lead with empathy and strive to improve the lives of those around us. Sweat the details - Excellence lives in the little things. Getting it just so is how we make a big impact. Raise the bar - We donâ€™t settle for industry standards, we redefine them. About Us Our story began in the mountain town of Truckee, California more than 20 years ago, when we pioneered simple, web-based valuation technology solutions for an industry that relied on paper. Today, weâ€™ve grown one of the highest-coverage networks of real estate professionals across the country. As we continue our journey to modernize valuation, weâ€™ll hold on to our promise from day one: to go wherever it leads and do whatever it takes to serve our customers with remarkable technology and uncompromising service. Clear Capital is an equal-opportunity employer. To all recruitment agencies: Clear Capital does not accept agency resumes. Please do not forward resumes to our jobs alias, Clear Capital employees, or any other company location. Clear Capital is not responsible for any fees related to unsolicited resumes. Apply for this job Jobs powered by",2025-12-07,5.0,,5+ years,Lead,lead,Version Control
4808d66e-1cd0-4008-893a-5809e292a7c7,DevOps Engineer,Saronic,Saronic - DevOps Engineer,https://jobs.lever.co/saronic/915beb5b-dec4-4792-8b14-e32e66261d68,jobs.lever.co,"Saronic - DevOps Engineer DevOps Engineer Austin, Texas IT / Full Time / On-site Apply for this job Saronic Technologies is a leader in revolutionizing defense autonomy at sea, dedicated to developing state-of-the-art solutions that enhance maritime operations for the Department of Defense (DoD) through autonomous and intelligent platforms. Job Overview: We are seeking a DevOps Engineer responsible for managing development operations and IT infrastructure to support our rapid growth. Responsibilities: Continuous Integration and Deployment: Design, implement, and maintain robust CI/CD pipelines to enable the efficient and automated release of software and firmware updates for our autonomous surface vessels. Collaborate with development teams to ensure smooth integration of new features and enhancements Infrastructure Automation: Utilize infrastructure-as-code (IaC) techniques to automate the provisioning, configuration, and management of cloud-based and on-premises infrastructure. Develop and maintain deployment scripts and configuration management tools Monitoring and Alerting: Implement and manage monitoring systems to ensure high availability, performance, and security of our applications and infrastructure. Establish appropriate alerting mechanisms to promptly identify and respond to incidents or anomalies Cloud Management: Manage cloud-based infrastructure and services (e.g., AWS GovCloud, Azure) to ensure scalability, reliability, and cost optimization. Monitor resource usage, analyze trends, and propose optimizations to improve efficiency Security and Compliance: Implement security best practices and industry standards for our infrastructure and applications. Collaborate with the security team to conduct vulnerability assessments, penetration testing, and remediation activities. Ensure compliance with relevant regulations and standards Qualifications: Bachelor's degree in Computer Science, Information Technology, or a related field. Advanced degree preferred Minimum of 3 years of experience in a combined DevOps and IT role, preferably in a technology-focused company Strong knowledge of DevOps principles, CI/CD methodologies, and experience with relevant tools (e.g., Jenkins, Git, Docker, Kubernetes) Experience managing cloud infrastructure and services (e.g., AWS, Azure, Google Cloud Platform) Proficiency in scripting and automation languages (e.g., Bash, Python) to streamline infrastructure and deployment processes Solid understanding of networking protocols, security practices, and infrastructure components (routers, switches, firewalls) Experience with configuration management tools (e.g., Ansible, Puppet, Chef) and infrastructure-as-code frameworks (e.g., Terraform, CloudFormation) Strong troubleshooting and problem-solving skills with the ability to analyze complex technical issues and propose effective solutions Knowledge of IT support best practices, including hardware and software troubleshooting, user management, and system administration Excellent communication and collaboration skills, with the ability to work effectively in a multidisciplinary team environment Self-motivated with strong attention to detail and the ability to manage multiple tasks and priorities simultaneously Benefits: Medical Insurance: Comprehensive health insurance plans covering a range of services Saronic pays 100% of the premium for employees and 80% for dependents Dental and Vision Insurance: Coverage for routine dental check-ups, orthodontics, and vision care Saronic pays 99% of the premium for employees and 80% for dependents Time Off: Generous PTO and Holidays Parental Leave: Paid maternity and paternity leave to support new parents Competitive Salary: Industry-standard salaries with opportunities for performance-based bonuses Retirement Plan: 401(k) plan Stock Options: Equity options to give employees a stake in the companyâ€™s success Life and Disability Insurance: Basic life insurance and short- and long-term disability coverage Additional Perks: Free lunch benefit and unlimited free drinks and snacks in the office Physical Demands: Prolonged periods of sitting at a desk and working on a computer. Occasional standing and walking within the office. Manual dexterity to operate a computer keyboard, mouse, and other office equipment. Visual acuity to read screens, documents, and reports. Occasional reaching, bending, or stooping to access file drawers, cabinets, or office supplies. Lifting and carrying items up to 20 pounds occasionally (e.g., office supplies, packages). This role requires access to export-controlled information or items that require â€œU.S. Personâ€ status. As defined by U.S. law, individuals who are any one of the following are considered to be a â€œU.S. Personâ€: (1) U.S. citizens, (2) legal permanent residents (a.k.a. green card holders), and (3) certain protected classes of asylees and refugees, as defined in 8 U.S.C. 1324b(a)(3) . Saronic does not discriminate on the basis of race, sex, color, relig",2025-12-07,3.0,,Minimum of 3 years,Unspecified,,Docker; Kubernetes; Linux / Bash; Version Control; CI/CD; Distributed Systems
01622e67-cb8d-4a2f-89d5-063578e1a8c2,MLOps Engineer,Ifm Us,Institute of Foundation Models - Senior MLOps Engineer,https://jobs.lever.co/ifm-us/5f0feab3-1309-4c24-a703-ed1993c448b9,jobs.lever.co,"Institute of Foundation Models - Senior MLOps Engineer Senior MLOps Engineer Abu Dhabi Engineering / Full-time / On-site Apply for this job About the Institute of Foundation Models (IFM) The Institute of Foundation Models is a dedicated research lab for building, understanding, deploying, and risk-managing large-scale AI systems. We drive innovation in foundation models and their operationalization, empowering research, education, and industry adoption through scalable infrastructure and real-world applications. As part of our engineering team, you will operate at the intersection of machine learning and systems design â€” building the cloud, orchestration, and deployment layers that power the next generation of intelligent applications at MBZUAI. Youâ€™ll work alongside world-class AI researchers and engineers to productionize LLMs, voice models, and multimodal systems at scale. The Role As a Senior MLOps Engineer , you will design, build, and maintain robust ML(Machine Learning) infrastructure across training, inference, and deployment pipelines. You will take ownership of the model lifecycle â€” from data ingestion to real-time serving â€” and ensure our LLM and speech models are deployed efficiently, securely, and reproducibly in Kubernetes-based environments. This position requires deep hands-on experience with Kubernetes (EKS) , Helm , AWS cloud infrastructure , and modern MLOps toolchains (e.g., vLLM , SGLang , OpenWebUI , Weights & Biases , MLflow ). Familiarity with speech/voice AI frameworks like ElevenLabs , Whisper , and RVC is also valuable. Key Responsibilities Design and manage scalable ML infrastructure on AWS using EKS , EC2 , RDS , S3 , and IAM -based access control. Build and maintain Kubernetes deployments for LLM and TTS inference using Helm , ArgoCD , and Prometheus/Grafana monitoring. Implement and optimize model serving pipelines using vLLM , SGLang , TensorRT , or similar frameworks for high-throughput inference. Develop CI/CD and MLOps automation for data versioning, model validation, and deployment (GitHub Actions, Jenkins, or AWS CodePipeline). Integrate OpenWebUI , Gradio , or similar UIs for user-facing model demos and internal evaluation tools. Collaborate with ML researchers to productize models â€” including TTS (e.g., ElevenLabs API), ASR (Whisper), and LLM-based chat systems. Ensure observability, cost optimization, and reliability of cloud resources across multiple environments. Contribute to internal tools for dataset curation, model monitoring, and retraining pipelines . Maintain infrastructure-as-code using Terraform and Helm charts for reproducibility and governance. Support real-time multimodal workloads (voice, text, vision) across inference clusters. Academic Qualifications 4+ years of experience in MLOps , DevOps , or Cloud Infrastructure Engineering for ML systems. Strong proficiency in Kubernetes , Helm , and container orchestration . Experience deploying ML models via vLLM , SGLang , TensorRT , or Ray Serve . Proficiency with AWS services (EKS, EC2, S3, RDS, CloudWatch, IAM). Solid experience with Python , Docker , Git , and CI/CD pipelines . Strong understanding of model lifecycle management , data pipelines , and observability tools (Grafana, Prometheus, Loki). Excellent collaboration skills with ML researchers and software engineers. Professional Experience â€“ Preferred Extensive Experience with vLLM, K8s, Elevenlabs , Whisper , Gradio/OpenWebUI , or custom TTS/ASR model hosting. Familiarity with multi-GPU scheduling , NCCL optimization , and HPC cluster integration . Knowledge of security , cost management , and network policy in multi-tenant Kubernetes clusters and cloudflare systems. Prior work in LLM deployment , fine-tuning pipelines , or foundation model research . Exposure to data governance and responsible AI operations in research or enterprise settings. Apply for this job Jobs powered by",2025-12-07,4.0,,4+ years,Senior,senior,Cloud Platforms; MLOps Tools; Docker; Kubernetes; Version Control; CI/CD; Generative AI
8030211d-6757-4a3a-9876-7040e775b18d,MLOps Engineer,Ifm Us,Institute of Foundation Models - Senior MLOps Engineer,https://jobs.lever.co/ifm-us/5f0feab3-1309-4c24-a703-ed1993c448b9,jobs.lever.co,"Institute of Foundation Models - Senior MLOps Engineer Senior MLOps Engineer Abu Dhabi Engineering / Full-time / On-site Apply for this job About the Institute of Foundation Models (IFM) The Institute of Foundation Models is a dedicated research lab for building, understanding, deploying, and risk-managing large-scale AI systems. We drive innovation in foundation models and their operationalization, empowering research, education, and industry adoption through scalable infrastructure and real-world applications. As part of our engineering team, you will operate at the intersection of machine learning and systems design â€” building the cloud, orchestration, and deployment layers that power the next generation of intelligent applications at MBZUAI. Youâ€™ll work alongside world-class AI researchers and engineers to productionize LLMs, voice models, and multimodal systems at scale. The Role As a Senior MLOps Engineer , you will design, build, and maintain robust ML(Machine Learning) infrastructure across training, inference, and deployment pipelines. You will take ownership of the model lifecycle â€” from data ingestion to real-time serving â€” and ensure our LLM and speech models are deployed efficiently, securely, and reproducibly in Kubernetes-based environments. This position requires deep hands-on experience with Kubernetes (EKS) , Helm , AWS cloud infrastructure , and modern MLOps toolchains (e.g., vLLM , SGLang , OpenWebUI , Weights & Biases , MLflow ). Familiarity with speech/voice AI frameworks like ElevenLabs , Whisper , and RVC is also valuable. Key Responsibilities Design and manage scalable ML infrastructure on AWS using EKS , EC2 , RDS , S3 , and IAM -based access control. Build and maintain Kubernetes deployments for LLM and TTS inference using Helm , ArgoCD , and Prometheus/Grafana monitoring. Implement and optimize model serving pipelines using vLLM , SGLang , TensorRT , or similar frameworks for high-throughput inference. Develop CI/CD and MLOps automation for data versioning, model validation, and deployment (GitHub Actions, Jenkins, or AWS CodePipeline). Integrate OpenWebUI , Gradio , or similar UIs for user-facing model demos and internal evaluation tools. Collaborate with ML researchers to productize models â€” including TTS (e.g., ElevenLabs API), ASR (Whisper), and LLM-based chat systems. Ensure observability, cost optimization, and reliability of cloud resources across multiple environments. Contribute to internal tools for dataset curation, model monitoring, and retraining pipelines . Maintain infrastructure-as-code using Terraform and Helm charts for reproducibility and governance. Support real-time multimodal workloads (voice, text, vision) across inference clusters. Academic Qualifications 4+ years of experience in MLOps , DevOps , or Cloud Infrastructure Engineering for ML systems. Strong proficiency in Kubernetes , Helm , and container orchestration . Experience deploying ML models via vLLM , SGLang , TensorRT , or Ray Serve . Proficiency with AWS services (EKS, EC2, S3, RDS, CloudWatch, IAM). Solid experience with Python , Docker , Git , and CI/CD pipelines . Strong understanding of model lifecycle management , data pipelines , and observability tools (Grafana, Prometheus, Loki). Excellent collaboration skills with ML researchers and software engineers. Professional Experience â€“ Preferred Extensive Experience with vLLM, K8s, Elevenlabs , Whisper , Gradio/OpenWebUI , or custom TTS/ASR model hosting. Familiarity with multi-GPU scheduling , NCCL optimization , and HPC cluster integration . Knowledge of security , cost management , and network policy in multi-tenant Kubernetes clusters and cloudflare systems. Prior work in LLM deployment , fine-tuning pipelines , or foundation model research . Exposure to data governance and responsible AI operations in research or enterprise settings. Apply for this job Jobs powered by",2025-12-07,4.0,,4+ years,Senior,senior,Cloud Platforms; MLOps Tools; Docker; Kubernetes; Version Control; CI/CD; Generative AI
4f03d4a6-f2cc-4a18-a2dc-da4f2c616e47,MLOps Engineer,Ifm Us,Institute of Foundation Models - Senior MLOps Engineer,https://jobs.lever.co/ifm-us/5f0feab3-1309-4c24-a703-ed1993c448b9,jobs.lever.co,"Institute of Foundation Models - Senior MLOps Engineer Senior MLOps Engineer Abu Dhabi Engineering / Full-time / On-site Apply for this job About the Institute of Foundation Models (IFM) The Institute of Foundation Models is a dedicated research lab for building, understanding, deploying, and risk-managing large-scale AI systems. We drive innovation in foundation models and their operationalization, empowering research, education, and industry adoption through scalable infrastructure and real-world applications. As part of our engineering team, you will operate at the intersection of machine learning and systems design â€” building the cloud, orchestration, and deployment layers that power the next generation of intelligent applications at MBZUAI. Youâ€™ll work alongside world-class AI researchers and engineers to productionize LLMs, voice models, and multimodal systems at scale. The Role As a Senior MLOps Engineer , you will design, build, and maintain robust ML(Machine Learning) infrastructure across training, inference, and deployment pipelines. You will take ownership of the model lifecycle â€” from data ingestion to real-time serving â€” and ensure our LLM and speech models are deployed efficiently, securely, and reproducibly in Kubernetes-based environments. This position requires deep hands-on experience with Kubernetes (EKS) , Helm , AWS cloud infrastructure , and modern MLOps toolchains (e.g., vLLM , SGLang , OpenWebUI , Weights & Biases , MLflow ). Familiarity with speech/voice AI frameworks like ElevenLabs , Whisper , and RVC is also valuable. Key Responsibilities Design and manage scalable ML infrastructure on AWS using EKS , EC2 , RDS , S3 , and IAM -based access control. Build and maintain Kubernetes deployments for LLM and TTS inference using Helm , ArgoCD , and Prometheus/Grafana monitoring. Implement and optimize model serving pipelines using vLLM , SGLang , TensorRT , or similar frameworks for high-throughput inference. Develop CI/CD and MLOps automation for data versioning, model validation, and deployment (GitHub Actions, Jenkins, or AWS CodePipeline). Integrate OpenWebUI , Gradio , or similar UIs for user-facing model demos and internal evaluation tools. Collaborate with ML researchers to productize models â€” including TTS (e.g., ElevenLabs API), ASR (Whisper), and LLM-based chat systems. Ensure observability, cost optimization, and reliability of cloud resources across multiple environments. Contribute to internal tools for dataset curation, model monitoring, and retraining pipelines . Maintain infrastructure-as-code using Terraform and Helm charts for reproducibility and governance. Support real-time multimodal workloads (voice, text, vision) across inference clusters. Academic Qualifications 4+ years of experience in MLOps , DevOps , or Cloud Infrastructure Engineering for ML systems. Strong proficiency in Kubernetes , Helm , and container orchestration . Experience deploying ML models via vLLM , SGLang , TensorRT , or Ray Serve . Proficiency with AWS services (EKS, EC2, S3, RDS, CloudWatch, IAM). Solid experience with Python , Docker , Git , and CI/CD pipelines . Strong understanding of model lifecycle management , data pipelines , and observability tools (Grafana, Prometheus, Loki). Excellent collaboration skills with ML researchers and software engineers. Professional Experience â€“ Preferred Extensive Experience with vLLM, K8s, Elevenlabs , Whisper , Gradio/OpenWebUI , or custom TTS/ASR model hosting. Familiarity with multi-GPU scheduling , NCCL optimization , and HPC cluster integration . Knowledge of security , cost management , and network policy in multi-tenant Kubernetes clusters and cloudflare systems. Prior work in LLM deployment , fine-tuning pipelines , or foundation model research . Exposure to data governance and responsible AI operations in research or enterprise settings. Apply for this job Jobs powered by",2025-12-07,4.0,,4+ years,Senior,senior,Cloud Platforms; MLOps Tools; Docker; Kubernetes; Version Control; CI/CD; Generative AI
4d85bc7e-a847-4fc8-95d6-eb7ac6a2bf5c,Computer Vision Engineer,Mujininc,Mujin - Senior Computer Vision Engineer - jobs.lever.co,https://jobs.lever.co/mujininc/6e7684bf-ebb0-4cbb-92d1-0cfbcda9f376,jobs.lever.co,"Mujin - Senior Computer Vision Engineer Senior Computer Vision Engineer Best, Netherlands 1 - Software Development â€“ Computer Vision Team / Full-Time (English) / On-site Apply for this job Are you ready to shape the future of industrial robotic systems? Mujin uses robotics technology to develop smart automation solutions for logistics, material handling, and manufacturing. Our technology gives robots perception and awareness, enabling them to take on more advanced tasks by applying our unique approach to industrial robotics. Be at the forefront of groundbreaking robotics automation that challenges your skills and pushes the boundaries of what's possible. Position: Senior Computer Vision Engineer As a Computer Vision Engineer, you will be a part of the Mujin Europe R&D team, focusing on the algorithmic design, development, and deployment of computer vision applications for high-speed recognition and the worldâ€™s first 3D vision system for factory automation and logistics solutions. Responsibilities Solve cutting-edge scientific and technical challenges related to recognition and pose estimation of a very wide variety of objects in challenging scenarios Analyze and evaluate state-of-the-art algorithms related to detection and pose estimation, from academic and industrial research, and implement and enhance them in a production environment Design, develop and evaluate the performance of highly scalable and accurate real-time computer vision applications, in Python and C/C++ Perform the detailed test, carry out performance analysis on algorithms, and use continuous integration tools to finely enhance the rapidly deployed algorithms Requirements Graduated in Computer Science or a related field with a BS or MS degree and experience in computer vision, or a Ph.D. in Computer Visionâ€“related topics. Ability to develop applications and tools in Python andCï¼‹ï¼‹ 3D pose estimation of textured and texture less objects in cluttered scenes, with proven experience Python and C++ experience Experience with a vast set of computer vision libraries Mathematical background in 3D processing and statistical analysis Extras: object tracking, SLAM, computer graphics, augmented reality, machine learning, exposure to projects in robotics Minimum of 3+ years of relevant experience Willingness to travel extensively, up to 40% of the year English speaking is a requirement Practical tips on how to approach your prep including understanding the role, links, and useful sample questions: Ace your Computer Vision job interview About Mujin Our mission at Mujin is to revolutionize the industry by liberating human resources from labor-intensive duties, allowing them to focus on more intellectually challenging endeavors. Working at Mujin means working with the latest tools and technologies available in the material handling systems world. We believe in fostering a work environment that values innovation, collaboration, and personal growth. Our fast-paced, start-up mindset and international connections encourage open communication, idea-sharing, and a collective commitment to success. Why Join Our Team: Â· Competitive base salary that reflects your skills, experiences and the value you bring to our team Â· Paid time off, including vacation, sick leave and holidays Â· Access to cutting-edge technology Â· International, inclusive and collaborative work culture Â· Opportunities for career growth and advancement within the company Are you ready to be a part of the Mujin journey and shape the future of robotics in Europe? Apply via this posting with your CV and any relevant project portfolios of GitHub repositories. At Mujin, we believe in a thorough and transparent recruitment process to ensure the best fit for both the candidate and the company. After submitting your application through our job site, our team will carefully review your CV to evaluate your qualifications and experience. If your profile aligns with the roleâ€™s requirements, you will be invited to complete a technical assessment, which will be sent to you via a direct link. Please note that we only accept applications through our job site and kindly ask that you refrain from submitting CVs via email. Thank you for your cooperation. Apply for this job Mujin Home Page Jobs powered by",2025-12-07,3.0,,3+ years,Senior,senior,Python; Computer Vision
c6ca2853-0d35-4edf-a8d3-fd32a831950a,Computer Vision Engineer,Mujininc,Mujin - Senior Computer Vision Engineer - jobs.lever.co,https://jobs.lever.co/mujininc/6e7684bf-ebb0-4cbb-92d1-0cfbcda9f376,jobs.lever.co,"Mujin - Senior Computer Vision Engineer Senior Computer Vision Engineer Best, Netherlands 1 - Software Development â€“ Computer Vision Team / Full-Time (English) / On-site Apply for this job Are you ready to shape the future of industrial robotic systems? Mujin uses robotics technology to develop smart automation solutions for logistics, material handling, and manufacturing. Our technology gives robots perception and awareness, enabling them to take on more advanced tasks by applying our unique approach to industrial robotics. Be at the forefront of groundbreaking robotics automation that challenges your skills and pushes the boundaries of what's possible. Position: Senior Computer Vision Engineer As a Computer Vision Engineer, you will be a part of the Mujin Europe R&D team, focusing on the algorithmic design, development, and deployment of computer vision applications for high-speed recognition and the worldâ€™s first 3D vision system for factory automation and logistics solutions. Responsibilities Solve cutting-edge scientific and technical challenges related to recognition and pose estimation of a very wide variety of objects in challenging scenarios Analyze and evaluate state-of-the-art algorithms related to detection and pose estimation, from academic and industrial research, and implement and enhance them in a production environment Design, develop and evaluate the performance of highly scalable and accurate real-time computer vision applications, in Python and C/C++ Perform the detailed test, carry out performance analysis on algorithms, and use continuous integration tools to finely enhance the rapidly deployed algorithms Requirements Graduated in Computer Science or a related field with a BS or MS degree and experience in computer vision, or a Ph.D. in Computer Visionâ€“related topics. Ability to develop applications and tools in Python andCï¼‹ï¼‹ 3D pose estimation of textured and texture less objects in cluttered scenes, with proven experience Python and C++ experience Experience with a vast set of computer vision libraries Mathematical background in 3D processing and statistical analysis Extras: object tracking, SLAM, computer graphics, augmented reality, machine learning, exposure to projects in robotics Minimum of 3+ years of relevant experience Willingness to travel extensively, up to 40% of the year English speaking is a requirement Practical tips on how to approach your prep including understanding the role, links, and useful sample questions: Ace your Computer Vision job interview About Mujin Our mission at Mujin is to revolutionize the industry by liberating human resources from labor-intensive duties, allowing them to focus on more intellectually challenging endeavors. Working at Mujin means working with the latest tools and technologies available in the material handling systems world. We believe in fostering a work environment that values innovation, collaboration, and personal growth. Our fast-paced, start-up mindset and international connections encourage open communication, idea-sharing, and a collective commitment to success. Why Join Our Team: Â· Competitive base salary that reflects your skills, experiences and the value you bring to our team Â· Paid time off, including vacation, sick leave and holidays Â· Access to cutting-edge technology Â· International, inclusive and collaborative work culture Â· Opportunities for career growth and advancement within the company Are you ready to be a part of the Mujin journey and shape the future of robotics in Europe? Apply via this posting with your CV and any relevant project portfolios of GitHub repositories. At Mujin, we believe in a thorough and transparent recruitment process to ensure the best fit for both the candidate and the company. After submitting your application through our job site, our team will carefully review your CV to evaluate your qualifications and experience. If your profile aligns with the roleâ€™s requirements, you will be invited to complete a technical assessment, which will be sent to you via a direct link. Please note that we only accept applications through our job site and kindly ask that you refrain from submitting CVs via email. Thank you for your cooperation. Apply for this job Mujin Home Page Jobs powered by",2025-12-07,3.0,,3+ years,Senior,senior,Python; Computer Vision
374d34ea-31fa-4817-868c-b695d011b592,Computer Vision Engineer,Mujininc,Mujin - Senior Computer Vision Engineer - jobs.lever.co,https://jobs.lever.co/mujininc/6e7684bf-ebb0-4cbb-92d1-0cfbcda9f376,jobs.lever.co,"Mujin - Senior Computer Vision Engineer Senior Computer Vision Engineer Best, Netherlands 1 - Software Development â€“ Computer Vision Team / Full-Time (English) / On-site Apply for this job Are you ready to shape the future of industrial robotic systems? Mujin uses robotics technology to develop smart automation solutions for logistics, material handling, and manufacturing. Our technology gives robots perception and awareness, enabling them to take on more advanced tasks by applying our unique approach to industrial robotics. Be at the forefront of groundbreaking robotics automation that challenges your skills and pushes the boundaries of what's possible. Position: Senior Computer Vision Engineer As a Computer Vision Engineer, you will be a part of the Mujin Europe R&D team, focusing on the algorithmic design, development, and deployment of computer vision applications for high-speed recognition and the worldâ€™s first 3D vision system for factory automation and logistics solutions. Responsibilities Solve cutting-edge scientific and technical challenges related to recognition and pose estimation of a very wide variety of objects in challenging scenarios Analyze and evaluate state-of-the-art algorithms related to detection and pose estimation, from academic and industrial research, and implement and enhance them in a production environment Design, develop and evaluate the performance of highly scalable and accurate real-time computer vision applications, in Python and C/C++ Perform the detailed test, carry out performance analysis on algorithms, and use continuous integration tools to finely enhance the rapidly deployed algorithms Requirements Graduated in Computer Science or a related field with a BS or MS degree and experience in computer vision, or a Ph.D. in Computer Visionâ€“related topics. Ability to develop applications and tools in Python andCï¼‹ï¼‹ 3D pose estimation of textured and texture less objects in cluttered scenes, with proven experience Python and C++ experience Experience with a vast set of computer vision libraries Mathematical background in 3D processing and statistical analysis Extras: object tracking, SLAM, computer graphics, augmented reality, machine learning, exposure to projects in robotics Minimum of 3+ years of relevant experience Willingness to travel extensively, up to 40% of the year English speaking is a requirement Practical tips on how to approach your prep including understanding the role, links, and useful sample questions: Ace your Computer Vision job interview About Mujin Our mission at Mujin is to revolutionize the industry by liberating human resources from labor-intensive duties, allowing them to focus on more intellectually challenging endeavors. Working at Mujin means working with the latest tools and technologies available in the material handling systems world. We believe in fostering a work environment that values innovation, collaboration, and personal growth. Our fast-paced, start-up mindset and international connections encourage open communication, idea-sharing, and a collective commitment to success. Why Join Our Team: Â· Competitive base salary that reflects your skills, experiences and the value you bring to our team Â· Paid time off, including vacation, sick leave and holidays Â· Access to cutting-edge technology Â· International, inclusive and collaborative work culture Â· Opportunities for career growth and advancement within the company Are you ready to be a part of the Mujin journey and shape the future of robotics in Europe? Apply via this posting with your CV and any relevant project portfolios of GitHub repositories. At Mujin, we believe in a thorough and transparent recruitment process to ensure the best fit for both the candidate and the company. After submitting your application through our job site, our team will carefully review your CV to evaluate your qualifications and experience. If your profile aligns with the roleâ€™s requirements, you will be invited to complete a technical assessment, which will be sent to you via a direct link. Please note that we only accept applications through our job site and kindly ask that you refrain from submitting CVs via email. Thank you for your cooperation. Apply for this job Mujin Home Page Jobs powered by",2025-12-07,3.0,,3+ years,Senior,senior,Python; Computer Vision
6fedb752-0bce-43e0-9865-26a6b49aae98,NLP Engineer,...,Increasingly Lead NLP Engineer | SmartRecruiters LeoTech - AI/NLP Engineer AI/NLP Engineer - Generative AI Applications for Enterprise ... Job Application for Senior Machine Learning Engineer at ...,https://jobs.smartrecruiters.com/Increasingly/743999949657842-lead-nlp-engineer,jobs.smartrecruiters.com,"Increasingly Lead NLP Engineer | SmartRecruiters Google Chrome Microsoft Edge Apple Safari Mozilla Firefox Lead NLP Engineer Full-time Company Description About Increasingly Increasingly is an award-winning, fast-growing retail technology company focused specifically on the automation of cross-selling for online retailers. Our clients include large global corporations like Samsung & Canon to several small to medium size retailers across the globe. Our AI-based algorithms help a customer buying a TV on Samsung to find the matching sound bar & purchase both together. Increasingly is headquartered in London with offices in Lisbon & Bangalore. We work with clients in over 30 countries & 20 languages. We are looking to rapidly expand our technology & product development operations in India. And we need smart, ambitious people like you who enjoy a fun yet challenging work environment. We believe strongly that diversity & inclusion are the foundations for a lasting, incredible culture. We also believe that itâ€™s important to get the balance right between work & life. Job Description NLP Engineer responsibilities include transforming natural language data into useful features using NLP techniques to feed classification algorithms. To succeed in this role, you should possess outstanding skills in statistical analysis, machine learning methods and text representation techniques. Responsibilities Your ultimate goal is to develop efficient self-learning NLP Search. You will design NLP search algorithms & proof of concepts. You will select appropriate annotated datasets for Supervised Learning methods You will use effective text representations to transform natural language into useful features Find and implement the right algorithms and tools for NLP tasks Develop NLP systems according to requirements Train the developed model and run evaluation experiments Perform statistical analysis of results and refine models Extend ML libraries and frameworks to apply in NLP tasks Study and transform data science prototypes Qualifications We would love it if you have BS/MS in Computer Science, Mathematics, Computational Linguistics or similar field Must have 7+ years in elastic search 2+ years of proven experience as an NLP Engineer NLP techniques for text representation, semantic extraction techniques, data structures and modeling Ability to effectively design software architecture Deep understanding of text representation techniques (such as n-grams, a bag of words, sentiment analysis etc), statistics and classification algorithms Good to have: Knowledge of Python, Java and R Ability to write robust and testable code Experience with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn) An analytical mind with problem-solving abilities Additional Information What are the benefits You'll get to work in one of the hottest & fastest-growing retail technologies in Europe right now. You'll get paid a competitive salary & be working directly with a super-experienced team of people. You'll get a great place to come to work every day. Varied, complex, challenging & with a great culture that you can shape & change. Group Health Insurance Job Location Google Maps requires functional cookies to be enabled Sorry, this job has expired Sorry, this job has expired Posted by L V share this job",2025-12-07,7.0,,7+ years,Lead,lead,Python; Deep Learning; NLP
b53ece8e-5061-4170-aa77-05bd848120e8,NLP Engineer,Leotechnologies,LeoTech - AI/NLP Engineer,https://jobs.lever.co/LEOTechnologies/193c2ab7-ed6d-4d01-9d49-e2614bf000ba,jobs.lever.co,"LeoTech - AI/NLP Engineer AI/NLP Engineer Irvine, CA Data Science/ML / Fulltime / Remote Apply for this job At LeoTech, we are passionate about building software that solves real-world problems in the Public Safety sector. Our software has been used to help the fight against continuing criminal enterprises, drug trafficking organizations, identifying financial fraud, disrupting sex and human trafficking rings and focusing on mental health matters to name a few. As an AI/NLP Engineer on our Data Science team, you will be at the forefront of leveraging Large Language Models (LLMs) and cutting-edge AI techniques to create transformative solutions for public safety and intelligence workflows. You will apply your expertise in LLMs, Retrieval-Augmented Generation (RAG), semantic search, Agentic AI, GraphRAG, and other advanced AI solutions to develop, enhance, and deploy robust features that enable real-time decision-making for our end users. You will work closely with product, engineering, and data science teams to translate real-world problems into scalable, production-grade solutions. This is an individual contributor (IC) role that emphasizes technical depth, experimentation, and hands-on engineering. You will participate in all phases of the AI solution lifecycle, from architecture and design through prototyping, implementation, evaluation, productionization and continuous improvement. Core Responsibilities Design, build, and optimize AI-powered solutions using LLMs, RAG pipelines, semantic search, GraphRAG, and Agentic AI architectures. Implement and experiment with the latest advancements in large-scale language modeling, including prompt engineering, model fine-tuning, evaluation, and monitoring. Collaborate with product, backend, and data engineering teams to define requirements, break down complex problems, and deliver high-impact features aligned with business objectives. Inform robust data ingestion and retrieval pipelines that power real-time and batch AI applications using open-source and proprietary tools. Integrate external data sources (e.g., knowledge graphs, internal databases, third-party APIs) to enhance the context-awareness and capabilities of LLM-based workflows. Evaluate and implement best practices for prompt design, model alignment, safety, and guardrails for responsible AI deployment. Stay on top of emerging AI research and contribute to internal knowledge-sharing, tech talks, and proof-of-concept projects. Author clean, well-documented, and testable code; participate in peer code reviews and engineering design discussions. Proactively identify bottlenecks and propose solutions to improve system scalability, efficiency, and reliability. What We Value Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Data Science, or a related field. 5+ years of hands-on experience in applied AI, NLP, or ML engineering (with at least 2 years working directly with LLMs, RAG, semantic search and Agentic AI). Deep familiarity with LLMs (e.g. OpenAI, Claude, Gemini), prompt engineering, and responsible deployment in production settings. Experience designing, building, and optimizing RAG pipelines, semantic search, vector databases (e.g. ElasticSearch, Pinecone), and Agentic or multi-agent AI workflows in in large scale production setup. Exposure to MCP and A2A protocol is a plus. Exposure to GraphRAG or graph-based knowledge retrieval techniques is a strong plus. Strong proficiency with modern ML frameworks and libraries (e.g. LangChain, LlamaIndex, PyTorch, HuggingFace Transformers). Ability to design APIs and scalable backend services, with hands-on experience in Python. Experience building, deploying, and monitoring AI/ML workloads in cloud environments (AWS, Azure) using services like AWS SageMaker, AWS Bedrock, AzureAI, etc. Experience with tools to load balance different LLMs providers is a plus. Familiarity with MLOps practices, CI/CD for AI, model monitoring, data versioning, and continuous integration. Demonstrated ability to work with large, complex datasets, perform data cleaning, feature engineering, and develop scalable data pipelines. Excellent problem-solving, collaboration, and communication skills; able to work effectively across remote and distributed teams. Proven record of shipping robust, high-impact AI solutions, ideally in fast-paced or regulated environments. Technologies We Use Cloud & AI Platforms: AWS (Bedrock, SageMaker, Lambda), AzureAI, Pinecone, ElasticCloud, Imply Polaris. LLMs & NLP: HuggingFace, OpenAI API, LangChain, LlamaIndex, Cohere, Anthropic. Backend: Python (primary), Elixir (other teams). Data Infrastructure: ElasticSearch, Pinecone, Weaviate, Apache Kafka, Airflow. Frontend: TypeScript, React. DevOps & Automation: Terraform, EKS, GitHub Actions, CodePipeline, ArgoCD. Monitoring & Metrics: Grafana (metrics dashboards, alerting), Langfuse (Agentic AI observability, prompt management) Testing: Playwright for end-to-end test automation. Other ",2025-12-07,5.0,,5+ years,Unspecified,,Python; Deep Learning; APIs & Microservices; NLP; Generative AI
7e5df2ec-0abb-4756-9356-de5e1b289bbf,NLP Engineer,...,Increasingly Lead NLP Engineer | SmartRecruiters LeoTech - AI/NLP Engineer AI/NLP Engineer - Generative AI Applications for Enterprise ... Job Application for Senior Machine Learning Engineer at ...,https://jobs.smartrecruiters.com/Increasingly/743999949657842-lead-nlp-engineer,jobs.smartrecruiters.com,"Increasingly Lead NLP Engineer | SmartRecruiters Google Chrome Microsoft Edge Apple Safari Mozilla Firefox Lead NLP Engineer Full-time Company Description About Increasingly Increasingly is an award-winning, fast-growing retail technology company focused specifically on the automation of cross-selling for online retailers. Our clients include large global corporations like Samsung & Canon to several small to medium size retailers across the globe. Our AI-based algorithms help a customer buying a TV on Samsung to find the matching sound bar & purchase both together. Increasingly is headquartered in London with offices in Lisbon & Bangalore. We work with clients in over 30 countries & 20 languages. We are looking to rapidly expand our technology & product development operations in India. And we need smart, ambitious people like you who enjoy a fun yet challenging work environment. We believe strongly that diversity & inclusion are the foundations for a lasting, incredible culture. We also believe that itâ€™s important to get the balance right between work & life. Job Description NLP Engineer responsibilities include transforming natural language data into useful features using NLP techniques to feed classification algorithms. To succeed in this role, you should possess outstanding skills in statistical analysis, machine learning methods and text representation techniques. Responsibilities Your ultimate goal is to develop efficient self-learning NLP Search. You will design NLP search algorithms & proof of concepts. You will select appropriate annotated datasets for Supervised Learning methods You will use effective text representations to transform natural language into useful features Find and implement the right algorithms and tools for NLP tasks Develop NLP systems according to requirements Train the developed model and run evaluation experiments Perform statistical analysis of results and refine models Extend ML libraries and frameworks to apply in NLP tasks Study and transform data science prototypes Qualifications We would love it if you have BS/MS in Computer Science, Mathematics, Computational Linguistics or similar field Must have 7+ years in elastic search 2+ years of proven experience as an NLP Engineer NLP techniques for text representation, semantic extraction techniques, data structures and modeling Ability to effectively design software architecture Deep understanding of text representation techniques (such as n-grams, a bag of words, sentiment analysis etc), statistics and classification algorithms Good to have: Knowledge of Python, Java and R Ability to write robust and testable code Experience with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn) An analytical mind with problem-solving abilities Additional Information What are the benefits You'll get to work in one of the hottest & fastest-growing retail technologies in Europe right now. You'll get paid a competitive salary & be working directly with a super-experienced team of people. You'll get a great place to come to work every day. Varied, complex, challenging & with a great culture that you can shape & change. Group Health Insurance Job Location Google Maps requires functional cookies to be enabled Sorry, this job has expired Sorry, this job has expired Posted by L V share this job",2025-12-07,7.0,,7+ years,Lead,lead,Python; Deep Learning; NLP
c0d47662-af59-4323-9fb4-e991b62f1b99,NLP Engineer,Leotechnologies,LeoTech - AI/NLP Engineer,https://jobs.lever.co/LEOTechnologies/193c2ab7-ed6d-4d01-9d49-e2614bf000ba,jobs.lever.co,"LeoTech - AI/NLP Engineer AI/NLP Engineer Irvine, CA Data Science/ML / Fulltime / Remote Apply for this job At LeoTech, we are passionate about building software that solves real-world problems in the Public Safety sector. Our software has been used to help the fight against continuing criminal enterprises, drug trafficking organizations, identifying financial fraud, disrupting sex and human trafficking rings and focusing on mental health matters to name a few. As an AI/NLP Engineer on our Data Science team, you will be at the forefront of leveraging Large Language Models (LLMs) and cutting-edge AI techniques to create transformative solutions for public safety and intelligence workflows. You will apply your expertise in LLMs, Retrieval-Augmented Generation (RAG), semantic search, Agentic AI, GraphRAG, and other advanced AI solutions to develop, enhance, and deploy robust features that enable real-time decision-making for our end users. You will work closely with product, engineering, and data science teams to translate real-world problems into scalable, production-grade solutions. This is an individual contributor (IC) role that emphasizes technical depth, experimentation, and hands-on engineering. You will participate in all phases of the AI solution lifecycle, from architecture and design through prototyping, implementation, evaluation, productionization and continuous improvement. Core Responsibilities Design, build, and optimize AI-powered solutions using LLMs, RAG pipelines, semantic search, GraphRAG, and Agentic AI architectures. Implement and experiment with the latest advancements in large-scale language modeling, including prompt engineering, model fine-tuning, evaluation, and monitoring. Collaborate with product, backend, and data engineering teams to define requirements, break down complex problems, and deliver high-impact features aligned with business objectives. Inform robust data ingestion and retrieval pipelines that power real-time and batch AI applications using open-source and proprietary tools. Integrate external data sources (e.g., knowledge graphs, internal databases, third-party APIs) to enhance the context-awareness and capabilities of LLM-based workflows. Evaluate and implement best practices for prompt design, model alignment, safety, and guardrails for responsible AI deployment. Stay on top of emerging AI research and contribute to internal knowledge-sharing, tech talks, and proof-of-concept projects. Author clean, well-documented, and testable code; participate in peer code reviews and engineering design discussions. Proactively identify bottlenecks and propose solutions to improve system scalability, efficiency, and reliability. What We Value Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Data Science, or a related field. 5+ years of hands-on experience in applied AI, NLP, or ML engineering (with at least 2 years working directly with LLMs, RAG, semantic search and Agentic AI). Deep familiarity with LLMs (e.g. OpenAI, Claude, Gemini), prompt engineering, and responsible deployment in production settings. Experience designing, building, and optimizing RAG pipelines, semantic search, vector databases (e.g. ElasticSearch, Pinecone), and Agentic or multi-agent AI workflows in in large scale production setup. Exposure to MCP and A2A protocol is a plus. Exposure to GraphRAG or graph-based knowledge retrieval techniques is a strong plus. Strong proficiency with modern ML frameworks and libraries (e.g. LangChain, LlamaIndex, PyTorch, HuggingFace Transformers). Ability to design APIs and scalable backend services, with hands-on experience in Python. Experience building, deploying, and monitoring AI/ML workloads in cloud environments (AWS, Azure) using services like AWS SageMaker, AWS Bedrock, AzureAI, etc. Experience with tools to load balance different LLMs providers is a plus. Familiarity with MLOps practices, CI/CD for AI, model monitoring, data versioning, and continuous integration. Demonstrated ability to work with large, complex datasets, perform data cleaning, feature engineering, and develop scalable data pipelines. Excellent problem-solving, collaboration, and communication skills; able to work effectively across remote and distributed teams. Proven record of shipping robust, high-impact AI solutions, ideally in fast-paced or regulated environments. Technologies We Use Cloud & AI Platforms: AWS (Bedrock, SageMaker, Lambda), AzureAI, Pinecone, ElasticCloud, Imply Polaris. LLMs & NLP: HuggingFace, OpenAI API, LangChain, LlamaIndex, Cohere, Anthropic. Backend: Python (primary), Elixir (other teams). Data Infrastructure: ElasticSearch, Pinecone, Weaviate, Apache Kafka, Airflow. Frontend: TypeScript, React. DevOps & Automation: Terraform, EKS, GitHub Actions, CodePipeline, ArgoCD. Monitoring & Metrics: Grafana (metrics dashboards, alerting), Langfuse (Agentic AI observability, prompt management) Testing: Playwright for end-to-end test automation. Other ",2025-12-07,5.0,,5+ years,Unspecified,,Python; Deep Learning; APIs & Microservices; NLP; Generative AI
8569c762-f382-4cbd-a952-c7339e58b6a3,NLP Engineer,...,Increasingly Lead NLP Engineer | SmartRecruiters LeoTech - AI/NLP Engineer AI/NLP Engineer - Generative AI Applications for Enterprise ... Job Application for Senior Machine Learning Engineer at ...,https://jobs.smartrecruiters.com/Increasingly/743999949657842-lead-nlp-engineer,jobs.smartrecruiters.com,"Increasingly Lead NLP Engineer | SmartRecruiters Google Chrome Microsoft Edge Apple Safari Mozilla Firefox Lead NLP Engineer Full-time Company Description About Increasingly Increasingly is an award-winning, fast-growing retail technology company focused specifically on the automation of cross-selling for online retailers. Our clients include large global corporations like Samsung & Canon to several small to medium size retailers across the globe. Our AI-based algorithms help a customer buying a TV on Samsung to find the matching sound bar & purchase both together. Increasingly is headquartered in London with offices in Lisbon & Bangalore. We work with clients in over 30 countries & 20 languages. We are looking to rapidly expand our technology & product development operations in India. And we need smart, ambitious people like you who enjoy a fun yet challenging work environment. We believe strongly that diversity & inclusion are the foundations for a lasting, incredible culture. We also believe that itâ€™s important to get the balance right between work & life. Job Description NLP Engineer responsibilities include transforming natural language data into useful features using NLP techniques to feed classification algorithms. To succeed in this role, you should possess outstanding skills in statistical analysis, machine learning methods and text representation techniques. Responsibilities Your ultimate goal is to develop efficient self-learning NLP Search. You will design NLP search algorithms & proof of concepts. You will select appropriate annotated datasets for Supervised Learning methods You will use effective text representations to transform natural language into useful features Find and implement the right algorithms and tools for NLP tasks Develop NLP systems according to requirements Train the developed model and run evaluation experiments Perform statistical analysis of results and refine models Extend ML libraries and frameworks to apply in NLP tasks Study and transform data science prototypes Qualifications We would love it if you have BS/MS in Computer Science, Mathematics, Computational Linguistics or similar field Must have 7+ years in elastic search 2+ years of proven experience as an NLP Engineer NLP techniques for text representation, semantic extraction techniques, data structures and modeling Ability to effectively design software architecture Deep understanding of text representation techniques (such as n-grams, a bag of words, sentiment analysis etc), statistics and classification algorithms Good to have: Knowledge of Python, Java and R Ability to write robust and testable code Experience with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn) An analytical mind with problem-solving abilities Additional Information What are the benefits You'll get to work in one of the hottest & fastest-growing retail technologies in Europe right now. You'll get paid a competitive salary & be working directly with a super-experienced team of people. You'll get a great place to come to work every day. Varied, complex, challenging & with a great culture that you can shape & change. Group Health Insurance Job Location Google Maps requires functional cookies to be enabled Sorry, this job has expired Sorry, this job has expired Posted by L V share this job",2025-12-07,7.0,,7+ years,Lead,lead,Python; Deep Learning; NLP
ae894a04-ff9e-45d4-9742-4c47d977c056,NLP Engineer,Leotechnologies,LeoTech - AI/NLP Engineer,https://jobs.lever.co/LEOTechnologies/193c2ab7-ed6d-4d01-9d49-e2614bf000ba,jobs.lever.co,"LeoTech - AI/NLP Engineer AI/NLP Engineer Irvine, CA Data Science/ML / Fulltime / Remote Apply for this job At LeoTech, we are passionate about building software that solves real-world problems in the Public Safety sector. Our software has been used to help the fight against continuing criminal enterprises, drug trafficking organizations, identifying financial fraud, disrupting sex and human trafficking rings and focusing on mental health matters to name a few. As an AI/NLP Engineer on our Data Science team, you will be at the forefront of leveraging Large Language Models (LLMs) and cutting-edge AI techniques to create transformative solutions for public safety and intelligence workflows. You will apply your expertise in LLMs, Retrieval-Augmented Generation (RAG), semantic search, Agentic AI, GraphRAG, and other advanced AI solutions to develop, enhance, and deploy robust features that enable real-time decision-making for our end users. You will work closely with product, engineering, and data science teams to translate real-world problems into scalable, production-grade solutions. This is an individual contributor (IC) role that emphasizes technical depth, experimentation, and hands-on engineering. You will participate in all phases of the AI solution lifecycle, from architecture and design through prototyping, implementation, evaluation, productionization and continuous improvement. Core Responsibilities Design, build, and optimize AI-powered solutions using LLMs, RAG pipelines, semantic search, GraphRAG, and Agentic AI architectures. Implement and experiment with the latest advancements in large-scale language modeling, including prompt engineering, model fine-tuning, evaluation, and monitoring. Collaborate with product, backend, and data engineering teams to define requirements, break down complex problems, and deliver high-impact features aligned with business objectives. Inform robust data ingestion and retrieval pipelines that power real-time and batch AI applications using open-source and proprietary tools. Integrate external data sources (e.g., knowledge graphs, internal databases, third-party APIs) to enhance the context-awareness and capabilities of LLM-based workflows. Evaluate and implement best practices for prompt design, model alignment, safety, and guardrails for responsible AI deployment. Stay on top of emerging AI research and contribute to internal knowledge-sharing, tech talks, and proof-of-concept projects. Author clean, well-documented, and testable code; participate in peer code reviews and engineering design discussions. Proactively identify bottlenecks and propose solutions to improve system scalability, efficiency, and reliability. What We Value Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Data Science, or a related field. 5+ years of hands-on experience in applied AI, NLP, or ML engineering (with at least 2 years working directly with LLMs, RAG, semantic search and Agentic AI). Deep familiarity with LLMs (e.g. OpenAI, Claude, Gemini), prompt engineering, and responsible deployment in production settings. Experience designing, building, and optimizing RAG pipelines, semantic search, vector databases (e.g. ElasticSearch, Pinecone), and Agentic or multi-agent AI workflows in in large scale production setup. Exposure to MCP and A2A protocol is a plus. Exposure to GraphRAG or graph-based knowledge retrieval techniques is a strong plus. Strong proficiency with modern ML frameworks and libraries (e.g. LangChain, LlamaIndex, PyTorch, HuggingFace Transformers). Ability to design APIs and scalable backend services, with hands-on experience in Python. Experience building, deploying, and monitoring AI/ML workloads in cloud environments (AWS, Azure) using services like AWS SageMaker, AWS Bedrock, AzureAI, etc. Experience with tools to load balance different LLMs providers is a plus. Familiarity with MLOps practices, CI/CD for AI, model monitoring, data versioning, and continuous integration. Demonstrated ability to work with large, complex datasets, perform data cleaning, feature engineering, and develop scalable data pipelines. Excellent problem-solving, collaboration, and communication skills; able to work effectively across remote and distributed teams. Proven record of shipping robust, high-impact AI solutions, ideally in fast-paced or regulated environments. Technologies We Use Cloud & AI Platforms: AWS (Bedrock, SageMaker, Lambda), AzureAI, Pinecone, ElasticCloud, Imply Polaris. LLMs & NLP: HuggingFace, OpenAI API, LangChain, LlamaIndex, Cohere, Anthropic. Backend: Python (primary), Elixir (other teams). Data Infrastructure: ElasticSearch, Pinecone, Weaviate, Apache Kafka, Airflow. Frontend: TypeScript, React. DevOps & Automation: Terraform, EKS, GitHub Actions, CodePipeline, ArgoCD. Monitoring & Metrics: Grafana (metrics dashboards, alerting), Langfuse (Agentic AI observability, prompt management) Testing: Playwright for end-to-end test automation. Other ",2025-12-07,5.0,,5+ years,Unspecified,,Python; Deep Learning; APIs & Microservices; NLP; Generative AI
b4e23f9f-f12c-4496-9268-e1fd42d83bab,AI Product Manager,Mistral,"Mistral AI - Product Manager, AI Assistant - jobs.lever.co",https://jobs.lever.co/mistral/17451d76-dd74-4a01-8959-c2a9e18b19de,jobs.lever.co,"Mistral AI - Product Manager, AI Assistant Product Manager, AI Assistant Paris / London Product / Full-time / Hybrid Apply for this job About Mistral At Mistral AI, we believe in the power of AI to simplify tasks, save time, and enhance learning and creativity. Our technology is designed to integrate seamlessly into daily working life. We democratize AI through high-performance, optimized, open-source and cutting-edge models, products and solutions. Our comprehensive AI platform is designed to meet enterprise needs, whether on-premises or in cloud environments. Our offerings include le Chat, the AI assistant for life and work. We are a dynamic, collaborative team passionate about AI and its potential to transform society. Our diverse workforce thrives in competitive environments and is committed to driving innovation. Our teams are distributed between France, USA, UK, Germany and Singapore. We are creative, low-ego and team-spirited. Join us to be part of a pioneering company shaping the future of AI. Together, we can make a meaningful impact. See more about our culture on https://mistral.ai/careers . Role summary Weâ€™re seeking strategic and execution-focused product managers to define and execute the strategy for the primary interfaces through which professionals engage with our models. This role demands a blend of strategic vision, technical depth, business acumen and user obsession to build experiences that empower millions â€” from professional consumers (""prosumers"") to enterprise users. Youâ€™ll shape the next generation of AI-driven productivity tools, moving beyond conversational experiences to redefine how professionals interact with information and create content. ðŸ§¢ Reporting line: Product Director, Applications ðŸ“ Location: Paris or London What you will do Define the Future â€¢ Set the vision: Shape and evangelize a compelling product strategy for prosumer and enterprise-grade AI tools, ensuring alignment with company goals and market opportunities. â€¢ Spot the gaps: Lead market and UX research to uncover unmet needs, competitive whitespaces, and emerging trends in AI-driven productivity. Build & Ship â€¢ Own the lifecycle: Drive end-to-end product development, from ideation to launch and iterationâ€”balancing speed, quality, and user delight. â€¢ Champion the user: Partner with design and research to craft intuitive, high-impact experiences, using data and feedback to refine continuously. Scale & Execute â€¢ Go-to-market: Collaborate with marketing and sales to launch products successfully, including pricing, positioning, and adoption strategies. â€¢ Align stakeholders: Rally engineering, design, and business teams around priorities, trade-offs, and timelines. â€¢ Prioritize ruthlessly: Maintain a dynamic roadmap that delivers quick wins while advancing long-term bets. Required Qualifications â€¢ Product Management : 5+ years of relevant experience with a focus on building productivity-related products and/or enterprise-grade features (B2B/B2B2C) â€¢ Problem-solving : Experience solving hard problems in dynamic, competitive and ambiguous environments â€¢ AI/ML fluency : Hands-on experience with generative AI, LLMs, or ML-driven products â€” you understand technical trade-offs and can partner effectively with engineering teams. â€¢ Growth mindset : Deep familiarity with product-led growth strategies (e.g., viral loops, onboarding optimization, monetization, AARRR, etc.). â€¢ User obsession : Relentless focus on solving real user problems, backed by data and qualitative insights. â€¢ Cross-functional influence : Proven ability to align and inspire engineering, design, and go-to-market teams without direct authority. â€¢ Pragmatism: Balance big-picture thinking with hands-on problem-solving â€” youâ€™re equally comfortable crafting a roadmap and diving into metrics. â€¢ Communication : Crisp, persuasive storytelling for executives, teams, and usersâ€”whether in docs, decks, or whiteboard sessions. â€¢ Adaptability : Thrive in high-velocity, dynamic settings where priorities shift quickly. â€¢ Collaboration : Low ego + high EQ â€” you build trust and drive decisions through clarity, not hierarchy. â€¢ Autonomy : Self-directed with a bias for action, you own outcomes end-to-end. Now, it would be ideal if you have: â€¢ AI product intuition: Hands-on experience shipping generative AI consumer products â€” youâ€™ve seen what works (and what doesnâ€™t) beyond chatbots. â€¢ Builderâ€™s mindset: Founder or early-stage PM experience â€” youâ€™ve turned 0 â†’ 1 ideas into products users love. â€¢ Technical depth: Ability to prototype, hack, or dive into code when needed (even if not a core responsibility). Location This role is based in one of the following offices: ðŸ‡«ðŸ‡· Paris, France ðŸ‡¬ðŸ‡§ London, UK ðŸ‡ºðŸ‡¸ New York, USA We will only consider candidates who either reside or are open to relocating there. We strongly believe in the value of in-person collaboration and we encourage going to the office as much as we can (at least 3 days per week) to create bonds and smooth communication. Ou",2025-12-07,5.0,,5+ years,Director,director,Machine Learning; Generative AI
7bc056df-de19-4a4b-9e28-dab1e1d83901,AI Product Manager,Mistral,"Mistral AI - Product Manager, Document Intellegence",https://jobs.lever.co/mistral/7809b483-bdae-4964-97c7-5b8d232a142f,jobs.lever.co,"Mistral AI - Product Manager, Document Intelligence Product Manager, Document Intelligence New York Product / Full-time / Hybrid Apply for this job About Mistral At Mistral AI, we believe in the power of AI to simplify tasks, save time, and enhance learning and creativity. Our technology is designed to integrate seamlessly into daily working life. We democratize AI through high-performance, optimized, open-source and cutting-edge models, products and solutions. Our comprehensive AI platform is designed to meet enterprise as well as personal needs. Our offerings include Le Chat, La Plateforme, Mistral Code and Mistral Compute - a suite that brings frontier intelligence to end-users. We are a dynamic, collaborative team passionate about AI and its potential to transform society. Our diverse workforce thrives in competitive environments and is committed to driving innovation. Our teams are distributed between France, USA, UK, Germany and Singapore. We are creative, low-ego and team-spirited. Join us to be part of a pioneering company shaping the future of AI. Together, we can make a meaningful impact. See more about our culture on https://mistral.ai/careers. Role summary Weâ€™re seeking strategic and execution-focused product managers to define and execute the strategy for the primary interface through which professionals engage with our models. This role demands a blend of strategic vision, technical depth, business acumen and user obsession to build experiences that empower millions â€” from professional consumers (""prosumers"") to enterprise users. Youâ€™ll shape the next generation of AI-driven productivity tools, moving beyond conversational experiences to redefine how professionals interact with information and create content. ðŸ§¢ Reporting line: Product Director, Applications ðŸ“ Location: NYC What you will do Define the Future â€¢ Set the vision: Shape and evangelize a compelling product strategy for prosumer and enterprise-grade AI tools, ensuring alignment with company goals and market opportunities. â€¢ Spot the gaps: Lead market and UX research to uncover unmet needs, competitive whitespaces, and emerging trends in AI-driven productivity. Build & Ship â€¢ Own the lifecycle: Drive end-to-end product development, from ideation to launch and iterationâ€”balancing speed, quality, and user delight. â€¢ Champion the user: Partner with design and research to craft intuitive, high-impact experiences, using data and feedback to refine continuously. Scale & Execute â€¢ Go-to-market: Collaborate with marketing and sales to launch products successfully, including pricing, positioning, and adoption strategies. â€¢ Align stakeholders: Rally engineering, design, and business teams around priorities, trade-offs, and timelines. â€¢ Prioritize ruthlessly: Maintain a dynamic roadmap that delivers quick wins while advancing long-term bets. Required Qualifications â€¢ Product Management : 5+ years of relevant experience with a focus on building productivity-related products and/or enterprise-grade features (B2B/B2B2C) â€¢ Problem-solving : Experience solving hard problems in dynamic, competitive and ambiguous environments â€¢ AI/ML fluency : Hands-on experience with generative AI, LLMs, or ML-driven products â€” you understand technical trade-offs and can partner effectively with engineering teams. â€¢ Growth mindset : Deep familiarity with product-led growth strategies (e.g., viral loops, onboarding optimization, monetization, AARRR, etc.). â€¢ User obsession : Relentless focus on solving real user problems, backed by data and qualitative insights. â€¢ Cross-functional influence : Proven ability to align and inspire engineering, design, and go-to-market teams without direct authority. â€¢ Pragmatism: Balance big-picture thinking with hands-on problem-solving â€” youâ€™re equally comfortable crafting a roadmap and diving into metrics. â€¢ Communication : Crisp, persuasive storytelling for executives, teams, and usersâ€”whether in docs, decks, or whiteboard sessions. â€¢ Adaptability : Thrive in high-velocity, dynamic settings where priorities shift quickly. â€¢ Collaboration : Low ego + high EQ â€” you build trust and drive decisions through clarity, not hierarchy. â€¢ Autonomy : Self-directed with a bias for action, you own outcomes end-to-end. Now, it would be ideal if you have: â€¢ AI product intuition: Hands-on experience shipping generative AI consumer products â€” youâ€™ve seen what works (and what doesnâ€™t) beyond chatbots. â€¢ Builderâ€™s mindset: Founder or early-stage PM experience â€” youâ€™ve turned 0 â†’ 1 ideas into products users love. â€¢ Technical depth: Ability to prototype, hack, or dive into code when needed (even if not a core responsibility). What we offer ðŸ’° Competitive salary and equity. ðŸš‘ Healthcare: Medical/Dental/Vision covered for you and your family. ðŸ‘´ðŸ» Pension : 401K (6% matching) ðŸï¸ PTO : 18 days ðŸš— Transportation: Reimburse office parking charges, or $120/month for public transport ðŸ€ Sport: $120/month reimbursement for gym membership ðŸ¥• Meal stipend: $400 monthly all",2025-12-07,5.0,,5+ years,Director,director,Machine Learning; Generative AI
3b57dfdc-724b-46f5-a409-ba8ad489f654,AI Product Manager,Mistral,"Mistral AI - Product Manager, AI Assistant - jobs.lever.co",https://jobs.lever.co/mistral/17451d76-dd74-4a01-8959-c2a9e18b19de,jobs.lever.co,"Mistral AI - Product Manager, AI Assistant Product Manager, AI Assistant Paris / London Product / Full-time / Hybrid Apply for this job About Mistral At Mistral AI, we believe in the power of AI to simplify tasks, save time, and enhance learning and creativity. Our technology is designed to integrate seamlessly into daily working life. We democratize AI through high-performance, optimized, open-source and cutting-edge models, products and solutions. Our comprehensive AI platform is designed to meet enterprise needs, whether on-premises or in cloud environments. Our offerings include le Chat, the AI assistant for life and work. We are a dynamic, collaborative team passionate about AI and its potential to transform society. Our diverse workforce thrives in competitive environments and is committed to driving innovation. Our teams are distributed between France, USA, UK, Germany and Singapore. We are creative, low-ego and team-spirited. Join us to be part of a pioneering company shaping the future of AI. Together, we can make a meaningful impact. See more about our culture on https://mistral.ai/careers . Role summary Weâ€™re seeking strategic and execution-focused product managers to define and execute the strategy for the primary interfaces through which professionals engage with our models. This role demands a blend of strategic vision, technical depth, business acumen and user obsession to build experiences that empower millions â€” from professional consumers (""prosumers"") to enterprise users. Youâ€™ll shape the next generation of AI-driven productivity tools, moving beyond conversational experiences to redefine how professionals interact with information and create content. ðŸ§¢ Reporting line: Product Director, Applications ðŸ“ Location: Paris or London What you will do Define the Future â€¢ Set the vision: Shape and evangelize a compelling product strategy for prosumer and enterprise-grade AI tools, ensuring alignment with company goals and market opportunities. â€¢ Spot the gaps: Lead market and UX research to uncover unmet needs, competitive whitespaces, and emerging trends in AI-driven productivity. Build & Ship â€¢ Own the lifecycle: Drive end-to-end product development, from ideation to launch and iterationâ€”balancing speed, quality, and user delight. â€¢ Champion the user: Partner with design and research to craft intuitive, high-impact experiences, using data and feedback to refine continuously. Scale & Execute â€¢ Go-to-market: Collaborate with marketing and sales to launch products successfully, including pricing, positioning, and adoption strategies. â€¢ Align stakeholders: Rally engineering, design, and business teams around priorities, trade-offs, and timelines. â€¢ Prioritize ruthlessly: Maintain a dynamic roadmap that delivers quick wins while advancing long-term bets. Required Qualifications â€¢ Product Management : 5+ years of relevant experience with a focus on building productivity-related products and/or enterprise-grade features (B2B/B2B2C) â€¢ Problem-solving : Experience solving hard problems in dynamic, competitive and ambiguous environments â€¢ AI/ML fluency : Hands-on experience with generative AI, LLMs, or ML-driven products â€” you understand technical trade-offs and can partner effectively with engineering teams. â€¢ Growth mindset : Deep familiarity with product-led growth strategies (e.g., viral loops, onboarding optimization, monetization, AARRR, etc.). â€¢ User obsession : Relentless focus on solving real user problems, backed by data and qualitative insights. â€¢ Cross-functional influence : Proven ability to align and inspire engineering, design, and go-to-market teams without direct authority. â€¢ Pragmatism: Balance big-picture thinking with hands-on problem-solving â€” youâ€™re equally comfortable crafting a roadmap and diving into metrics. â€¢ Communication : Crisp, persuasive storytelling for executives, teams, and usersâ€”whether in docs, decks, or whiteboard sessions. â€¢ Adaptability : Thrive in high-velocity, dynamic settings where priorities shift quickly. â€¢ Collaboration : Low ego + high EQ â€” you build trust and drive decisions through clarity, not hierarchy. â€¢ Autonomy : Self-directed with a bias for action, you own outcomes end-to-end. Now, it would be ideal if you have: â€¢ AI product intuition: Hands-on experience shipping generative AI consumer products â€” youâ€™ve seen what works (and what doesnâ€™t) beyond chatbots. â€¢ Builderâ€™s mindset: Founder or early-stage PM experience â€” youâ€™ve turned 0 â†’ 1 ideas into products users love. â€¢ Technical depth: Ability to prototype, hack, or dive into code when needed (even if not a core responsibility). Location This role is based in one of the following offices: ðŸ‡«ðŸ‡· Paris, France ðŸ‡¬ðŸ‡§ London, UK ðŸ‡ºðŸ‡¸ New York, USA We will only consider candidates who either reside or are open to relocating there. We strongly believe in the value of in-person collaboration and we encourage going to the office as much as we can (at least 3 days per week) to create bonds and smooth communication. Ou",2025-12-07,5.0,,5+ years,Director,director,Machine Learning; Generative AI
0a48f748-1869-45db-adc1-7096ced38199,AI Product Manager,Mistral,"Mistral AI - Product Manager, Document Intellegence",https://jobs.lever.co/mistral/7809b483-bdae-4964-97c7-5b8d232a142f,jobs.lever.co,"Mistral AI - Product Manager, Document Intelligence Product Manager, Document Intelligence New York Product / Full-time / Hybrid Apply for this job About Mistral At Mistral AI, we believe in the power of AI to simplify tasks, save time, and enhance learning and creativity. Our technology is designed to integrate seamlessly into daily working life. We democratize AI through high-performance, optimized, open-source and cutting-edge models, products and solutions. Our comprehensive AI platform is designed to meet enterprise as well as personal needs. Our offerings include Le Chat, La Plateforme, Mistral Code and Mistral Compute - a suite that brings frontier intelligence to end-users. We are a dynamic, collaborative team passionate about AI and its potential to transform society. Our diverse workforce thrives in competitive environments and is committed to driving innovation. Our teams are distributed between France, USA, UK, Germany and Singapore. We are creative, low-ego and team-spirited. Join us to be part of a pioneering company shaping the future of AI. Together, we can make a meaningful impact. See more about our culture on https://mistral.ai/careers. Role summary Weâ€™re seeking strategic and execution-focused product managers to define and execute the strategy for the primary interface through which professionals engage with our models. This role demands a blend of strategic vision, technical depth, business acumen and user obsession to build experiences that empower millions â€” from professional consumers (""prosumers"") to enterprise users. Youâ€™ll shape the next generation of AI-driven productivity tools, moving beyond conversational experiences to redefine how professionals interact with information and create content. ðŸ§¢ Reporting line: Product Director, Applications ðŸ“ Location: NYC What you will do Define the Future â€¢ Set the vision: Shape and evangelize a compelling product strategy for prosumer and enterprise-grade AI tools, ensuring alignment with company goals and market opportunities. â€¢ Spot the gaps: Lead market and UX research to uncover unmet needs, competitive whitespaces, and emerging trends in AI-driven productivity. Build & Ship â€¢ Own the lifecycle: Drive end-to-end product development, from ideation to launch and iterationâ€”balancing speed, quality, and user delight. â€¢ Champion the user: Partner with design and research to craft intuitive, high-impact experiences, using data and feedback to refine continuously. Scale & Execute â€¢ Go-to-market: Collaborate with marketing and sales to launch products successfully, including pricing, positioning, and adoption strategies. â€¢ Align stakeholders: Rally engineering, design, and business teams around priorities, trade-offs, and timelines. â€¢ Prioritize ruthlessly: Maintain a dynamic roadmap that delivers quick wins while advancing long-term bets. Required Qualifications â€¢ Product Management : 5+ years of relevant experience with a focus on building productivity-related products and/or enterprise-grade features (B2B/B2B2C) â€¢ Problem-solving : Experience solving hard problems in dynamic, competitive and ambiguous environments â€¢ AI/ML fluency : Hands-on experience with generative AI, LLMs, or ML-driven products â€” you understand technical trade-offs and can partner effectively with engineering teams. â€¢ Growth mindset : Deep familiarity with product-led growth strategies (e.g., viral loops, onboarding optimization, monetization, AARRR, etc.). â€¢ User obsession : Relentless focus on solving real user problems, backed by data and qualitative insights. â€¢ Cross-functional influence : Proven ability to align and inspire engineering, design, and go-to-market teams without direct authority. â€¢ Pragmatism: Balance big-picture thinking with hands-on problem-solving â€” youâ€™re equally comfortable crafting a roadmap and diving into metrics. â€¢ Communication : Crisp, persuasive storytelling for executives, teams, and usersâ€”whether in docs, decks, or whiteboard sessions. â€¢ Adaptability : Thrive in high-velocity, dynamic settings where priorities shift quickly. â€¢ Collaboration : Low ego + high EQ â€” you build trust and drive decisions through clarity, not hierarchy. â€¢ Autonomy : Self-directed with a bias for action, you own outcomes end-to-end. Now, it would be ideal if you have: â€¢ AI product intuition: Hands-on experience shipping generative AI consumer products â€” youâ€™ve seen what works (and what doesnâ€™t) beyond chatbots. â€¢ Builderâ€™s mindset: Founder or early-stage PM experience â€” youâ€™ve turned 0 â†’ 1 ideas into products users love. â€¢ Technical depth: Ability to prototype, hack, or dive into code when needed (even if not a core responsibility). What we offer ðŸ’° Competitive salary and equity. ðŸš‘ Healthcare: Medical/Dental/Vision covered for you and your family. ðŸ‘´ðŸ» Pension : 401K (6% matching) ðŸï¸ PTO : 18 days ðŸš— Transportation: Reimburse office parking charges, or $120/month for public transport ðŸ€ Sport: $120/month reimbursement for gym membership ðŸ¥• Meal stipend: $400 monthly all",2025-12-07,5.0,,5+ years,Director,director,Machine Learning; Generative AI
653ab69b-42c3-4e9a-bf06-3dbb4d2cf7ad,AI Product Manager,Mistral,"Mistral AI - Product Manager, Document Intellegence",https://jobs.lever.co/mistral/7809b483-bdae-4964-97c7-5b8d232a142f,jobs.lever.co,"Mistral AI - Product Manager, Document Intelligence Product Manager, Document Intelligence New York Product / Full-time / Hybrid Apply for this job About Mistral At Mistral AI, we believe in the power of AI to simplify tasks, save time, and enhance learning and creativity. Our technology is designed to integrate seamlessly into daily working life. We democratize AI through high-performance, optimized, open-source and cutting-edge models, products and solutions. Our comprehensive AI platform is designed to meet enterprise as well as personal needs. Our offerings include Le Chat, La Plateforme, Mistral Code and Mistral Compute - a suite that brings frontier intelligence to end-users. We are a dynamic, collaborative team passionate about AI and its potential to transform society. Our diverse workforce thrives in competitive environments and is committed to driving innovation. Our teams are distributed between France, USA, UK, Germany and Singapore. We are creative, low-ego and team-spirited. Join us to be part of a pioneering company shaping the future of AI. Together, we can make a meaningful impact. See more about our culture on https://mistral.ai/careers. Role summary Weâ€™re seeking strategic and execution-focused product managers to define and execute the strategy for the primary interface through which professionals engage with our models. This role demands a blend of strategic vision, technical depth, business acumen and user obsession to build experiences that empower millions â€” from professional consumers (""prosumers"") to enterprise users. Youâ€™ll shape the next generation of AI-driven productivity tools, moving beyond conversational experiences to redefine how professionals interact with information and create content. ðŸ§¢ Reporting line: Product Director, Applications ðŸ“ Location: NYC What you will do Define the Future â€¢ Set the vision: Shape and evangelize a compelling product strategy for prosumer and enterprise-grade AI tools, ensuring alignment with company goals and market opportunities. â€¢ Spot the gaps: Lead market and UX research to uncover unmet needs, competitive whitespaces, and emerging trends in AI-driven productivity. Build & Ship â€¢ Own the lifecycle: Drive end-to-end product development, from ideation to launch and iterationâ€”balancing speed, quality, and user delight. â€¢ Champion the user: Partner with design and research to craft intuitive, high-impact experiences, using data and feedback to refine continuously. Scale & Execute â€¢ Go-to-market: Collaborate with marketing and sales to launch products successfully, including pricing, positioning, and adoption strategies. â€¢ Align stakeholders: Rally engineering, design, and business teams around priorities, trade-offs, and timelines. â€¢ Prioritize ruthlessly: Maintain a dynamic roadmap that delivers quick wins while advancing long-term bets. Required Qualifications â€¢ Product Management : 5+ years of relevant experience with a focus on building productivity-related products and/or enterprise-grade features (B2B/B2B2C) â€¢ Problem-solving : Experience solving hard problems in dynamic, competitive and ambiguous environments â€¢ AI/ML fluency : Hands-on experience with generative AI, LLMs, or ML-driven products â€” you understand technical trade-offs and can partner effectively with engineering teams. â€¢ Growth mindset : Deep familiarity with product-led growth strategies (e.g., viral loops, onboarding optimization, monetization, AARRR, etc.). â€¢ User obsession : Relentless focus on solving real user problems, backed by data and qualitative insights. â€¢ Cross-functional influence : Proven ability to align and inspire engineering, design, and go-to-market teams without direct authority. â€¢ Pragmatism: Balance big-picture thinking with hands-on problem-solving â€” youâ€™re equally comfortable crafting a roadmap and diving into metrics. â€¢ Communication : Crisp, persuasive storytelling for executives, teams, and usersâ€”whether in docs, decks, or whiteboard sessions. â€¢ Adaptability : Thrive in high-velocity, dynamic settings where priorities shift quickly. â€¢ Collaboration : Low ego + high EQ â€” you build trust and drive decisions through clarity, not hierarchy. â€¢ Autonomy : Self-directed with a bias for action, you own outcomes end-to-end. Now, it would be ideal if you have: â€¢ AI product intuition: Hands-on experience shipping generative AI consumer products â€” youâ€™ve seen what works (and what doesnâ€™t) beyond chatbots. â€¢ Builderâ€™s mindset: Founder or early-stage PM experience â€” youâ€™ve turned 0 â†’ 1 ideas into products users love. â€¢ Technical depth: Ability to prototype, hack, or dive into code when needed (even if not a core responsibility). What we offer ðŸ’° Competitive salary and equity. ðŸš‘ Healthcare: Medical/Dental/Vision covered for you and your family. ðŸ‘´ðŸ» Pension : 401K (6% matching) ðŸï¸ PTO : 18 days ðŸš— Transportation: Reimburse office parking charges, or $120/month for public transport ðŸ€ Sport: $120/month reimbursement for gym membership ðŸ¥• Meal stipend: $400 monthly all",2025-12-07,5.0,,5+ years,Director,director,Machine Learning; Generative AI
820dc002-2ec1-465e-9b66-73d0d18cb54b,AI Product Manager,Mistral,"Mistral AI - Product Manager, AI Assistant - jobs.lever.co",https://jobs.lever.co/mistral/17451d76-dd74-4a01-8959-c2a9e18b19de,jobs.lever.co,"Mistral AI - Product Manager, AI Assistant Product Manager, AI Assistant Paris / London Product / Full-time / Hybrid Apply for this job About Mistral At Mistral AI, we believe in the power of AI to simplify tasks, save time, and enhance learning and creativity. Our technology is designed to integrate seamlessly into daily working life. We democratize AI through high-performance, optimized, open-source and cutting-edge models, products and solutions. Our comprehensive AI platform is designed to meet enterprise needs, whether on-premises or in cloud environments. Our offerings include le Chat, the AI assistant for life and work. We are a dynamic, collaborative team passionate about AI and its potential to transform society. Our diverse workforce thrives in competitive environments and is committed to driving innovation. Our teams are distributed between France, USA, UK, Germany and Singapore. We are creative, low-ego and team-spirited. Join us to be part of a pioneering company shaping the future of AI. Together, we can make a meaningful impact. See more about our culture on https://mistral.ai/careers . Role summary Weâ€™re seeking strategic and execution-focused product managers to define and execute the strategy for the primary interfaces through which professionals engage with our models. This role demands a blend of strategic vision, technical depth, business acumen and user obsession to build experiences that empower millions â€” from professional consumers (""prosumers"") to enterprise users. Youâ€™ll shape the next generation of AI-driven productivity tools, moving beyond conversational experiences to redefine how professionals interact with information and create content. ðŸ§¢ Reporting line: Product Director, Applications ðŸ“ Location: Paris or London What you will do Define the Future â€¢ Set the vision: Shape and evangelize a compelling product strategy for prosumer and enterprise-grade AI tools, ensuring alignment with company goals and market opportunities. â€¢ Spot the gaps: Lead market and UX research to uncover unmet needs, competitive whitespaces, and emerging trends in AI-driven productivity. Build & Ship â€¢ Own the lifecycle: Drive end-to-end product development, from ideation to launch and iterationâ€”balancing speed, quality, and user delight. â€¢ Champion the user: Partner with design and research to craft intuitive, high-impact experiences, using data and feedback to refine continuously. Scale & Execute â€¢ Go-to-market: Collaborate with marketing and sales to launch products successfully, including pricing, positioning, and adoption strategies. â€¢ Align stakeholders: Rally engineering, design, and business teams around priorities, trade-offs, and timelines. â€¢ Prioritize ruthlessly: Maintain a dynamic roadmap that delivers quick wins while advancing long-term bets. Required Qualifications â€¢ Product Management : 5+ years of relevant experience with a focus on building productivity-related products and/or enterprise-grade features (B2B/B2B2C) â€¢ Problem-solving : Experience solving hard problems in dynamic, competitive and ambiguous environments â€¢ AI/ML fluency : Hands-on experience with generative AI, LLMs, or ML-driven products â€” you understand technical trade-offs and can partner effectively with engineering teams. â€¢ Growth mindset : Deep familiarity with product-led growth strategies (e.g., viral loops, onboarding optimization, monetization, AARRR, etc.). â€¢ User obsession : Relentless focus on solving real user problems, backed by data and qualitative insights. â€¢ Cross-functional influence : Proven ability to align and inspire engineering, design, and go-to-market teams without direct authority. â€¢ Pragmatism: Balance big-picture thinking with hands-on problem-solving â€” youâ€™re equally comfortable crafting a roadmap and diving into metrics. â€¢ Communication : Crisp, persuasive storytelling for executives, teams, and usersâ€”whether in docs, decks, or whiteboard sessions. â€¢ Adaptability : Thrive in high-velocity, dynamic settings where priorities shift quickly. â€¢ Collaboration : Low ego + high EQ â€” you build trust and drive decisions through clarity, not hierarchy. â€¢ Autonomy : Self-directed with a bias for action, you own outcomes end-to-end. Now, it would be ideal if you have: â€¢ AI product intuition: Hands-on experience shipping generative AI consumer products â€” youâ€™ve seen what works (and what doesnâ€™t) beyond chatbots. â€¢ Builderâ€™s mindset: Founder or early-stage PM experience â€” youâ€™ve turned 0 â†’ 1 ideas into products users love. â€¢ Technical depth: Ability to prototype, hack, or dive into code when needed (even if not a core responsibility). Location This role is based in one of the following offices: ðŸ‡«ðŸ‡· Paris, France ðŸ‡¬ðŸ‡§ London, UK ðŸ‡ºðŸ‡¸ New York, USA We will only consider candidates who either reside or are open to relocating there. We strongly believe in the value of in-person collaboration and we encourage going to the office as much as we can (at least 3 days per week) to create bonds and smooth communication. Ou",2025-12-07,5.0,,5+ years,Director,director,Machine Learning; Generative AI
d278cee3-5560-4d8a-a4c2-d50768eb2c6d,Software Engineer (Backend),Shopback 2,ShopBack - Software Engineer - Backend - jobs.lever.co,https://jobs.lever.co/shopback-2/b53b7c48-afa3-46b7-9c80-d8de7ec2d36e,jobs.lever.co,"ShopBack - Software Engineer - Backend Software Engineer - Backend Shenzhen, China 11. Engineering â€“ Engineering - SZTG / Full-time / On-site Apply for this job Our Journey ShopBack began in 2014 as a late-night spark of inspiration between Henry and Joel â€” not just to build a Cashback platform, but to reimagine how brands and consumers connect. As former advertisers, they understood the limitations of traditional marketing, and saw an opportunity to deliver more value on both sides. That idea quickly turned into action, and the first prototype was built over a weekend with the other co-founders. Today, ShopBack serves over 50 million users across 13 markets, partners with 20,000+ merchants, and powers over half a million transactions daily. We're building The Worldâ€™s Most Rewarding Way to Shop â€” and looking for bold, driven individuals to join us. About the role: At ShopBack, our engineering teams build scalable and operable platforms serving eCommerce traffic around the world and deliver world-class product experience. You will join a diverse and talented team of engineers from many different countries with great ambitions to impact the eCommerce landscape. We are seeking team members who strive to solve the hard problems, take pride in delivering world-class products, and are strong team players. You are someone who is resilient, self driven and highly motivated. You want to see the impact of your work making a difference every day. You find passion in the craft and are constantly seeking improvement and better ways to solve tough problems. Your Adventure Ahead You have consistently led and delivered large scale projects. Contribute to the ideation, technical design, implementation, and testing of product features Produce high quality software following good architecture and design principles that are scalable Design & deliver thoughtfully crafted clean APIs to drive the interactions between our client applications and backend services Collaborate with product, data and design to define the future of the ShopBack experience Comfortably lead and mentor other software engineers. Encourages others to follow engineering best practices. Analyze requirements well, come up with solutions, and explain trade-offs. Essentials to Succeed 2-4 years of experience developing consumer facing web applications Proven experience designing complex distributed systems, management products or business applications Hands-on experience working with NodeJS (Preferred) Experience building and deploying applications and services into cloud environments (AWS highly desired) Strong experience leading design and implementation of robust and highly scalable web services Demonstrated use of Generative AI tools (e.g. ChatGPT, Cursor) to develop new or improve workflows, enhance productivity, and drive efficiency at scale Ability to work effectively in a fast paced, complex technical environment with high adaptability and flexibility Technologies We Use & Love Cloud: AWS Infra: Kubernetes Programming languages: NodeJS / Typescript, Java, Kotlin, Python Relational database: Postgres Message queue: Kafka, SQS Continuous Integration: Gitlab / Jenkins Monitoring: Prometheus / DataDog Big Data: Redshift, Spark, S3, etc. Communication: Slack Project Management: JIRA / Confluence Other technologies: Knative Eventing / Serving Debezium + Kafka Connect ShopBackers' DNA Grit - We tackle all challenges head-on, working together to solve problems and achieve success. Hunger - We value hard work, and having relentless drive. Speed - We move fast and have a bias for action, all to deliver maximum impact. Impact - We focus on results, always aiming for the best possible outcomes and timelines. Growth - We embrace a growth mindset, constantly striving to learn, improve, and excel in our roles. Exclusively for ShopBackers Career progression paths and opportunities to take on greater challenges that help you realise your ambitions. Be part of a winning team on a journey to global scale. Competitive compensation based on your performance. Candid, open, and collaborative culture where feedback is valued, for everyone to grow and improve every day. Work-From-Anywhere benefit to enable you to thrive personally and professionally. ShopBack is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, color, religion, sexual orientation, national origin, age, disability, genetic information, veteran status, or any other protected status under applicable laws. Join our team and help us make a difference! We are committed to protecting your data and ensuring fairness in our recruitment process. We may use automated tools, including AI, to help our team screen applications, match candidates to roles, generate interview notes, and review assessments. These tools assist our recruiters and interviewers and they do not make final hiring decisions. If an a",2025-12-07,2.0,4.0,2-4 years,Lead,lead,Python; Cloud Platforms; Kubernetes; Data Engineering; Version Control; Databases; CI/CD; Distributed Systems; Generative AI
9f0c9909-98e9-4483-8102-ded517e86a14,Software Engineer (Backend),Shopback 2,ShopBack - Senior Software Engineer - Backend,https://jobs.lever.co/shopback-2/1f85999c-083a-440e-a5cd-0e12f2988da0,jobs.lever.co,"ShopBack - Senior Software Engineer - Backend Senior Software Engineer - Backend Taipei, Taiwan 11. Engineering â€“ Engineering - TTG / Full-time / On-site Apply for this job Our Journey ShopBack began in 2014 as a late-night spark of inspiration between Henry and Joel â€” not just to build a Cashback platform, but to reimagine how brands and consumers connect. As former advertisers, they understood the limitations of traditional marketing, and saw an opportunity to deliver more value on both sides. That idea quickly turned into action, and the first prototype was built over a weekend with the other co-founders. Today, ShopBack serves over 50 million users across 13 markets, partners with 20,000+ merchants, and powers over half a million transactions daily. We're building The Worldâ€™s Most Rewarding Way to Shop â€” and looking for bold, driven individuals to join us. About the role: At ShopBack, our engineering teams build scalable platforms and utilize leading-edge technologies to build a world-class product. You will join a diverse and talented team of aspiring engineers with great ambitions to impact the eCommerce landscape. We are seeking team members who strive to solve the hard problems, take pride in delivering world-class products, and are strong team players. You are someone who wants to see the impact of your work making a difference every day. You find passion in the craft and are constantly seeking improvement and better ways to solve tough problems. Your Adventure Ahead Contribute to the ideation, technical design, implementation, and testing of product features Produce high quality software following good architecture and design principles that are scalable Design & deliver thoughtfully crafted REST APIs to drive the interactions between our client applications and backend services Collaborate with product, data and design to define the future of the ShopBack experience Strong mentoring skills with ability to provide technical guidance and review code Essentials to Succeed 5+ years of experience developing consumer-facing web applications Proven experience designing complex distributed systems, management products or business applications Hands-on experience working with NodeJS (Preferred) Experience building and deploying applications and services into cloud environments (AWS highly desired) Strong experience leading design and implementation of robust and highly scalable web services Demonstrated use of Generative AI tools (e.g. ChatGPT, Cursor) to develop new or improve workflows, enhance productivity, and drive efficiency at scale Ability to work effectively in a fast-paced, complex technical environment with high adaptability and flexibility Fluent in Chinese and English in order to converse effectively with both local and regional stakeholders ShopBackers' DNA Grit - We tackle all challenges head-on, working together to solve problems and achieve success. Hunger - We value hard work, and having relentless drive. Speed - We move fast and have a bias for action, all to deliver maximum impact. Impact - We focus on results, always aiming for the best possible outcomes and timelines. Growth - We embrace a growth mindset, constantly striving to learn, improve, and excel in our roles. Exclusively for ShopBackers Career progression paths and opportunities to take on greater challenges that help you realise your ambitions. Be part of a winning team on a journey to global scale. Competitive compensation based on your performance. Candid, open, and collaborative culture where feedback is valued, for everyone to grow and improve every day. Work-From-Anywhere benefit to enable you to thrive personally and professionally. ShopBack is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, color, religion, sexual orientation, national origin, age, disability, genetic information, veteran status, or any other protected status under applicable laws. Join our team and help us make a difference! We are committed to protecting your data and ensuring fairness in our recruitment process. We may use automated tools, including AI, to help our team screen applications, match candidates to roles, generate interview notes, and review assessments. These tools assist our recruiters and interviewers and they do not make final hiring decisions. If an assessment is part of your process, we may (with your consent) capture screen activity and/or webcam images during the test to help verify test integrity. We do not use AI to infer your emotions or sensitive traits. We process personal data lawfully, securely, and transparently in line with applicable data-protection laws and our commitment to fair employment. You can ask questions or exercise your rights including to request human review or to challenge an outcome by contacting [email protected] . We may use artificial intelligence (AI) tools to support parts of ",2025-12-07,5.0,,5+ years,Senior,senior,Cloud Platforms; Data Engineering; APIs & Microservices; Distributed Systems; Generative AI
789d6a8c-f70c-4f2e-8abe-2859687ac584,Software Engineer (Backend),Shopback 2,ShopBack - Senior Software Engineer - Backend,https://jobs.lever.co/shopback-2/1f85999c-083a-440e-a5cd-0e12f2988da0,jobs.lever.co,"ShopBack - Senior Software Engineer - Backend Senior Software Engineer - Backend Taipei, Taiwan 11. Engineering â€“ Engineering - TTG / Full-time / On-site Apply for this job Our Journey ShopBack began in 2014 as a late-night spark of inspiration between Henry and Joel â€” not just to build a Cashback platform, but to reimagine how brands and consumers connect. As former advertisers, they understood the limitations of traditional marketing, and saw an opportunity to deliver more value on both sides. That idea quickly turned into action, and the first prototype was built over a weekend with the other co-founders. Today, ShopBack serves over 50 million users across 13 markets, partners with 20,000+ merchants, and powers over half a million transactions daily. We're building The Worldâ€™s Most Rewarding Way to Shop â€” and looking for bold, driven individuals to join us. About the role: At ShopBack, our engineering teams build scalable platforms and utilize leading-edge technologies to build a world-class product. You will join a diverse and talented team of aspiring engineers with great ambitions to impact the eCommerce landscape. We are seeking team members who strive to solve the hard problems, take pride in delivering world-class products, and are strong team players. You are someone who wants to see the impact of your work making a difference every day. You find passion in the craft and are constantly seeking improvement and better ways to solve tough problems. Your Adventure Ahead Contribute to the ideation, technical design, implementation, and testing of product features Produce high quality software following good architecture and design principles that are scalable Design & deliver thoughtfully crafted REST APIs to drive the interactions between our client applications and backend services Collaborate with product, data and design to define the future of the ShopBack experience Strong mentoring skills with ability to provide technical guidance and review code Essentials to Succeed 5+ years of experience developing consumer-facing web applications Proven experience designing complex distributed systems, management products or business applications Hands-on experience working with NodeJS (Preferred) Experience building and deploying applications and services into cloud environments (AWS highly desired) Strong experience leading design and implementation of robust and highly scalable web services Demonstrated use of Generative AI tools (e.g. ChatGPT, Cursor) to develop new or improve workflows, enhance productivity, and drive efficiency at scale Ability to work effectively in a fast-paced, complex technical environment with high adaptability and flexibility Fluent in Chinese and English in order to converse effectively with both local and regional stakeholders ShopBackers' DNA Grit - We tackle all challenges head-on, working together to solve problems and achieve success. Hunger - We value hard work, and having relentless drive. Speed - We move fast and have a bias for action, all to deliver maximum impact. Impact - We focus on results, always aiming for the best possible outcomes and timelines. Growth - We embrace a growth mindset, constantly striving to learn, improve, and excel in our roles. Exclusively for ShopBackers Career progression paths and opportunities to take on greater challenges that help you realise your ambitions. Be part of a winning team on a journey to global scale. Competitive compensation based on your performance. Candid, open, and collaborative culture where feedback is valued, for everyone to grow and improve every day. Work-From-Anywhere benefit to enable you to thrive personally and professionally. ShopBack is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, color, religion, sexual orientation, national origin, age, disability, genetic information, veteran status, or any other protected status under applicable laws. Join our team and help us make a difference! We are committed to protecting your data and ensuring fairness in our recruitment process. We may use automated tools, including AI, to help our team screen applications, match candidates to roles, generate interview notes, and review assessments. These tools assist our recruiters and interviewers and they do not make final hiring decisions. If an assessment is part of your process, we may (with your consent) capture screen activity and/or webcam images during the test to help verify test integrity. We do not use AI to infer your emotions or sensitive traits. We process personal data lawfully, securely, and transparently in line with applicable data-protection laws and our commitment to fair employment. You can ask questions or exercise your rights including to request human review or to challenge an outcome by contacting [email protected] . We may use artificial intelligence (AI) tools to support parts of ",2025-12-07,5.0,,5+ years,Senior,senior,Cloud Platforms; Data Engineering; APIs & Microservices; Distributed Systems; Generative AI
49a5c1cf-ec1b-430d-a13c-9e0b22902b52,Software Engineer (Backend),Shopback 2,ShopBack - Software Engineer - Backend - jobs.lever.co,https://jobs.lever.co/shopback-2/b53b7c48-afa3-46b7-9c80-d8de7ec2d36e,jobs.lever.co,"ShopBack - Software Engineer - Backend Software Engineer - Backend Shenzhen, China 11. Engineering â€“ Engineering - SZTG / Full-time / On-site Apply for this job Our Journey ShopBack began in 2014 as a late-night spark of inspiration between Henry and Joel â€” not just to build a Cashback platform, but to reimagine how brands and consumers connect. As former advertisers, they understood the limitations of traditional marketing, and saw an opportunity to deliver more value on both sides. That idea quickly turned into action, and the first prototype was built over a weekend with the other co-founders. Today, ShopBack serves over 50 million users across 13 markets, partners with 20,000+ merchants, and powers over half a million transactions daily. We're building The Worldâ€™s Most Rewarding Way to Shop â€” and looking for bold, driven individuals to join us. About the role: At ShopBack, our engineering teams build scalable and operable platforms serving eCommerce traffic around the world and deliver world-class product experience. You will join a diverse and talented team of engineers from many different countries with great ambitions to impact the eCommerce landscape. We are seeking team members who strive to solve the hard problems, take pride in delivering world-class products, and are strong team players. You are someone who is resilient, self driven and highly motivated. You want to see the impact of your work making a difference every day. You find passion in the craft and are constantly seeking improvement and better ways to solve tough problems. Your Adventure Ahead You have consistently led and delivered large scale projects. Contribute to the ideation, technical design, implementation, and testing of product features Produce high quality software following good architecture and design principles that are scalable Design & deliver thoughtfully crafted clean APIs to drive the interactions between our client applications and backend services Collaborate with product, data and design to define the future of the ShopBack experience Comfortably lead and mentor other software engineers. Encourages others to follow engineering best practices. Analyze requirements well, come up with solutions, and explain trade-offs. Essentials to Succeed 2-4 years of experience developing consumer facing web applications Proven experience designing complex distributed systems, management products or business applications Hands-on experience working with NodeJS (Preferred) Experience building and deploying applications and services into cloud environments (AWS highly desired) Strong experience leading design and implementation of robust and highly scalable web services Demonstrated use of Generative AI tools (e.g. ChatGPT, Cursor) to develop new or improve workflows, enhance productivity, and drive efficiency at scale Ability to work effectively in a fast paced, complex technical environment with high adaptability and flexibility Technologies We Use & Love Cloud: AWS Infra: Kubernetes Programming languages: NodeJS / Typescript, Java, Kotlin, Python Relational database: Postgres Message queue: Kafka, SQS Continuous Integration: Gitlab / Jenkins Monitoring: Prometheus / DataDog Big Data: Redshift, Spark, S3, etc. Communication: Slack Project Management: JIRA / Confluence Other technologies: Knative Eventing / Serving Debezium + Kafka Connect ShopBackers' DNA Grit - We tackle all challenges head-on, working together to solve problems and achieve success. Hunger - We value hard work, and having relentless drive. Speed - We move fast and have a bias for action, all to deliver maximum impact. Impact - We focus on results, always aiming for the best possible outcomes and timelines. Growth - We embrace a growth mindset, constantly striving to learn, improve, and excel in our roles. Exclusively for ShopBackers Career progression paths and opportunities to take on greater challenges that help you realise your ambitions. Be part of a winning team on a journey to global scale. Competitive compensation based on your performance. Candid, open, and collaborative culture where feedback is valued, for everyone to grow and improve every day. Work-From-Anywhere benefit to enable you to thrive personally and professionally. ShopBack is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, color, religion, sexual orientation, national origin, age, disability, genetic information, veteran status, or any other protected status under applicable laws. Join our team and help us make a difference! We are committed to protecting your data and ensuring fairness in our recruitment process. We may use automated tools, including AI, to help our team screen applications, match candidates to roles, generate interview notes, and review assessments. These tools assist our recruiters and interviewers and they do not make final hiring decisions. If an a",2025-12-07,2.0,4.0,2-4 years,Lead,lead,Python; Cloud Platforms; Kubernetes; Data Engineering; Version Control; Databases; CI/CD; Distributed Systems; Generative AI
d031df97-dce4-4243-8ad8-d67432de396a,Software Engineer (Backend),Shopback 2,ShopBack - Software Engineer - Backend - jobs.lever.co,https://jobs.lever.co/shopback-2/b53b7c48-afa3-46b7-9c80-d8de7ec2d36e,jobs.lever.co,"ShopBack - Software Engineer - Backend Software Engineer - Backend Shenzhen, China 11. Engineering â€“ Engineering - SZTG / Full-time / On-site Apply for this job Our Journey ShopBack began in 2014 as a late-night spark of inspiration between Henry and Joel â€” not just to build a Cashback platform, but to reimagine how brands and consumers connect. As former advertisers, they understood the limitations of traditional marketing, and saw an opportunity to deliver more value on both sides. That idea quickly turned into action, and the first prototype was built over a weekend with the other co-founders. Today, ShopBack serves over 50 million users across 13 markets, partners with 20,000+ merchants, and powers over half a million transactions daily. We're building The Worldâ€™s Most Rewarding Way to Shop â€” and looking for bold, driven individuals to join us. About the role: At ShopBack, our engineering teams build scalable and operable platforms serving eCommerce traffic around the world and deliver world-class product experience. You will join a diverse and talented team of engineers from many different countries with great ambitions to impact the eCommerce landscape. We are seeking team members who strive to solve the hard problems, take pride in delivering world-class products, and are strong team players. You are someone who is resilient, self driven and highly motivated. You want to see the impact of your work making a difference every day. You find passion in the craft and are constantly seeking improvement and better ways to solve tough problems. Your Adventure Ahead You have consistently led and delivered large scale projects. Contribute to the ideation, technical design, implementation, and testing of product features Produce high quality software following good architecture and design principles that are scalable Design & deliver thoughtfully crafted clean APIs to drive the interactions between our client applications and backend services Collaborate with product, data and design to define the future of the ShopBack experience Comfortably lead and mentor other software engineers. Encourages others to follow engineering best practices. Analyze requirements well, come up with solutions, and explain trade-offs. Essentials to Succeed 2-4 years of experience developing consumer facing web applications Proven experience designing complex distributed systems, management products or business applications Hands-on experience working with NodeJS (Preferred) Experience building and deploying applications and services into cloud environments (AWS highly desired) Strong experience leading design and implementation of robust and highly scalable web services Demonstrated use of Generative AI tools (e.g. ChatGPT, Cursor) to develop new or improve workflows, enhance productivity, and drive efficiency at scale Ability to work effectively in a fast paced, complex technical environment with high adaptability and flexibility Technologies We Use & Love Cloud: AWS Infra: Kubernetes Programming languages: NodeJS / Typescript, Java, Kotlin, Python Relational database: Postgres Message queue: Kafka, SQS Continuous Integration: Gitlab / Jenkins Monitoring: Prometheus / DataDog Big Data: Redshift, Spark, S3, etc. Communication: Slack Project Management: JIRA / Confluence Other technologies: Knative Eventing / Serving Debezium + Kafka Connect ShopBackers' DNA Grit - We tackle all challenges head-on, working together to solve problems and achieve success. Hunger - We value hard work, and having relentless drive. Speed - We move fast and have a bias for action, all to deliver maximum impact. Impact - We focus on results, always aiming for the best possible outcomes and timelines. Growth - We embrace a growth mindset, constantly striving to learn, improve, and excel in our roles. Exclusively for ShopBackers Career progression paths and opportunities to take on greater challenges that help you realise your ambitions. Be part of a winning team on a journey to global scale. Competitive compensation based on your performance. Candid, open, and collaborative culture where feedback is valued, for everyone to grow and improve every day. Work-From-Anywhere benefit to enable you to thrive personally and professionally. ShopBack is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, color, religion, sexual orientation, national origin, age, disability, genetic information, veteran status, or any other protected status under applicable laws. Join our team and help us make a difference! We are committed to protecting your data and ensuring fairness in our recruitment process. We may use automated tools, including AI, to help our team screen applications, match candidates to roles, generate interview notes, and review assessments. These tools assist our recruiters and interviewers and they do not make final hiring decisions. If an a",2025-12-07,2.0,4.0,2-4 years,Lead,lead,Python; Cloud Platforms; Kubernetes; Data Engineering; Version Control; Databases; CI/CD; Distributed Systems; Generative AI
2f89c465-7dec-41d5-873f-fbcdad6f15b7,Software Engineer (Backend),Shopback 2,ShopBack - Senior Software Engineer - Backend,https://jobs.lever.co/shopback-2/1f85999c-083a-440e-a5cd-0e12f2988da0,jobs.lever.co,"ShopBack - Senior Software Engineer - Backend Senior Software Engineer - Backend Taipei, Taiwan 11. Engineering â€“ Engineering - TTG / Full-time / On-site Apply for this job Our Journey ShopBack began in 2014 as a late-night spark of inspiration between Henry and Joel â€” not just to build a Cashback platform, but to reimagine how brands and consumers connect. As former advertisers, they understood the limitations of traditional marketing, and saw an opportunity to deliver more value on both sides. That idea quickly turned into action, and the first prototype was built over a weekend with the other co-founders. Today, ShopBack serves over 50 million users across 13 markets, partners with 20,000+ merchants, and powers over half a million transactions daily. We're building The Worldâ€™s Most Rewarding Way to Shop â€” and looking for bold, driven individuals to join us. About the role: At ShopBack, our engineering teams build scalable platforms and utilize leading-edge technologies to build a world-class product. You will join a diverse and talented team of aspiring engineers with great ambitions to impact the eCommerce landscape. We are seeking team members who strive to solve the hard problems, take pride in delivering world-class products, and are strong team players. You are someone who wants to see the impact of your work making a difference every day. You find passion in the craft and are constantly seeking improvement and better ways to solve tough problems. Your Adventure Ahead Contribute to the ideation, technical design, implementation, and testing of product features Produce high quality software following good architecture and design principles that are scalable Design & deliver thoughtfully crafted REST APIs to drive the interactions between our client applications and backend services Collaborate with product, data and design to define the future of the ShopBack experience Strong mentoring skills with ability to provide technical guidance and review code Essentials to Succeed 5+ years of experience developing consumer-facing web applications Proven experience designing complex distributed systems, management products or business applications Hands-on experience working with NodeJS (Preferred) Experience building and deploying applications and services into cloud environments (AWS highly desired) Strong experience leading design and implementation of robust and highly scalable web services Demonstrated use of Generative AI tools (e.g. ChatGPT, Cursor) to develop new or improve workflows, enhance productivity, and drive efficiency at scale Ability to work effectively in a fast-paced, complex technical environment with high adaptability and flexibility Fluent in Chinese and English in order to converse effectively with both local and regional stakeholders ShopBackers' DNA Grit - We tackle all challenges head-on, working together to solve problems and achieve success. Hunger - We value hard work, and having relentless drive. Speed - We move fast and have a bias for action, all to deliver maximum impact. Impact - We focus on results, always aiming for the best possible outcomes and timelines. Growth - We embrace a growth mindset, constantly striving to learn, improve, and excel in our roles. Exclusively for ShopBackers Career progression paths and opportunities to take on greater challenges that help you realise your ambitions. Be part of a winning team on a journey to global scale. Competitive compensation based on your performance. Candid, open, and collaborative culture where feedback is valued, for everyone to grow and improve every day. Work-From-Anywhere benefit to enable you to thrive personally and professionally. ShopBack is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, color, religion, sexual orientation, national origin, age, disability, genetic information, veteran status, or any other protected status under applicable laws. Join our team and help us make a difference! We are committed to protecting your data and ensuring fairness in our recruitment process. We may use automated tools, including AI, to help our team screen applications, match candidates to roles, generate interview notes, and review assessments. These tools assist our recruiters and interviewers and they do not make final hiring decisions. If an assessment is part of your process, we may (with your consent) capture screen activity and/or webcam images during the test to help verify test integrity. We do not use AI to infer your emotions or sensitive traits. We process personal data lawfully, securely, and transparently in line with applicable data-protection laws and our commitment to fair employment. You can ask questions or exercise your rights including to request human review or to challenge an outcome by contacting [email protected] . We may use artificial intelligence (AI) tools to support parts of ",2025-12-07,5.0,,5+ years,Senior,senior,Cloud Platforms; Data Engineering; APIs & Microservices; Distributed Systems; Generative AI
